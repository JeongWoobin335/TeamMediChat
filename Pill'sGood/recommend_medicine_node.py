# recommend_medicine_node.py

from qa_state import QAState
from retrievers import llm, pdf_structured_docs, excel_docs
from langchain_core.documents import Document
from typing import List
import json
import re
from cache_manager import cache_manager

# ì‹ ì²´ ë¶€ìœ„ë³„ ìœ„í—˜ í‚¤ì›Œë“œ ë§µ
body_part_risk_map = {
    "ìœ„ì¥": ["ìœ„ì¥ ìê·¹", "ì†ì“°ë¦¼", "êµ¬í† ", "ì†Œí™”ë¶ˆëŸ‰", "ìœ„í†µ", "ë³µí†µ", "ë©”ìŠ¤êº¼ì›€"],
    "ì‹¬ì¥": ["ì‹¬ì¥ ë¶€ë‹´", "í˜ˆì•• ìƒìŠ¹", "ì‹¬ë°•ìˆ˜ ì¦ê°€", "ë¶€ì •ë§¥", "í˜‘ì‹¬ì¦"],
    "ê°„": ["ê°„ë…ì„±", "ê°„ ì†ìƒ", "ê°„ìˆ˜ì¹˜ ìƒìŠ¹", "í™©ë‹¬"],
    "ì‹ ì¥": ["ì‹ ì¥ ë…ì„±", "ì‹ ì¥ ì†ìƒ", "ì†Œë³€ëŸ‰ ê°ì†Œ", "ë¶€ì¢…"],
    "í": ["í˜¸í¡ê³¤ë€", "ê¸°ì¹¨", "ì²œì‹ ì•…í™”", "íë¶€ì¢…"],
    "ë‡Œ": ["ë‘í†µ", "ì–´ì§€ëŸ¼ì¦", "ì¡¸ìŒ", "ì§‘ì¤‘ë ¥ ì €í•˜", "ê¸°ì–µë ¥ ì €í•˜"]
}

# ë³‘ë ¥ ìœ„í—˜ í‚¤ì›Œë“œ ë§µ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
condition_risk_map = {
    "ìœ„ì¥ì—¼": body_part_risk_map["ìœ„ì¥"],
    "ê°„ì§ˆí™˜": body_part_risk_map["ê°„"],
    "ê³ í˜ˆì••": body_part_risk_map["ì‹¬ì¥"],
    "ê°ê¸°": []  # ê°ê¸°ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìœ„í—˜ í‚¤ì›Œë“œê°€ ì—†ìŒ
}

# ì‹ ì²´ ë¶€ìœ„ ê°ì§€ í•¨ìˆ˜
def detect_body_part_concern(query: str) -> tuple[str, list[str]]:
    """ì§ˆë¬¸ì—ì„œ ì‹ ì²´ ë¶€ìœ„ë³„ ìš°ë ¤ì‚¬í•­ì„ ê°ì§€í•©ë‹ˆë‹¤."""
    query_lower = query.lower()
    
    # ì‹ ì²´ ë¶€ìœ„ë³„ í‚¤ì›Œë“œ ë§¤í•‘
    body_part_keywords = {
        "ìœ„ì¥": ["ìœ„ì¥", "ìœ„", "ì†", "ë°°", "ë³µë¶€"],
        "ì‹¬ì¥": ["ì‹¬ì¥", "ì‹¬", "í˜ˆì••", "í˜ˆê´€"],
        "ê°„": ["ê°„", "ê°„ì¥"],
        "ì‹ ì¥": ["ì‹ ì¥", "ì½©íŒ¥", "ì†Œë³€"],
        "í": ["í", "í˜¸í¡", "ìˆ¨"],
        "ë‡Œ": ["ë‡Œ", "ë¨¸ë¦¬", "ì •ì‹ ", "ì§‘ì¤‘"]
    }
    
    # ë¶€ë‹´/ìê·¹ ê´€ë ¨ í‚¤ì›Œë“œ
    concern_keywords = ["ë¶€ë‹´", "ìê·¹", "ë‚˜ì¨", "ì•ˆì¢‹ìŒ", "ë¯¼ê°", "ì•½í•¨", "ìƒì²˜"]
    
    detected_parts = []
    for part, keywords in body_part_keywords.items():
        if any(keyword in query_lower for keyword in keywords):
            if any(concern in query_lower for concern in concern_keywords):
                detected_parts.append(part)
    
    return detected_parts[0] if detected_parts else "", detected_parts

# í•„ë“œ ì¶”ì¶œ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)
def extract_field_from_doc(text: str, label: str) -> str:
    pattern = rf"\[{label}\]:\s*((?:.|\n)*?)(?=\n\[|\Z)"
    match = re.search(pattern, text)
    return match.group(1).strip() if match else "ì •ë³´ ì—†ìŒ"

# ì•½í’ˆë³„ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ (ìƒˆë¡œìš´ ì²­í¬ êµ¬ì¡° ì§€ì›)
def collect_medicine_info(product_name: str, all_docs: List[Document]) -> dict:
    """ì•½í’ˆë³„ë¡œ íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²• ì •ë³´ë¥¼ ìˆ˜ì§‘"""
    info = {
        "ì œí’ˆëª…": product_name,
        "íš¨ëŠ¥": "ì •ë³´ ì—†ìŒ",
        "ë¶€ì‘ìš©": "ì •ë³´ ì—†ìŒ", 
        "ì‚¬ìš©ë²•": "ì •ë³´ ì—†ìŒ"
    }
    
    # í•´ë‹¹ ì•½í’ˆì˜ ëª¨ë“  ë¬¸ì„œ ì°¾ê¸°
    product_docs = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == product_name]
    
    for doc in product_docs:
        content = doc.page_content
        doc_type = doc.metadata.get("type", "")
        
        # íš¨ëŠ¥ê³¼ ë¶€ì‘ìš©ì€ main íƒ€ì…ì—ì„œ ì¶”ì¶œ
        if doc_type == "main" or doc_type == "":
            efficacy = extract_field_from_doc(content, "íš¨ëŠ¥")
            side_effects = extract_field_from_doc(content, "ë¶€ì‘ìš©")
            
            if efficacy != "ì •ë³´ ì—†ìŒ":
                info["íš¨ëŠ¥"] = efficacy
            if side_effects != "ì •ë³´ ì—†ìŒ":
                info["ë¶€ì‘ìš©"] = side_effects
        
        # ì‚¬ìš©ë²•ì€ usage íƒ€ì…ì—ì„œ ì¶”ì¶œ
        if doc_type == "usage":
            usage = extract_field_from_doc(content, "ì‚¬ìš©ë²•")
            if usage != "ì •ë³´ ì—†ìŒ":
                info["ì‚¬ìš©ë²•"] = usage
    
    return info

# ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì•½í’ˆ-ì¦ìƒ ë§¤ì¹­ íŒë‹¨
def batch_medicine_matching(medicines_info, condition, batch_size=20):
    """ì—¬ëŸ¬ ì•½í’ˆì„ í•œ ë²ˆì— ë¬¶ì–´ì„œ LLMì´ ì¦ìƒ ê´€ë ¨ì„±ì„ íŒë‹¨"""
    if not medicines_info:
        return {}
    
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    cached_result = cache_manager.get_matching_cache(condition, medicines_info)
    if cached_result is not None:
        return cached_result
    
    # ì•½í’ˆì´ ë„ˆë¬´ ë§ìœ¼ë©´ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    medicines_list = list(medicines_info.items())
    all_results = {}
    
    for i in range(0, len(medicines_list), batch_size):
        batch_medicines = dict(medicines_list[i:i + batch_size])
        
        # ë°°ì¹˜ë³„ ìºì‹œ í™•ì¸
        batch_cached = cache_manager.get_matching_cache(condition, batch_medicines)
        if batch_cached is not None:
            all_results.update(batch_cached)
            continue
        
        # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        medicines_text = ""
        for j, (name, info) in enumerate(batch_medicines.items(), 1):
            medicines_text += f"{j}. {name}: {info['íš¨ëŠ¥']}\n"
        
        batch_prompt = f"""
        ë‹¤ìŒ ì•½í’ˆë“¤ ì¤‘ '{condition}' ì¦ìƒì— ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì•½í’ˆë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.
        
        {medicines_text}
        
        ë‹µë³€ì€ ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1,3,5)
        ë„ì›€ì´ ë˜ëŠ” ì•½í’ˆì´ ì—†ìœ¼ë©´ 'ì—†ìŒ'ì´ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = llm.invoke(batch_prompt).content.strip()
            
            # ì‘ë‹µ íŒŒì‹±
            if "ì—†ìŒ" in response or "none" in response.lower():
                batch_result = {}
            else:
                # ë²ˆí˜¸ ì¶”ì¶œ
                import re
                numbers = re.findall(r'\d+', response)
                batch_result = {}
                
                for num in numbers:
                    idx = int(num) - 1
                    if idx < len(batch_medicines):
                        medicine_name = list(batch_medicines.keys())[idx]
                        batch_result[medicine_name] = True
            
            # ë°°ì¹˜ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            cache_manager.save_matching_cache(condition, batch_medicines, batch_result)
            
            # ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
            all_results.update(batch_result)
            
        except Exception as e:
            print(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ (ë°°ì¹˜ {i//batch_size + 1}): {e}")
            continue
    
    return all_results

# ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
def generate_recommendation_response(condition, category, candidates, primary_concern=None):
    # ì‹ ì²´ ë¶€ìœ„ë³„ ê·¼ê±° ì„¤ëª… ì¶”ê°€
    concern_explanation = ""
    if primary_concern:
        concern_explanation = f"""
**ì¤‘ìš”**: ì‚¬ìš©ìê°€ '{primary_concern}'ì— ë¶€ë‹´ì´ ì ì€ ì•½ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
ë¶€ì‘ìš© ì„¹ì…˜ì—ì„œ '{primary_concern}' ê´€ë ¨ í‚¤ì›Œë“œê°€ ì ì€ ì•½í’ˆì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•˜ê³ , 
ì™œ í•´ë‹¹ ì•½í’ˆì´ '{primary_concern}'ì— ë¶€ë‹´ì´ ì ì€ì§€ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
    
    prompt = f"""
ë‹¹ì‹ ì€ ê±´ê°• ìƒíƒœì— ë§ëŠ” ì•½ì„ ì¶”ì²œí•´ì£¼ëŠ” ê±´ê°• ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” '{condition}' ë³‘ë ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, '{category}'ì— ë„ì›€ì´ ë˜ëŠ” ì•½ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.

{concern_explanation}

ë‹¤ìŒì€ ì¶”ì²œ ê°€ëŠ¥í•œ í›„ë³´ ëª©ë¡ì…ë‹ˆë‹¤. ê° ì•½í’ˆì„ ì¹œì ˆí•˜ê²Œ ì†Œê°œí•˜ê³  ë³‘ë ¥ê³¼ ê´€ë ¨ëœ ì´ìœ ë¥¼ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ë¶€ì‘ìš© ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™œ í•´ë‹¹ ì•½í’ˆì´ ì í•©í•œì§€ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

{json.dumps(candidates[:3], ensure_ascii=False)}

**ì‘ë‹µ í˜•ì‹**:
1. ê° ì•½í’ˆë³„ë¡œ íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²•ì„ ëª…í™•íˆ ì„¤ëª…
2. ë¶€ì‘ìš© ì„¹ì…˜ì—ì„œ ì‹¤ì œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ì²´ ë¶€ìœ„ë³„ ë¶€ë‹´ë„ ì„¤ëª…
3. êµ¬ì²´ì ì¸ ê·¼ê±° ì—†ì´ "ë¶€ë‹´ì´ ì ë‹¤"ê³  í•¨ë¶€ë¡œ ë§í•˜ì§€ ë§ê³ , ì‹¤ì œ ë¶€ì‘ìš© ë‚´ìš©ì„ ì¸ìš©
4. ë°ì´í„° ì†ŒìŠ¤(PDF/Excel)ë„ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„± í‘œì‹œ

ë‹µë³€:
"""
    return llm.invoke(prompt).content.strip()

# LangGraph ë…¸ë“œ ì •ì˜
def recommend_medicine_node(state: QAState) -> QAState:
    condition = state.get("condition", "")
    category = state.get("category", "")
    query = state.get("query", "").lower()
    
    if not condition or not category:
        state["recommendation_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ë³‘ë ¥ ë˜ëŠ” ì•½ë¬¼ ì¢…ë¥˜ ì •ë³´ê°€ ì—†ì–´ ì¶”ì²œì´ ì–´ë µìŠµë‹ˆë‹¤."
        return state

    # conditionì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
    if isinstance(condition, list):
        conditions = condition
    else:
        conditions = [condition] if condition else []
    
    # ì‹ ì²´ ë¶€ìœ„ë³„ ìš°ë ¤ì‚¬í•­ ê°ì§€
    primary_concern, all_concerns = detect_body_part_concern(query)

    # ëª¨ë“  ì¡°ê±´ì— ëŒ€í•œ ìœ„í—˜ í‚¤ì›Œë“œ ìˆ˜ì§‘
    all_risk_keywords = []
    for cond in conditions:
        if cond in condition_risk_map:
            all_risk_keywords.extend(condition_risk_map[cond])
    
    # ì¤‘ë³µ ì œê±°
    all_risk_keywords = list(set(all_risk_keywords))
    
    candidates = []
    
    # Excel DBë¥¼ ìš°ì„ ìœ¼ë¡œ ê²€ìƒ‰ (Excel ìš°ì„  ì •ì±…)
    print(f"ğŸ” Excel DB ìš°ì„  ê²€ìƒ‰ ì‹œì‘: {len(excel_docs)}ê°œ ë¬¸ì„œ")
    
    # Excelì—ì„œ ë¨¼ì € ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘
    excel_medicines_info = {}
    for doc in excel_docs:
        name = doc.metadata.get("ì œí’ˆëª…", "")
        if name and name not in excel_medicines_info:
            medicine_info = collect_medicine_info(name, excel_docs)
            excel_medicines_info[name] = medicine_info
    
    print(f"âœ… Excel DBì—ì„œ {len(excel_medicines_info)}ê°œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘")
    
    # Excel DBì—ì„œ ë¨¼ì € ë§¤ì¹­ ì‹œë„
    for condition in conditions:
        if excel_medicines_info:
            print(f"ğŸ” Excel DBì—ì„œ {condition} ì¦ìƒ ë§¤ì¹­ ì‹œë„...")
            excel_relevant_medicines = batch_medicine_matching(excel_medicines_info, condition, batch_size=15)
            
            # Excel DBì—ì„œ ë§¤ì¹­ëœ ì•½í’ˆë“¤ì„ candidatesì— ì¶”ê°€
            for name, is_relevant in excel_relevant_medicines.items():
                if is_relevant and name in excel_medicines_info:
                    medicine_info = excel_medicines_info[name]
                    
                    # ì‹ ì²´ ë¶€ìœ„ë³„ ìš°ë ¤ì‚¬í•­ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë¶€ìœ„ ë¶€ì‘ìš©ì´ ì ì€ ì•½í’ˆ ìš°ì„ 
                    if primary_concern:
                        concern_risk_keywords = body_part_risk_map.get(primary_concern, [])
                        concern_risk_count = sum(1 for risk in concern_risk_keywords if risk in medicine_info["ë¶€ì‘ìš©"].lower())
                        
                        # í•´ë‹¹ ë¶€ìœ„ ë¶€ì‘ìš©ì´ ì ì€ ì•½í’ˆë§Œ ì„ íƒ
                        if concern_risk_count <= 1:
                            candidates.append({
                                "ì œí’ˆëª…": name,
                                "íš¨ëŠ¥": medicine_info["íš¨ëŠ¥"],
                                "ë¶€ì‘ìš©": medicine_info["ë¶€ì‘ìš©"],
                                "ì‚¬ìš©ë²•": medicine_info["ì‚¬ìš©ë²•"],
                                f"{primary_concern}_ë¶€ë‹´ë„": concern_risk_count,
                                "ë°ì´í„°_ì†ŒìŠ¤": "Excel"
                            })
                            print(f"âœ… Excel í›„ë³´ ì¶”ê°€: {name}")
                    else:
                        # ì¼ë°˜ì ì¸ ìœ„í—˜ í‚¤ì›Œë“œ í•„í„°ë§
                        if not any(risk in medicine_info["ë¶€ì‘ìš©"].lower() for risk in all_risk_keywords):
                            candidates.append({
                                "ì œí’ˆëª…": name,
                                "íš¨ëŠ¥": medicine_info["íš¨ëŠ¥"],
                                "ë¶€ì‘ìš©": medicine_info["ë¶€ì‘ìš©"],
                                "ì‚¬ìš©ë²•": medicine_info["ì‚¬ìš©ë²•"],
                                "ë°ì´í„°_ì†ŒìŠ¤": "Excel"
                            })
                            print(f"âœ… Excel í›„ë³´ ì¶”ê°€: {name}")
    
    # Excel DBì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ PDF ë³´ì™„
    if len(candidates) < 3:  # ìµœì†Œ 3ê°œ ì´ìƒì˜ ì•½í’ˆì´ í•„ìš”
        print(f"ğŸ” Excel DBì—ì„œ {len(candidates)}ê°œ ì•½í’ˆë§Œ ì°¾ìŒ, PDF DB ë³´ì™„ ê²€ìƒ‰...")
        
        # PDFì—ì„œ ì¶”ê°€ ê²€ìƒ‰
        pdf_medicines_info = {}
        for doc in pdf_structured_docs:
            name = doc.metadata.get("ì œí’ˆëª…", "")
            if name and name not in pdf_medicines_info:
                medicine_info = collect_medicine_info(name, pdf_structured_docs)
                pdf_medicines_info[name] = medicine_info
        
        print(f"âœ… PDF DBì—ì„œ {len(pdf_medicines_info)}ê°œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘")
        
        # PDFì—ì„œ ì¶”ê°€ ë§¤ì¹­
        for condition in conditions:
            if pdf_medicines_info:
                print(f"ğŸ” PDF DBì—ì„œ {condition} ì¦ìƒ ì¶”ê°€ ë§¤ì¹­...")
                pdf_relevant_medicines = batch_medicine_matching(pdf_medicines_info, condition, batch_size=10)
                
                # ì´ë¯¸ Excelì—ì„œ ì°¾ì€ ì•½í’ˆì€ ì œì™¸í•˜ê³  PDFì—ì„œë§Œ ì°¾ì€ ì•½í’ˆ ì¶”ê°€
                for name, is_relevant in pdf_relevant_medicines.items():
                    if is_relevant and name in pdf_medicines_info and name not in [c["ì œí’ˆëª…"] for c in candidates]:
                        medicine_info = pdf_medicines_info[name]
                        
                        # ì‹ ì²´ ë¶€ìœ„ë³„ ìš°ë ¤ì‚¬í•­ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë¶€ìœ„ ë¶€ì‘ìš©ì´ ì ì€ ì•½í’ˆ ìš°ì„ 
                        if primary_concern:
                            concern_risk_keywords = body_part_risk_map.get(primary_concern, [])
                            concern_risk_count = sum(1 for risk in concern_risk_keywords if risk in medicine_info["ë¶€ì‘ìš©"].lower())
                            
                            if concern_risk_count <= 1:
                                candidates.append({
                                    "ì œí’ˆëª…": name,
                                    "íš¨ëŠ¥": medicine_info["íš¨ëŠ¥"],
                                    "ë¶€ì‘ìš©": medicine_info["ë¶€ì‘ìš©"],
                                    "ì‚¬ìš©ë²•": medicine_info["ì‚¬ìš©ë²•"],
                                    f"{primary_concern}_ë¶€ë‹´ë„": concern_risk_count,
                                    "ë°ì´í„°_ì†ŒìŠ¤": "PDF"
                                })
                                print(f"âœ… PDF í›„ë³´ ì¶”ê°€: {name}")
                        else:
                            if not any(risk in medicine_info["ë¶€ì‘ìš©"].lower() for risk in all_risk_keywords):
                                candidates.append({
                                    "ì œí’ˆëª…": name,
                                    "íš¨ëŠ¥": medicine_info["íš¨ëŠ¥"],
                                    "ë¶€ì‘ìš©": medicine_info["ë¶€ì‘ìš©"],
                                    "ì‚¬ìš©ë²•": medicine_info["ì‚¬ìš©ë²•"],
                                    "ë°ì´í„°_ì†ŒìŠ¤": "PDF"
                                })
                                print(f"âœ… PDF í›„ë³´ ì¶”ê°€: {name}")
                        
                        # ì¶©ë¶„í•œ ì•½í’ˆì„ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
                        if len(candidates) >= 5:
                            break
    else:
        print(f"âœ… Excel DBì—ì„œ ì¶©ë¶„í•œ ì•½í’ˆì„ ì°¾ìŒ: {len(candidates)}ê°œ, PDF ê²€ìƒ‰ ê±´ë„ˆëœ€")

    print(f"ğŸ” ë””ë²„ê¹…: ìµœì¢… candidates ê°œìˆ˜ = {len(candidates)}")
    print(f"ğŸ” ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„:")
    excel_count = sum(1 for c in candidates if c["ë°ì´í„°_ì†ŒìŠ¤"] == "Excel")
    pdf_count = sum(1 for c in candidates if c["ë°ì´í„°_ì†ŒìŠ¤"] == "PDF")
    print(f"  - Excel: {excel_count}ê°œ")
    print(f"  - PDF: {pdf_count}ê°œ")
    
    if not candidates:
        state["recommendation_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{condition}' ë³‘ë ¥ì— ì í•©í•œ {category} ê´€ë ¨ ì•½í’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return state

    # ì‹ ì²´ ë¶€ìœ„ë³„ ìš°ë ¤ì‚¬í•­ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë¶€ìœ„ ë¶€ë‹´ë„ë¡œ ì •ë ¬
    if primary_concern:
        candidates.sort(key=lambda x: x.get(f"{primary_concern}_ë¶€ë‹´ë„", 0))

    try:
        response = generate_recommendation_response(condition, category, candidates, primary_concern)
        state["recommendation_answer"] = response
    except Exception as e:
        state["recommendation_answer"] = "ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: LLM í˜¸ì¶œ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return state
