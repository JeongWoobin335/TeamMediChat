# naver_news_api.py - ë„¤ì´ë²„ ë‰´ìŠ¤ API ì—°ë™ (ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ìš©)

import os
import requests
import time
from typing import List, Dict, Optional
from dotenv import load_dotenv
from cache_manager import cache_manager

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class NaverNewsAPI:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í´ëž˜ìŠ¤ - ì•½í’ˆ ê´€ë ¨ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘"""
    
    def __init__(self):
        # ê°•ì œë¡œ .env ë‹¤ì‹œ ë¡œë“œ (ë””ë²„ê¹…ìš©)
        load_dotenv(override=True)
        
        self.client_id = os.getenv("NAVER_CLIENT_ID")
        self.client_secret = os.getenv("NAVER_CLIENT_SECRET")
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.request_delay = 0.1  # API ìš”ì²­ ê°„ê²© (ì´ˆ)
        
        # ë””ë²„ê¹…: ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ í‚¤ ì¶œë ¥
        print(f"ðŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (NaverNewsAPI ì´ˆê¸°í™”):")
        print(f"   .env íŒŒì¼ì—ì„œ ì½ì€ NAVER_CLIENT_ID: {self.client_id if self.client_id else 'âŒ None'}")
        print(f"   .env íŒŒì¼ì—ì„œ ì½ì€ NAVER_CLIENT_SECRET: {'***' + self.client_secret[-4:] if self.client_secret and len(self.client_secret) > 4 else 'âŒ None'}")
        
        # ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ ì¤‘ NAVERë¡œ ì‹œìž‘í•˜ëŠ” ê²ƒë“¤ ì¶œë ¥
        naver_vars = {k: v for k, v in os.environ.items() if 'NAVER' in k.upper()}
        if naver_vars:
            print(f"   í™˜ê²½ ë³€ìˆ˜ ì¤‘ NAVER ê´€ë ¨: {list(naver_vars.keys())}")
        else:
            print(f"   âš ï¸ í™˜ê²½ ë³€ìˆ˜ì— NAVER ê´€ë ¨ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        if not self.client_id or not self.client_secret:
            print("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (.env íŒŒì¼ì— NAVER_CLIENT_ID, NAVER_CLIENT_SECRET ì¶”ê°€ í•„ìš”)")
    
    def search_news(
        self, 
        query: str, 
        display: int = 10, 
        start: int = 1, 
        sort: str = "date"  # "date" ë˜ëŠ” "sim"
    ) -> List[Dict]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ì–´ (ì•½í’ˆëª… ë“±)
            display: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 100)
            start: ê²€ìƒ‰ ì‹œìž‘ ìœ„ì¹˜ (ìµœëŒ€ 1000)
            sort: ì •ë ¬ ë°©ì‹ ("date": ìµœì‹ ìˆœ, "sim": ì •í™•ë„ìˆœ)
        
        Returns:
            ë‰´ìŠ¤ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        # API í‚¤ í™•ì¸
        if not self.client_id or not self.client_secret:
            print("âŒ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print(f"   NAVER_CLIENT_ID: {'ì„¤ì •ë¨' if self.client_id else 'âŒ ì—†ìŒ'}")
            print(f"   NAVER_CLIENT_SECRET: {'ì„¤ì •ë¨' if self.client_secret else 'âŒ ì—†ìŒ'}")
            print("   .env íŒŒì¼ì— NAVER_CLIENT_IDì™€ NAVER_CLIENT_SECRETë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
            return []
        
        # ìºì‹œ í™•ì¸
        cache_key = f"naver_news_{query}_{display}_{start}_{sort}"
        cached_result = cache_manager.get_search_cache(cache_key, "naver_news")
        if cached_result is not None:
            print(f"ðŸ“‚ ë„¤ì´ë²„ ë‰´ìŠ¤ ìºì‹œ ížˆíŠ¸: {query}")
            return cached_result
        
        try:
            # API ìš”ì²­ í—¤ë”
            headers = {
                "X-Naver-Client-Id": self.client_id,
                "X-Naver-Client-Secret": self.client_secret
            }
            
            # íŒŒë¼ë¯¸í„°
            params = {
                "query": query,
                "display": min(display, 100),  # ìµœëŒ€ 100ê°œ
                "start": min(start, 1000),     # ìµœëŒ€ 1000
                "sort": sort
            }
            
            print(f"ðŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰: '{query}' (ì •ë ¬: {sort})")
            print(f"   URL: {self.base_url}")
            print(f"   íŒŒë¼ë¯¸í„°: {params}")
            
            # API í˜¸ì¶œ
            response = requests.get(
                self.base_url,
                headers=headers,
                params=params,
                timeout=10
            )
            
            print(f"   ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            # ê²°ê³¼ ê°€ê³µ
            processed_items = []
            for item in items:
                processed_item = {
                    "title": self._remove_html_tags(item.get("title", "")),
                    "original_link": item.get("originallink", ""),
                    "link": item.get("link", ""),
                    "description": self._remove_html_tags(item.get("description", "")),
                    "pub_date": item.get("pubDate", ""),
                    "pub_date_parsed": self._parse_date(item.get("pubDate", ""))
                }
                processed_items.append(processed_item)
            
            print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(processed_items)}ê±´")
            
            # ìºì‹œ ì €ìž¥
            cache_manager.save_search_cache(cache_key, "naver_news", processed_items)
            
            # API ìš”ì²­ ê°„ê²©
            time.sleep(self.request_delay)
            
            return processed_items
            
        except requests.exceptions.HTTPError as e:
            print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ API HTTP ì˜¤ë¥˜: {e}")
            print(f"   ì‘ë‹µ ë‚´ìš©: {e.response.text if hasattr(e, 'response') else 'N/A'}")
            if hasattr(e, 'response') and e.response.status_code == 403:
                print("   ðŸ’¡ 403 ì˜¤ë¥˜: ë„¤ì´ë²„ ê°œë°œìž ì„¼í„°ì—ì„œ 'ê²€ìƒ‰ API'ë¥¼ í™œì„±í™”í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            elif hasattr(e, 'response') and e.response.status_code == 401:
                print("   ðŸ’¡ 401 ì˜¤ë¥˜: Client ID ë˜ëŠ” Client Secretì´ ìž˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return []
        except requests.exceptions.RequestException as e:
            print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return []
        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def search_medicine_additional_info(
        self, 
        medicine_name: str, 
        ingredients: List[str] = None,
        max_results: int = 15
    ) -> Dict:
        """
        ì•½í’ˆ ê´€ë ¨ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ (ì‹ ì œí’ˆ, íŠ¸ë Œë“œ, ì´ìŠˆ ë“±)
        
        Args:
            medicine_name: ì•½í’ˆëª…
            ingredients: ì£¼ì„±ë¶„ ë¦¬ìŠ¤íŠ¸
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        
        Returns:
            {
                "medicine_news": [...],      # ì•½í’ˆ ì§ì ‘ ê´€ë ¨ ë‰´ìŠ¤
                "product_news": [...],       # ì‹ ì œí’ˆ/ì¶œì‹œ ê´€ë ¨
                "ingredient_news": [...],    # ì„±ë¶„ ê´€ë ¨ ë‰´ìŠ¤
                "trend_news": [...],         # íŠ¸ë Œë“œ/ì´ìŠˆ
                "total_count": int
            }
        """
        result = {
            "medicine_news": [],
            "product_news": [],
            "ingredient_news": [],
            "trend_news": [],
            "total_count": 0
        }
        
        try:
            # ðŸš€ ì„±ëŠ¥ ìµœì í™”: ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ê°ì†Œ
            print(f"ðŸ“° ì•½í’ˆ ìµœì‹  ì†Œì‹ ê²€ìƒ‰: {medicine_name}")
            medicine_news = self.search_news(
                query=medicine_name,
                display=min(max_results, 15),  # 100ê°œ â†’ 15ê°œë¡œ ê°ì†Œ
                sort="date"
            )
            
            # ì‹ ì œí’ˆ/ì¶œì‹œ ê´€ë ¨ í•„í„°ë§
            product_keywords = ["ì¶œì‹œ", "ì‹ ì œí’ˆ", "ìƒˆë¡œìš´", "ë¡ ì¹­", "ë¦¬ë‰´ì–¼", "íŒŒì›Œ", "í”ŒëŸ¬ìŠ¤"]
            for news in medicine_news[:10]:
                title_desc = (news.get("title", "") + " " + news.get("description", "")).lower()
                if any(keyword in title_desc for keyword in product_keywords):
                    result["product_news"].append(news)
                else:
                    result["medicine_news"].append(news)
            
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ (ë” ë§Žì´)
            result["medicine_news"] = result["medicine_news"][:8]  # 8ê°œë¡œ ì¦ê°€
            result["product_news"] = result["product_news"][:5]  # 5ê°œë¡œ ì¦ê°€
            
            # ðŸš€ ì„±ëŠ¥ ìµœì í™”: ì„±ë¶„ ê²€ìƒ‰ ìˆ˜ ê°ì†Œ (3ê°œ â†’ 2ê°œ, 10ê°œ â†’ 5ê°œ)
            if ingredients:
                for ingredient in ingredients[:2]:  # 3ê°œ â†’ 2ê°œ
                    print(f"ðŸ“° ì„±ë¶„ íŠ¸ë Œë“œ ê²€ìƒ‰: {ingredient}")
                    ingredient_news = self.search_news(
                        query=ingredient,
                        display=5,  # 10ê°œ â†’ 5ê°œ
                        sort="date"
                    )
                    
                    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ í•„í„°ë§
                    trend_keywords = ["íš¨ê³¼", "ì—°êµ¬", "ë°œê²¬", "ë°í˜€", "ë„ì›€", "ì˜ˆë°©", "ê°œì„ "]
                    for news in ingredient_news[:5]:
                        title_desc = (news.get("title", "") + " " + news.get("description", "")).lower()
                        if any(keyword in title_desc for keyword in trend_keywords):
                            result["trend_news"].append(news)
                        else:
                            result["ingredient_news"].append(news)
            
            # ìµœëŒ€ ê°œìˆ˜ ì œí•œ (ë” ë§Žì´)
            result["ingredient_news"] = result["ingredient_news"][:5]  # 5ê°œë¡œ ì¦ê°€
            result["trend_news"] = result["trend_news"][:5]  # 5ê°œë¡œ ì¦ê°€
            
            # ì¤‘ë³µ ì œê±°
            result = self._remove_duplicates(result)
            
            # ì´ ê°œìˆ˜
            result["total_count"] = (
                len(result["medicine_news"]) +
                len(result["product_news"]) +
                len(result["ingredient_news"]) +
                len(result["trend_news"])
            )
            
            print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ: ì´ {result['total_count']}ê±´")
            print(f"   - ì•½í’ˆ ë‰´ìŠ¤: {len(result['medicine_news'])}ê±´")
            print(f"   - ì‹ ì œí’ˆ ì •ë³´: {len(result['product_news'])}ê±´")
            print(f"   - ì„±ë¶„ ë‰´ìŠ¤: {len(result['ingredient_news'])}ê±´")
            print(f"   - íŠ¸ë Œë“œ ì •ë³´: {len(result['trend_news'])}ê±´")
            
        except Exception as e:
            print(f"âŒ ì•½í’ˆ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return result
    
    def _remove_html_tags(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±° (<b>, </b> ë“±)"""
        import re
        clean = re.compile('<.*?>')
        return re.sub(clean, '', text)
    
    def _parse_date(self, date_str: str) -> str:
        """ë‚ ì§œ íŒŒì‹± (RFC 2822 í˜•ì‹ â†’ ì½ê¸° ì‰¬ìš´ í˜•ì‹)"""
        try:
            from email.utils import parsedate_to_datetime
            dt = parsedate_to_datetime(date_str)
            return dt.strftime("%Y-%m-%d")
        except:
            return date_str
    
    def _remove_duplicates(self, result: Dict) -> Dict:
        """ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°"""
        seen_links = set()
        
        for category in ["medicine_news", "product_news", "ingredient_news", "trend_news"]:
            unique_items = []
            for item in result[category]:
                link = item.get("original_link") or item.get("link")
                if link not in seen_links:
                    seen_links.add(link)
                    unique_items.append(item)
            result[category] = unique_items
        
        return result
