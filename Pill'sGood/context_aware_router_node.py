from qa_state import QAState
from answer_utils import generate_response_llm_from_prompt
import json
import re

def extract_json_from_response(response: str) -> dict:
    """
    LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # ì§ì ‘ JSON íŒŒì‹± ì‹œë„
        return json.loads(response)
    except json.JSONDecodeError:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass
        
        # JSON í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        return analyze_response_by_keywords(response)

def analyze_response_by_keywords(response: str) -> dict:
    """
    LLM ì‘ë‹µì„ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë¼ìš°íŒ… ê²°ì •
    """
    response_lower = response.lower()
    
    # ë¼ìš°íŒ… ê²°ì •ì„ ìœ„í•œ í‚¤ì›Œë“œ ë§¤ì¹­
    if any(word in response_lower for word in ["ë¶€ì‘ìš©", "íš¨ëŠ¥", "íš¨ê³¼", "ì •ë³´"]):
        return {
            "routing_decision": "excel_search",
            "confidence": "medium",
            "reasoning": "í‚¤ì›Œë“œ ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰ ë¼ìš°íŒ…",
            "user_intent": "ì•½í’ˆ ì •ë³´ ìš”ì²­",
            "context_relevance": "ì •ë³´ ê²€ìƒ‰ ê´€ë ¨ ì§ˆë¬¸"
        }
    elif any(word in response_lower for word in ["ì—°êµ¬", "ë°ì´í„°", "ë¶„ì„", "ë…¼ë¬¸"]):
        return {
            "routing_decision": "pdf_search",
            "confidence": "medium",
            "reasoning": "í‚¤ì›Œë“œ ê¸°ë°˜ ì—°êµ¬ ìë£Œ ê²€ìƒ‰ ë¼ìš°íŒ…",
            "user_intent": "ì—°êµ¬ ìë£Œ ìš”ì²­",
            "context_relevance": "ì—°êµ¬ ìë£Œ ê´€ë ¨ ì§ˆë¬¸"
        }
    elif any(word in response_lower for word in ["ìµœì‹ ", "ì‹ ì•½", "2024", "2023", "FDA"]):
        return {
            "routing_decision": "external_search",
            "confidence": "medium",
            "reasoning": "í‚¤ì›Œë“œ ê¸°ë°˜ ìµœì‹  ì •ë³´ ê²€ìƒ‰ ë¼ìš°íŒ…",
            "user_intent": "ìµœì‹  ì •ë³´ ìš”ì²­",
            "context_relevance": "ìµœì‹  ì •ë³´ ê´€ë ¨ ì§ˆë¬¸"
        }
    else:
        return {
            "routing_decision": "excel_search",
            "confidence": "low",
            "reasoning": "í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ë¼ìš°íŒ…",
            "user_intent": "ì¼ë°˜ ì •ë³´ ìš”ì²­",
            "context_relevance": "ê¸°ë³¸ ì •ë³´ ê²€ìƒ‰"
        }

def context_aware_router_node(state: QAState) -> QAState:
    """
    LLMì´ ì§ì ‘ ë§¥ë½ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¥¼ ê²°ì •í•˜ëŠ” ë…¸ë“œ
    ìŠ¤ë§ˆíŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ìœ¼ë¡œ ì•ˆì •ì„±ê³¼ ì •í™•ì„±ì„ ëª¨ë‘ í™•ë³´
    """
    print("ğŸ§  ë§¥ë½ ì¸ì‹ ë¼ìš°í„° ë…¸ë“œ ì‹œì‘")
    
    # í˜„ì¬ ì§ˆë¬¸ê³¼ ëŒ€í™” ë§¥ë½ ìˆ˜ì§‘
    current_query = state.get("query", "")
    conversation_context = state.get("conversation_context", "")
    user_context = state.get("user_context", "")
    category = state.get("category", "")
    
    # 1ì°¨: ë¹ ë¥¸ íŒ¨í„´ ë§¤ì¹­ (í•˜ë“œì½”ë”©)
    print("ğŸ” 1ì°¨: ë¹ ë¥¸ íŒ¨í„´ ë§¤ì¹­ ì‹œì‘")
    pattern_result = quick_pattern_analysis(current_query, category)
    
    if pattern_result['confidence'] == 'high':
        print("âœ… ë†’ì€ ì‹ ë¢°ë„ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬")
        state.update(pattern_result)
        return state
    
    # 2ì°¨: LLM ë§¥ë½ ë¶„ì„
    print("ğŸ§  2ì°¨: LLM ë§¥ë½ ë¶„ì„ ì‹œì‘")
    llm_result = llm_context_analysis(current_query, conversation_context, user_context, category)
    
    # 3ì°¨: ê²°ê³¼ ë¹„êµ ë° ìµœì¢… ê²°ì •
    final_decision = compare_and_decide(pattern_result, llm_result)
    
    print(f"ğŸ“Š ìµœì¢… ë¼ìš°íŒ… ê²°ì •:")
    print(f"  - ê²½ë¡œ: {final_decision['route']}")
    print(f"  - ì‹ ë¢°ë„: {final_decision['confidence']}")
    print(f"  - ë°©ë²•: {final_decision['method']}")
    print(f"  - íŒë‹¨ ê·¼ê±°: {final_decision.get('reasoning', '')}")
    
    # ìƒíƒœì— ìµœì¢… ê²°ì • ì €ì¥
    state.update(final_decision)
    
    return state

def quick_pattern_analysis(query: str, category: str) -> dict:
    """
    1ì°¨ í•„í„°ë§: ë¹ ë¥¸ íŒ¨í„´ ë§¤ì¹­ (í•˜ë“œì½”ë”©)
    """
    query_lower = query.lower()
    
    # ëª…í™•í•œ íŒ¨í„´ë“¤ (í•˜ë“œì½”ë”©)
    patterns = {
        "excel_search": [
            "ë¶€ì‘ìš©", "íš¨ëŠ¥", "íš¨ê³¼", "ì„±ë¶„", "ê°€ê²©", "ì œì¡°ì‚¬", "ë³´í—˜", "ê¸‰ì—¬",
            "ë³µìš©", "íˆ¬ì—¬", "ì„­ì·¨", "ë¨¹ëŠ”ë²•", "ì•½ë¬¼", "ì•½í’ˆ", "ì •ë³´", "ì•Œë ¤ì¤˜",
            "ì‚¬ìš©", "ë³µìš©ë²•", "ìš©ë²•", "ì–´ë–»ê²Œ"
        ],
        "pdf_search": [
            "ì—°êµ¬", "ë…¼ë¬¸", "ì„ìƒ", "ì‹œí—˜", "ë°ì´í„°", "í†µê³„", "ë¶„ì„", "ê²°ê³¼",
            "ë³´ê³ ì„œ", "ë¬¸ì„œ", "ìë£Œ", "ë…¼ë¬¸", "ì—°êµ¬ê²°ê³¼"
        ],
        "external_search": [
            "ìµœì‹ ", "ì‹ ì•½", "2024", "2023", "FDA", "ìŠ¹ì¸", "ì‹œíŒ", "ì¶œì‹œ",
            "ë‰´ìŠ¤", "ì†Œì‹", "ì—…ë°ì´íŠ¸", "ë³€ê²½", "ìƒˆë¡œìš´", "ìµœê·¼"
        ]
    }
    
    # íŒ¨í„´ ë§¤ì¹­
    for route, keywords in patterns.items():
        for keyword in keywords:
            if keyword in query_lower:
                return {
                    "route": route,
                    "confidence": "high",
                    "method": "pattern_matching",
                    "matched_keyword": keyword,
                    "routing_decision": route,
                    "reasoning": f"í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­"
                }
    
    # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê¸°ë³¸ ë¼ìš°íŒ…
    if category:
        category_mapping = {
            "ì •ë³´": "excel_search", 
            "ì—°êµ¬": "pdf_search",
            "ìµœì‹ ": "external_search"
        }
        if category in category_mapping:
            return {
                "route": category_mapping[category],
                "confidence": "medium",
                "method": "category_based",
                "matched_category": category,
                "routing_decision": category_mapping[category],
                "reasoning": f"ì¹´í…Œê³ ë¦¬ '{category}' ê¸°ë°˜ ë¼ìš°íŒ…"
            }
    
    return {
        "route": "excel_search",
        "confidence": "low",
        "method": "default",
        "reason": "íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨",
        "routing_decision": "excel_search",
        "reasoning": "ê¸°ë³¸ ë¼ìš°íŒ…"
    }

def llm_context_analysis(query: str, context: str, user_context: str, category: str) -> dict:
    """
    2ì°¨ ë¶„ì„: LLM ê¸°ë°˜ ë§¥ë½ ì´í•´ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    """
    max_retries = 2
    
    for attempt in range(max_retries):
        try:
            print(f"ğŸ§  LLM ë§¥ë½ ë¶„ì„ ì‹œë„ {attempt + 1}/{max_retries}")
            
            context_prompt = f"""
ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ìƒë‹´ ì‹œìŠ¤í…œì˜ ë¼ìš°íŒ… ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¥¼ ê²°ì •í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì§ˆë¬¸:**
{query}

**ëŒ€í™” ë§¥ë½:**
{context[:500] if context else "ì—†ìŒ"}

**ì‚¬ìš©ì ë§¥ë½:**
{user_context[:300] if user_context else "ì—†ìŒ"}

**ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬:**
{category if category else "ë¯¸ë¶„ë¥˜"}

**ì²˜ë¦¬ ê²½ë¡œ ì˜µì…˜:**
1. "excel_search" - ì•½í’ˆ ì •ë³´, ë¶€ì‘ìš©, íš¨ëŠ¥ ë“± ê¸°ë³¸ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°  
2. "pdf_search" - ì—°êµ¬ ìë£Œ, ì„ìƒ ë°ì´í„°, ìƒì„¸ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš°
3. "external_search" - ìµœì‹  ì •ë³´, ì‹ ì•½, ì™¸ë¶€ ì†Œì‹ì´ í•„ìš”í•œ ê²½ìš°

**ë¶„ì„ ê¸°ì¤€:**
- ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ì˜ë„ íŒŒì•…
- ì´ì „ ëŒ€í™”ì™€ì˜ ì—°ê´€ì„±
- í•„ìš”í•œ ì •ë³´ì˜ ì¢…ë¥˜ì™€ ê¹Šì´
- ë§¥ë½ì  ì´í•´

**ì¤‘ìš”:** ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

JSON í˜•ì‹:
{{
    "routing_decision": "ì²˜ë¦¬_ê²½ë¡œ",
    "confidence": "high/medium/low",
    "reasoning": "íŒë‹¨ ê·¼ê±°",
    "user_intent": "ì‚¬ìš©ì ì˜ë„",
    "context_relevance": "ë§¥ë½ ê´€ë ¨ì„±"
}}
"""
            
            response = generate_response_llm_from_prompt(
                prompt=context_prompt,
                temperature=0.1,
                max_tokens=400
            )
            
            # JSON íŒŒì‹± ì‹œë„
            result = extract_json_from_response(response)
            
            if result and "routing_decision" in result:
                print("âœ… LLM ë§¥ë½ ë¶„ì„ ì„±ê³µ")
                return {
                    "route": result.get("routing_decision", "excel_search"),
                    "confidence": result.get("confidence", "medium"),
                    "method": "llm_analysis",
                    "reasoning": result.get("reasoning", ""),
                    "user_intent": result.get("user_intent", ""),
                    "context_relevance": result.get("context_relevance", ""),
                    "routing_decision": result.get("routing_decision", "excel_search")
                }
            else:
                print(f"âš ï¸ LLM ì‘ë‹µì—ì„œ ìœ íš¨í•œ ë¼ìš°íŒ… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ì‹œë„ {attempt + 1})")
                
        except Exception as e:
            print(f"âŒ LLM ë§¥ë½ ë¶„ì„ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ í´ë°±
    print("ğŸ”„ ëª¨ë“  LLM ë¶„ì„ ì‹œë„ ì‹¤íŒ¨, í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©")
    return llm_fallback_analysis(query, context, user_context, category)

def llm_fallback_analysis(query: str, context: str, user_context: str, category: str) -> dict:
    """
    LLM ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°± ë¶„ì„
    """
    print("ğŸ”„ í´ë°± ë¶„ì„ ì‹œìŠ¤í…œ ì‹¤í–‰")
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
    query_lower = query.lower()
    
    if any(word in query_lower for word in ["ë¶€ì‘ìš©", "íš¨ëŠ¥", "ì •ë³´", "ì•Œë ¤ì¤˜"]):
        return {
            "route": "excel_search",
            "confidence": "low",
            "method": "fallback",
            "routing_decision": "excel_search",
            "reasoning": "í´ë°± í‚¤ì›Œë“œ ë¶„ì„"
        }
    elif any(word in query_lower for word in ["ì—°êµ¬", "ë°ì´í„°", "ë¶„ì„", "ë…¼ë¬¸"]):
        return {
            "route": "pdf_search",
            "confidence": "low",
            "method": "fallback",
            "routing_decision": "pdf_search",
            "reasoning": "í´ë°± í‚¤ì›Œë“œ ë¶„ì„"
        }
    else:
        return {
            "route": "excel_search",
            "confidence": "low",
            "method": "fallback",
            "routing_decision": "excel_search",
            "reasoning": "í´ë°± ê¸°ë³¸ê°’"
        }

def compare_and_decide(pattern_result: dict, llm_result: dict) -> dict:
    """
    íŒ¨í„´ ë§¤ì¹­ê³¼ LLM ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì¢… ê²°ì •
    """
    print("âš–ï¸ ê²°ê³¼ ë¹„êµ ë° ìµœì¢… ê²°ì •")
    
    # ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ê³„ì‚°
    confidence_weights = {"high": 3, "medium": 2, "low": 1}
    
    pattern_score = confidence_weights.get(pattern_result.get("confidence", "low"), 1)
    llm_score = confidence_weights.get(llm_result.get("confidence", "low"), 1)
    
    print(f"ğŸ“Š ì ìˆ˜ ë¹„êµ:")
    print(f"  - íŒ¨í„´ ë§¤ì¹­: {pattern_score}ì  ({pattern_result.get('confidence', 'low')})")
    print(f"  - LLM ë¶„ì„: {llm_score}ì  ({llm_result.get('confidence', 'low')})")
    
    # ë” ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê²°ê³¼ ì„ íƒ
    if pattern_score >= llm_score:
        print("âœ… íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼ ì„ íƒ")
        return pattern_result
    else:
        print("âœ… LLM ë¶„ì„ ê²°ê³¼ ì„ íƒ")
        return llm_result
