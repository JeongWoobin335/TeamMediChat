from qa_state import QAState
from retrievers import compressor  # CrossEncoder ê¸°ë°˜ ë¬¸ì„œ ì••ì¶•ê¸°
from langchain_core.documents import Document
from typing import List
from answer_utils import generate_response_llm_from_prompt
import re
import json

def normalize(text: str) -> str:
    text = re.sub(r"\(.*?\)", "", text)
    text = re.sub(r"[^\wê°€-í£]", "", text)
    return re.sub(r"\s+", "", text.strip().lower())

def contains_product_name(doc: Document, product_name: str) -> bool:
    return normalize(product_name) == normalize(doc.metadata.get("ì œí’ˆëª…", ""))

def rerank_node(state: QAState) -> QAState:
    """
    ì›ë˜ ì‹œìŠ¤í…œì˜ ë¦¬ë­í‚¹ ë…¸ë“œ
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒ
    """
    print("ğŸ”„ ë¦¬ë­í‚¹ ë…¸ë“œ ì‹œì‘")
    
    all_docs: List[Document] = []
    if state.get("pdf_results"):
        all_docs.extend(state["pdf_results"])
    if state.get("excel_results"):
        all_docs.extend(state["excel_results"])
    if state.get("sns_results"):
        all_docs.extend(state["sns_results"])

    if not all_docs:
        print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒ")
        state["reranked_docs"] = []
        state["relevant_docs"] = []
        return state

    try:
        query = state.get("query", "")
        product_name = state.get("normalized_query") or state.get("cleaned_query")
        product_name = normalize(product_name or "")

        # ì œí’ˆëª… ê¸°ë°˜ í•„í„°ë§ (í•˜ë“œì½”ë”©)
        excel_docs = state.get("excel_results", [])
        excel_matched = [doc for doc in excel_docs if contains_product_name(doc, product_name)]

        if excel_matched:
            print("âœ… ì œí’ˆëª… ê¸°ë°˜ ë§¤ì¹­ ì„±ê³µ")
            state["relevant_docs"] = excel_matched[:3]
            state["reranked_docs"] = []
            return state

        # ì „ì²´ ë¬¸ì„œ ë¦¬ë­í‚¹
        print("ğŸ”„ ì „ì²´ ë¬¸ì„œ ë¦¬ë­í‚¹ ì‹¤í–‰")
        reranked = compressor.compress_documents(all_docs, query=query)
        state["reranked_docs"] = reranked

        # ì œí’ˆëª… ê¸°ë°˜ ì¶”ê°€ í•„í„°ë§
        filtered = [doc for doc in reranked if contains_product_name(doc, product_name)]

        if filtered:
            # ì¤‘ë³µ ì œê±°
            deduped = []
            seen = set()
            for doc in filtered + reranked:
                key = doc.page_content[:100]
                if key not in seen:
                    deduped.append(doc)
                    seen.add(key)
                if len(deduped) >= 3:
                    break
            state["relevant_docs"] = deduped
        else:
            state["relevant_docs"] = reranked[:3]

        print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ: {len(state['relevant_docs'])}ê°œ ë¬¸ì„œ")

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        state["reranked_docs"] = []
        state["relevant_docs"] = []

    return state
