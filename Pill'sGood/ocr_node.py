# ocr_node.py
import cv2
import numpy as np
from PIL import Image
import io
import re
from typing import Optional, Tuple, List
from qa_state import QAState
from answer_utils import generate_response_llm_from_prompt
from difflib import get_close_matches
from retrievers import excel_docs

# EasyOCR import
try:
    import easyocr
    EASYOCR_AVAILABLE = True
    print("âœ… EasyOCR ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    EASYOCR_AVAILABLE = False
    print("âŒ EasyOCR ì‚¬ìš© ë¶ˆê°€ - ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

def preprocess_image(image_data: bytes) -> np.ndarray:
    """
    ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
    - íšŒì „ ë³´ì •
    - ë…¸ì´ì¦ˆ ì œê±°
    - ëŒ€ë¹„ í–¥ìƒ
    """
    try:
        # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(image_data))
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ë° ë¦¬ì‚¬ì´ì¦ˆ
        width, height = image.size
        print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}")
        
        # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ëŠ” í™•ëŒ€
        if width < 300 or height < 300:
            scale_factor = max(300/width, 300/height)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            print(f"ğŸ“ ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ í¬ê¸°: {new_width}x{new_height}")
        
        # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # RGBë¥¼ BGRë¡œ ë³€í™˜ (OpenCVëŠ” BGR ì‚¬ìš©)
        if len(img_array.shape) == 3:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        
        # ê°„ë‹¨í•œ ì „ì²˜ë¦¬
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.medianBlur(gray, 3)
        
        # ëŒ€ë¹„ í–¥ìƒ
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        # ê°„ë‹¨í•œ ì´ì§„í™”
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def extract_text_from_image(image_data: bytes) -> str:
    """
    ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì¤‘ OCR ì—”ì§„ + ROI ê¸°ë°˜ ì²˜ë¦¬)
    """
    try:
        # ì›ë³¸ ì´ë¯¸ì§€ ì§ì ‘ ì‚¬ìš©
        image = Image.open(io.BytesIO(image_data))
        print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {image.size[0]}x{image.size[1]}")
        
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ëŒ€ (OCR ì •í™•ë„ í–¥ìƒ)
        if image.size[0] < 2000 or image.size[1] < 2000:
            scale_factor = max(2000/image.size[0], 2000/image.size[1])
            new_size = (int(image.size[0] * scale_factor), int(image.size[1] * scale_factor))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
            print(f"ğŸ”„ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {new_size}")
        
        # OpenCVë¡œ ë³€í™˜
        img_array = np.array(image)
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # ëŒ€ë¹„í–¥ìƒ ë°©ë²•ë§Œ ì‚¬ìš© (ê°€ì¥ ì •í™•í•œ ê²°ê³¼)
        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray)
        
        print("âœ… ëŒ€ë¹„í–¥ìƒ ì „ì²˜ë¦¬ ì™„ë£Œ")
        
        # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = ""
        
        if EASYOCR_AVAILABLE:
            try:
                print("ğŸ” EasyOCRë¡œ ì‹œë„...")
                reader = easyocr.Reader(['ko', 'en'], gpu=False)
                result = reader.readtext(enhanced)
                
                if result:
                    texts = []
                    for (bbox, text, confidence) in result:
                        if confidence > 0.2:  # ì‹ ë¢°ë„ 20% ì´ìƒ
                            texts.append(text)
                            print(f"  ğŸ” EasyOCR: '{text}' (ì‹ ë¢°ë„: {confidence:.2f})")
                    
                    if texts:
                        text = ' '.join(texts)
                        print(f"âœ… EasyOCR ê²°ê³¼: '{text}'")
                    else:
                        print("âš ï¸ EasyOCRì—ì„œ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²°ê³¼ë§Œ ë°œê²¬ë¨")
                else:
                    print("âš ï¸ EasyOCRì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        
            except Exception as e:
                print(f"âŒ EasyOCR ì˜¤ë¥˜: {e}")
        else:
            print("âŒ EasyOCRì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        if not text.strip():
            print("âŒ OCR ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        cleaned_text = clean_extracted_text(text)
        
        # ì¡°ì‚¬ ì œê±° (ì •ê·œì‹ ê¸°ë°˜)
        if cleaned_text:
            # í•œê¸€ ì¡°ì‚¬ ì œê±°
            cleaned_text = re.sub(r'[ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì˜ì™€ê³¼ë„ë¶€í„°ê¹Œì§€ì—ì„œë¶€í„°]$', '', cleaned_text)
            # ì—°ì†ëœ ê³µë°± ì œê±°
            cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
            print(f"ğŸ” ì¡°ì‚¬ ì œê±° í›„ OCR ê²°ê³¼: '{cleaned_text}'")
        
        print(f"ğŸ” ìµœì¢… OCR ê²°ê³¼: '{cleaned_text}'")
        
        if not cleaned_text.strip():
            print("âŒ ëª¨ë“  OCR ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            return ""
        
        return cleaned_text
        
    except Exception as e:
        print(f"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

def clean_extracted_text(text: str) -> str:
    """
    OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ì œ
    """
    if not text:
        return ""
    
    # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
    text = re.sub(r'[^\wê°€-í£\s\-\.]', ' ', text)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    
    # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
    text = text.replace('\n', ' ')
    
    return text.strip()

def normalize_medicine_name(name: str) -> str:
    """
    ì•½í’ˆëª… ì •ê·œí™” (ìœ ì‚¬ë„ ë§¤ì¹­ì„ ìœ„í•´)
    """
    if not name:
        return ""
    
    # ì†Œë¬¸ì ë³€í™˜
    normalized = name.lower()
    
    # íŠ¹ìˆ˜ë¬¸ì, ê³µë°±, ìˆ«ì ì œê±° (í•œê¸€ê³¼ ì˜ë¬¸ë§Œ ìœ ì§€)
    normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    normalized = re.sub(r'\s+', '', normalized)
    
    return normalized.strip()

def calculate_similarity(str1: str, str2: str) -> float:
    """
    ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    """
    if not str1 or not str2:
        return 0.0
    
    if str1 == str2:
        return 1.0
    
    # ê¸¸ì´ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ
    len_diff = abs(len(str1) - len(str2))
    if len_diff > max(len(str1), len(str2)) * 0.5:
        return 0.0
    
    # Levenshtein distance ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    distance = levenshtein_distance(str1, str2)
    max_len = max(len(str1), len(str2))
    similarity = 1.0 - (distance / max_len)
    
    return similarity

def find_similar_medicine_name(ocr_result: str, medicine_list: List[str], cutoff: float = 0.8) -> Optional[str]:
    """
    OCR ê²°ê³¼ì™€ ìœ ì‚¬í•œ ì•½í’ˆëª… ì°¾ê¸°
    """
    if not ocr_result or not medicine_list:
        return None
    
    # OCR ê²°ê³¼ ì •ê·œí™”
    normalized_ocr = normalize_medicine_name(ocr_result)
    print(f"ğŸ” ì •ê·œí™”ëœ OCR ê²°ê³¼: '{normalized_ocr}'")
    
    # ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ë„ ì •ê·œí™”
    normalized_medicines = [(normalize_medicine_name(med), med) for med in medicine_list]
    
    
    # ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
    best_match = None
    best_similarity = 0.0
    
    for norm, orig in normalized_medicines:
        similarity = calculate_similarity(normalized_ocr, norm)
        
        # ìœ ì‚¬ë„ê°€ ë†’ì€ ê²½ìš°ë§Œ ë¡œê·¸ ì¶œë ¥ (ì„±ëŠ¥ ê°œì„ )
        if similarity > 0.3:
            print(f"ğŸ” '{orig}' ìœ ì‚¬ë„: {similarity:.3f}")
        
        if similarity > best_similarity and similarity >= cutoff:
            best_similarity = similarity
            best_match = orig
    
    if best_match:
        print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
        return best_match
    
    # cutoffë¥¼ ë‚®ì¶°ì„œ ë‹¤ì‹œ ì‹œë„
    if cutoff > 0.5:
        print(f"ğŸ” cutoffë¥¼ ë‚®ì¶°ì„œ ì¬ì‹œë„ (0.5)")
        for norm, orig in normalized_medicines:
            similarity = calculate_similarity(normalized_ocr, norm)
            if similarity > best_similarity and similarity >= 0.5:
                best_similarity = similarity
                best_match = orig
        
        if best_match:
            print(f"âœ… ë‚®ì€ cutoff ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
            return best_match
    
    print(f"âŒ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨: '{ocr_result}' (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.3f})")
    return None

def extract_medicine_name_from_text(text: str) -> str:
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ (íŒ¨í„´ ë§¤ì¹­ + ìœ ì‚¬ë„ ë§¤ì¹­ + LLM ê¸°ë°˜)
    """
    if not text:
        return ""
    
    # Excel DBì—ì„œ ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    medicine_list = []
    try:
        for doc in excel_docs:
            product_name = doc.metadata.get("ì œí’ˆëª…", "")
            if product_name and product_name not in medicine_list:
                medicine_list.append(product_name)
        print(f"ğŸ“Š Excel DBì—ì„œ {len(medicine_list)}ê°œ ì•½í’ˆëª… ë¡œë“œ")
    except Exception as e:
        print(f"âš ï¸ Excel DB ë¡œë“œ ì‹¤íŒ¨: {e}")
        medicine_list = []
    
    # ë¨¼ì € íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì•½í’ˆëª… ì°¾ê¸° (ë” í¬ê´„ì ìœ¼ë¡œ)
    medicine_patterns = [
        # êµ¬ì²´ì ì¸ ì•½í’ˆëª… íŒ¨í„´ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        r'([ê°€-í£]{2,10})\s*(ì—°ê³ |í¬ë¦¼|ì ¤|ì •|ìº¡ìŠ|ì‹œëŸ½|ì£¼ì‚¬|ì•¡|ë¶„ë§|ê°€ë£¨)',
        r'([ê°€-í£]{2,10})\s*(3ì¤‘|ë³µí•©|ì²˜ë°©)',
        r'([ê°€-í£]{2,10})\s*(ì¼ë°˜ì˜ì•½í’ˆ|ì²˜ë°©ì•½)',
        r'([ê°€-í£]{2,10})\s*(ì¹˜ë£Œ|ê°ì—¼|ì˜ˆë°©)',
        r'([ê°€-í£]{2,10})\s*(ì™¸ìƒ|ìƒì²˜|í™”ìƒ)',
        r'([ê°€-í£]{2,10})\s*(10g|20g|30g|50g|100g)',
        r'([ê°€-í£]{2,10})\s*(mg|g|ml)',
        
        # ì¼ë°˜ì ì¸ í•œê¸€ íŒ¨í„´
        r'([ê°€-í£]{2,10})\s*[0-9]',  # í•œê¸€ + ìˆ«ì
        r'([ê°€-í£]{2,10})\s*[a-zA-Z]',  # í•œê¸€ + ì˜ë¬¸
        r'([ê°€-í£]{2,10})',  # ë‹¨ìˆœíˆ í•œê¸€ 2-10ì
        
        # ë” ë„“ì€ ë²”ìœ„ì˜ í•œê¸€ íŒ¨í„´
        r'([ê°€-í£]{1,15})',  # í•œê¸€ 1-15ì (ë” ë„“ê²Œ)
        
        # íŠ¹ìˆ˜ ë¬¸ì í¬í•¨ íŒ¨í„´
        r'([ê°€-í£]{2,10})[^\w\s]',  # í•œê¸€ + íŠ¹ìˆ˜ë¬¸ì
        r'[^\w\s]([ê°€-í£]{2,10})',  # íŠ¹ìˆ˜ë¬¸ì + í•œê¸€
    ]
    
    # ì œì™¸í•  ë‹¨ì–´ë“¤ (ì•½í’ˆëª…ì´ ì•„ë‹Œ ê²ƒë“¤) - ê¸°ë³¸ ë‹¨ì–´ë§Œ
    exclude_words = [
        'ì•½í•™ì •ë³´ì›', 'ì •ë³´ì›', 'ì•½í•™', 'ì •ë³´', 'ì›', 'ì¹˜ë£Œ', 'ì˜ˆë°©', 'ê°ì—¼', 'ì™¸ìƒ', 'ìƒì²˜', 'í™”ìƒ',
        'ë³µí•©', 'ì²˜ë°©', 'ì¼ë°˜ì˜ì•½í’ˆ', 'ì²˜ë°©ì•½', 'ë°', 'ì˜', 'ì™€', 'ê³¼', 'ì„', 'ë¥¼', 'ì´', 'ê°€',
        '3ì¤‘', '2ì°¨', '10g', '20g', '30g', '50g', '100g', 'mg', 'g', 'ml', 'KPIC'
    ]
    
    # ì œì™¸í•  íŒ¨í„´ë“¤ (í•˜ë“œì½”ë”© ëŒ€ì‹  íŒ¨í„´ ë§¤ì¹­)
    exclude_patterns = [
        r'.*ë³µí•©.*ì²˜ë°©.*',  # "3ì¤‘ë³µí•©ì²˜ë°©ì˜", "ì¤‘ë³µí•©ì „ë°©ì˜" ë“±
        r'.*ë³µí•©.*ì „ë°©.*',  # "3ì¤‘ë³µí•©ì „ë°©ì˜" ë“±  
        r'.*ì¤‘ë³µ.*',        # "ì¤‘ë³µ"ì´ í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´
        r'.*ì²˜ë°©.*',        # "ì²˜ë°©"ì´ í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´
        r'.*ì „ë°©.*',        # "ì „ë°©"ì´ í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´
        r'.*ë³µí•©.*',        # "ë³µí•©"ì´ í¬í•¨ëœ ëª¨ë“  ë‹¨ì–´
        r'^\d+$',           # ìˆ«ìë§Œ ìˆëŠ” ë‹¨ì–´ (8, 10 ë“±)
        r'.*ì •ë³´ì›.*',      # "ì•½í•™ì •ë³´ì›" ë“±
        r'.*ì¹˜ë£Œ.*',        # "ì¹˜ë£Œ" ê´€ë ¨ ë‹¨ì–´
        r'.*ê°ì—¼.*',        # "ê°ì—¼" ê´€ë ¨ ë‹¨ì–´
    ]
    
    
    print(f"ğŸ” ì•½í’ˆëª… ì¶”ì¶œ ì‹œë„ - ì…ë ¥ í…ìŠ¤íŠ¸: '{text}'")
    
    # ì¼ë°˜ì ì¸ ì•½í’ˆëª… íŒ¨í„´ ìš°ì„  ê²€ìƒ‰ (í˜•íƒœ í¬í•¨)
    common_medicine_patterns = [
        r'([ê°€-í£]{2,8})\s*(ì—°ê³ |í¬ë¦¼|ì ¤)',  # ì—°ê³ ë¥˜
        r'([ê°€-í£]{2,8})\s*(ì •|ìº¡ìŠ)',      # ì •ì œ/ìº¡ìŠë¥˜
        r'([ê°€-í£]{2,8})\s*(ì‹œëŸ½|ì•¡)',      # ì•¡ì²´ë¥˜
        r'([ê°€-í£]{2,8})\s*(ì£¼ì‚¬|ì£¼)',      # ì£¼ì‚¬ì œ
        r'([ê°€-í£]{2,8})\s*(ë¶„ë§|ê°€ë£¨)',    # ë¶„ë§ë¥˜
    ]
    
    # êµ¬ì²´ì ì¸ ì•½í’ˆëª… íŒ¨í„´ ë¨¼ì € ê²€ìƒ‰ (í˜•íƒœ í¬í•¨)
    for pattern in common_medicine_patterns:
        matches = re.findall(pattern, text)
        if matches:
            # ê°€ì¥ ê¸´ ì•½í’ˆëª… ì„ íƒ (í˜•íƒœ í¬í•¨)
            best_match = max(matches, key=lambda x: len(x[0]))
            medicine_name = f"{best_match[0]}{best_match[1]}"  # ì•½í’ˆëª… + í˜•íƒœ
            if best_match[0] not in exclude_words and len(best_match[0]) >= 2:
                print(f"ğŸ” ì•½í’ˆëª… íŒ¨í„´ìœ¼ë¡œ ë°œê²¬: '{medicine_name}' (íŒ¨í„´: {pattern})")
                # íŒ¨í„´ ë§¤ì¹­ ì„±ê³µ í›„ì—ë„ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
                if medicine_list:
                    similar_medicine = find_similar_medicine_name(medicine_name, medicine_list, cutoff=0.8)
                    if similar_medicine:
                        print(f"âœ… íŒ¨í„´ ë§¤ì¹­ í›„ ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{medicine_name}' â†’ '{similar_medicine}'")
                        return similar_medicine
                return medicine_name
    
    # ìŠ¤ë§ˆíŠ¸í•œ ì•½í’ˆëª… ì„ íƒ (íŒ¨í„´ ê¸°ë°˜ í•„í„°ë§)
    # OCR ê²°ê³¼ì—ì„œ í•œê¸€ ë‹¨ì–´ë“¤ì„ ì¶”ì¶œí•˜ê³  ì ìˆ˜ ê³„ì‚°
    korean_words = re.findall(r'[ê°€-í£]{2,10}', text)
    if korean_words:
        # ì œì™¸ ë‹¨ì–´ì™€ íŒ¨í„´ í•„í„°ë§
        valid_words = []
        for word in korean_words:
            # ê¸°ë³¸ ì œì™¸ ë‹¨ì–´ ì²´í¬
            if word in exclude_words:
                print(f"ğŸ” ì œì™¸ ë‹¨ì–´: '{word}' (ê¸°ë³¸ ì œì™¸ ëª©ë¡)")
                continue
            
            # íŒ¨í„´ ê¸°ë°˜ ì œì™¸ ì²´í¬
            is_excluded = False
            for pattern in exclude_patterns:
                if re.match(pattern, word):
                    print(f"ğŸ” ì œì™¸ ë‹¨ì–´: '{word}' (íŒ¨í„´: {pattern})")
                    is_excluded = True
                    break
            
            if not is_excluded and len(word) >= 2:
                valid_words.append(word)
        
        if valid_words:
            # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
            scored_words = []
            for word in valid_words:
                score = len(word)  # ê¸°ë³¸ ì ìˆ˜: ê¸¸ì´ë§Œ ê³ ë ¤
                scored_words.append((word, score))
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì•½í’ˆëª… ì„ íƒ
            scored_words.sort(key=lambda x: x[1], reverse=True)
            best_word = scored_words[0][0]
            print(f"ğŸ” ìŠ¤ë§ˆíŠ¸ ì„ íƒ: '{best_word}' (ì ìˆ˜: {scored_words[0][1]})")
            
            # ìŠ¤ë§ˆíŠ¸ ì„ íƒ í›„ì—ë„ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
            if medicine_list:
                similar_medicine = find_similar_medicine_name(best_word, medicine_list, cutoff=0.8)
                if similar_medicine:
                    print(f"âœ… ìŠ¤ë§ˆíŠ¸ ì„ íƒ í›„ ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{best_word}' â†’ '{similar_medicine}'")
                    return similar_medicine
            
            return best_word
    
    # ì •ê·œì‹ ê¸°ë°˜ ì¡°ì‚¬ ì œê±°ëŠ” route_question_nodeì—ì„œ ì²˜ë¦¬
    
    # OCR ì˜¤íƒ€ ìˆ˜ì • ì œê±° - í•˜ë“œì½”ë”© ë°©ì‹ì€ í™•ì¥ì„± ì—†ìŒ
    
    # í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ê¸´ í•œê¸€ ë‹¨ì–´ ì°¾ê¸° (ì•½í’ˆëª… í›„ë³´)
    korean_words = re.findall(r'[ê°€-í£]{2,10}', text)
    if korean_words:
        # ì œì™¸ ë‹¨ì–´ê°€ ì•„ë‹Œ ê°€ì¥ ê¸´ ë‹¨ì–´ ì„ íƒ
        valid_words = [word for word in korean_words if word not in exclude_words and len(word) >= 2]
        if valid_words:
            medicine_name = max(valid_words, key=len)
            print(f"ğŸ” ê°€ì¥ ê¸´ í•œê¸€ ë‹¨ì–´ë¡œ ì•½í’ˆëª… ì¶”ì •: '{medicine_name}'")
            return medicine_name
    
    for i, pattern in enumerate(medicine_patterns):
        matches = re.findall(pattern, text)
        if matches:
            # ê°€ì¥ ê¸´ ì•½í’ˆëª… ì„ íƒ
            medicine_name = max(matches, key=lambda x: len(x[0]))[0]
            
            # ì œì™¸ ë‹¨ì–´ì— í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ ì„ íƒ
            if medicine_name not in exclude_words and len(medicine_name) >= 2:
                print(f"ğŸ” íŒ¨í„´ {i+1} ë§¤ì¹­ìœ¼ë¡œ ì•½í’ˆëª… ë°œê²¬: '{medicine_name}' (íŒ¨í„´: {pattern})")
                return medicine_name
            else:
                print(f"ğŸ” íŒ¨í„´ {i+1} ë§¤ì¹­ ê²°ê³¼ ì œì™¸: '{medicine_name}' (ì œì™¸ ë‹¨ì–´ ë˜ëŠ” ë„ˆë¬´ ì§§ìŒ)")
        else:
            print(f"ğŸ” íŒ¨í„´ {i+1} ë§¤ì¹­ ì‹¤íŒ¨ (íŒ¨í„´: {pattern})")
    
    # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
    if medicine_list:
        print("ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ì•½í’ˆëª… ë§¤ì¹­ ì‹œë„...")
        
        # ì¶”ì¶œëœ í•œê¸€ ë‹¨ì–´ë“¤ë¡œ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
        korean_words = re.findall(r'[ê°€-í£]{2,10}', text)
        for word in korean_words:
            if word not in exclude_words and len(word) >= 2:
                similar_medicine = find_similar_medicine_name(word, medicine_list, cutoff=0.8)
                if similar_medicine:
                    print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{word}' â†’ '{similar_medicine}'")
                    return similar_medicine
                else:
                    print(f"ğŸ” '{word}' ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ë¡œë„ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
        similar_medicine = find_similar_medicine_name(text, medicine_list, cutoff=0.7)
        if similar_medicine:
            print(f"âœ… ì „ì²´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{text}' â†’ '{similar_medicine}'")
            return similar_medicine
        else:
            print("ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨")
    
    # ìœ ì‚¬ë„ ë§¤ì¹­ì´ ì‹¤íŒ¨í–ˆë‹¤ë©´ ê³„ì† ì§„í–‰
    
    # ìœ ì‚¬ë„ ë§¤ì¹­ë„ ì‹¤íŒ¨ì‹œ LLM ì‚¬ìš©
    prompt = f"""
ë‹¤ìŒì€ ì•½í’ˆ í¬ì¥ì§€ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ì—ì„œ ì•½í’ˆëª…(ìƒí’ˆëª…)ì„ ì°¾ì•„ì£¼ì„¸ìš”.

**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**
{text}

**ì°¾ì„ ì•½í’ˆëª… íŠ¹ì§•:**
- ì •ì œ, ìº¡ìŠ, ì—°ê³ , í¬ë¦¼, ì ¤, ì‹œëŸ½, ì£¼ì‚¬ì œ ë“± ëª¨ë“  ì•½í’ˆ í˜•íƒœ
- ìƒí’ˆëª…, ë¸Œëœë“œëª…, ì˜ì•½í’ˆëª…, ì œí’ˆëª…
- ì²˜ë°©ì•½, ì¼ë°˜ì˜ì•½í’ˆ, ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë“± ëª¨ë“  ì˜ì•½í’ˆë¥˜
- ì˜ˆ: "ë°”ìŠ¤í¬", "íƒ€ì´ë ˆë†€ì •", "ë² íƒ€ë”˜ ì—°ê³ ", "ì´ë¶€í”„ë¡œíœ ìº¡ìŠ", "íŒì½œì—ì´", "ê²Œë³´ë¦°"

**ì œì™¸í•  ë‹¨ì–´ë“¤:**
ì•½í•™ì •ë³´ì›, ì •ë³´ì›, ì¹˜ë£Œ, ì˜ˆë°©, ê°ì—¼, ì™¸ìƒ, ìƒì²˜, í™”ìƒ, ë³µí•©, ì²˜ë°©, ì¼ë°˜ì˜ì•½í’ˆ, ì²˜ë°©ì•½, 3ì¤‘, 2ì°¨, 10g, 20g, 30g, 50g, 100g, mg, g, ml, KPIC, ì¹˜ë£Œë°, 2ì°¨ê°ì—¼, 3ì¤‘ë³µí•©ì²˜ë°©ì˜

**ì‘ë‹µ í˜•ì‹:**
ì•½í’ˆëª…ë§Œ ì •í™•íˆ ì¶”ì¶œí•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”. ì—¬ëŸ¬ ê°œê°€ ìˆë‹¤ë©´ ê°€ì¥ ì£¼ìš”í•œ ê²ƒ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.
ì•½í’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³  ë‹µí•˜ì„¸ìš”.

**ì•½í’ˆëª…:**
"""
    
    try:
        response = generate_response_llm_from_prompt(
            prompt=prompt,
            temperature=0.1,
            max_tokens=50
        )
        
        # "ì—†ìŒ"ì´ë‚˜ ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
        if not response or response.strip() in ["ì—†ìŒ", "ì°¾ì„ ìˆ˜ ì—†ìŒ", "ì—†ìŠµë‹ˆë‹¤"]:
            return ""
        
        return response.strip()
        
    except Exception as e:
        print(f"âŒ ì•½í’ˆëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

def ocr_image_node(state: QAState) -> QAState:
    """
    OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ë…¸ë“œ
    ì´ë¯¸ì§€ì—ì„œ ì•½í’ˆëª…ì„ ì¶”ì¶œí•˜ê³  ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ì„ ìœ„í•œ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
    """
    print("ğŸ“¸ OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ë…¸ë“œ ì‹œì‘")
    
    # ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸
    image_data = state.get("image_data")
    if not image_data:
        print("âŒ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        return state
    
    # OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    extracted_text = extract_text_from_image(image_data)
    if not extracted_text:
        print("âŒ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        return state
    
    # ì•½í’ˆëª… ì¶”ì¶œ (ìœ ì‚¬ë„ ë§¤ì¹­ í¬í•¨)
    medicine_name = extract_medicine_name_from_text(extracted_text)
    if not medicine_name:
        print("âŒ ì•½í’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ì—ì„œ ì•½í’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•½í’ˆëª…ì´ ëª…í™•íˆ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        return state
    
    print(f"âœ… ìµœì¢… ì•½í’ˆëª…: {medicine_name}")
    
    # ì›ë˜ ì§ˆë¬¸ì—ì„œ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ
    original_query = state.get("query", "")
    usage_context = extract_usage_context_from_query(original_query)
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["medicine_name"] = medicine_name
    state["usage_context"] = usage_context
    state["extracted_text"] = extracted_text
    state["routing_decision"] = "usage_check"  # ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ìœ¼ë¡œ ë¼ìš°íŒ…
    
    print(f"ğŸ¯ OCR ì²˜ë¦¬ ì™„ë£Œ - ì•½í’ˆëª…: {medicine_name}, ì‚¬ìš© ë§¥ë½: {usage_context}")
    
    return state

def extract_usage_context_from_query(query: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ
    """
    if not query:
        return "ì¼ë°˜ì ì¸ ì‚¬ìš©"
    
    # ì§ˆë¬¸ í˜•íƒœë¥¼ ì •ë¦¬í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜ (medicine_usage_check_nodeì™€ ë™ì¼í•œ ë¡œì§)
    clean_context = query
    if "?" in query:
        import re
        # ì§ˆë¬¸ í˜•íƒœì—ì„œ í•µì‹¬ ì¦ìƒ/ìƒí™©ë§Œ ì¶”ì¶œ
        # "ì´ ì—°ê³  ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìŠµì§„ì—"
        # "ì´ ì—°ê³  ìƒì²˜ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìƒì²˜ì—"
        
        # ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë°œë¼ë„\s+ë˜ë‚˜\?',  # "ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë¨¹ì–´ë„\s+ë˜ë‚˜\?',   # "ë‘í†µì— ë¨¹ì–´ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì¨ë„\s+ë˜ë‚˜\?',     # "ìƒì²˜ì— ì¨ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì‚¬ìš©í•´ë„\s+ë˜ë‚˜\?', # "ìƒì²˜ì— ì‚¬ìš©í•´ë„ ë˜ë‚˜?"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query)
            if match:
                clean_context = match.group(1)
                break
        
        # íŒ¨í„´ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        if clean_context == query:
            clean_context = query.replace("?", "").strip()
    
    print(f"ğŸ” ì‚¬ìš© ë§¥ë½ ì •ë¦¬: '{query}' â†’ '{clean_context}'")
    return clean_context

# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def test_ocr_with_image_file(image_path: str) -> str:
    """
    ì´ë¯¸ì§€ íŒŒì¼ë¡œ OCR í…ŒìŠ¤íŠ¸
    """
    try:
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        # OCR ì²˜ë¦¬
        extracted_text = extract_text_from_image(image_data)
        medicine_name = extract_medicine_name_from_text(extracted_text)
        
        print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {extracted_text}")
        print(f"ì¶”ì¶œëœ ì•½í’ˆëª…: {medicine_name}")
        
        return medicine_name
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ§ª OCR ë…¸ë“œ í…ŒìŠ¤íŠ¸")
    # test_ocr_with_image_file("test_image.jpg")
