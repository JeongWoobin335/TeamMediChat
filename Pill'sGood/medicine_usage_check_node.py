# medicine_usage_check_node.py

from qa_state import QAState
from retrievers import llm, pdf_structured_docs, excel_docs, get_medicine_dosage_warnings, load_dosage_warning_data
from langchain_core.documents import Document
from typing import List, Optional
import json
import re
from cache_manager import cache_manager
from difflib import get_close_matches

def normalize_medicine_name(name: str) -> str:
    """
    ì•½í’ˆëª… ì •ê·œí™” (ìœ ì‚¬ë„ ë§¤ì¹­ì„ ìœ„í•´)
    """
    if not name:
        return ""
    
    # ì†Œë¬¸ì ë³€í™˜
    normalized = name.lower()
    
    # íŠ¹ìˆ˜ë¬¸ì, ê³µë°±, ìˆ«ì ì œê±° (í•œê¸€ê³¼ ì˜ë¬¸ë§Œ ìœ ì§€)
    normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    normalized = re.sub(r'\s+', '', normalized)
    
    return normalized.strip()

def calculate_similarity(str1: str, str2: str) -> float:
    """
    ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    """
    if not str1 or not str2:
        return 0.0
    
    if str1 == str2:
        return 1.0
    
    # ê¸¸ì´ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ
    len_diff = abs(len(str1) - len(str2))
    if len_diff > max(len(str1), len(str2)) * 0.5:
        return 0.0
    
    # Levenshtein distance ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    distance = levenshtein_distance(str1, str2)
    max_len = max(len(str1), len(str2))
    similarity = 1.0 - (distance / max_len)
    
    return similarity

def find_similar_medicine_name(ocr_result: str, medicine_list: List[str], cutoff: float = 0.8) -> Optional[str]:
    """
    OCR ê²°ê³¼ì™€ ìœ ì‚¬í•œ ì•½í’ˆëª… ì°¾ê¸°
    """
    if not ocr_result or not medicine_list:
        return None
    
    # OCR ê²°ê³¼ ì •ê·œí™”
    normalized_ocr = normalize_medicine_name(ocr_result)
    print(f"ğŸ” ì •ê·œí™”ëœ OCR ê²°ê³¼: '{normalized_ocr}'")
    
    # ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ë„ ì •ê·œí™”
    normalized_medicines = [(normalize_medicine_name(med), med) for med in medicine_list]
    
    
    # ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
    best_match = None
    best_similarity = 0.0
    
    for norm, orig in normalized_medicines:
        similarity = calculate_similarity(normalized_ocr, norm)
        
        # ìœ ì‚¬ë„ê°€ ë†’ì€ ê²½ìš°ë§Œ ë¡œê·¸ ì¶œë ¥ (ì„±ëŠ¥ ê°œì„ )
        if similarity > 0.3:
            print(f"ğŸ” '{orig}' ìœ ì‚¬ë„: {similarity:.3f}")
        
        if similarity > best_similarity and similarity >= cutoff:
            best_similarity = similarity
            best_match = orig
    
    if best_match:
        print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
        return best_match
    
    # cutoffë¥¼ ë‚®ì¶°ì„œ ë‹¤ì‹œ ì‹œë„
    if cutoff > 0.5:
        print(f"ğŸ” cutoffë¥¼ ë‚®ì¶°ì„œ ì¬ì‹œë„ (0.5)")
        for norm, orig in normalized_medicines:
            similarity = calculate_similarity(normalized_ocr, norm)
            if similarity > best_similarity and similarity >= 0.5:
                best_similarity = similarity
                best_match = orig
        
        if best_match:
            print(f"âœ… ë‚®ì€ cutoff ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
            return best_match
    
    print(f"âŒ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨: '{ocr_result}' (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.3f})")
    return None

def find_medicine_info(medicine_name: str, all_docs: List[Document], is_ocr_result: bool = False) -> dict:
    """ì•½í’ˆëª…ìœ¼ë¡œ ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜"""
    medicine_info = {
        "ì œí’ˆëª…": medicine_name,
        "íš¨ëŠ¥": "ì •ë³´ ì—†ìŒ",
        "ë¶€ì‘ìš©": "ì •ë³´ ì—†ìŒ", 
        "ì‚¬ìš©ë²•": "ì •ë³´ ì—†ìŒ",
        "ì£¼ì˜ì‚¬í•­": "ì •ë³´ ì—†ìŒ"
    }
    
    # ì •í™•í•œ ì œí’ˆëª… ë§¤ì¹­ ì‹œë„
    exact_matches = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == medicine_name]
    
    if not exact_matches:
        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì•½í’ˆëª…ì´ í¬í•¨ëœ ê²½ìš°)
        partial_matches = []
        for doc in all_docs:
            doc_name = doc.metadata.get("ì œí’ˆëª…", "")
            if medicine_name in doc_name or doc_name in medicine_name:
                partial_matches.append(doc)
        
        if partial_matches:
            exact_matches = partial_matches
        else:
            # OCR ê²°ê³¼ì¸ ê²½ìš°ì—ë§Œ ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ì‹œë„
            if is_ocr_result:
                print(f"ğŸ” OCR ê²°ê³¼ ìœ ì‚¬ë„ ê¸°ë°˜ ì•½í’ˆëª… ë§¤ì¹­ ì‹œë„: '{medicine_name}'")
                
                # ëª¨ë“  ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ ìƒì„±
                medicine_list = [doc.metadata.get("ì œí’ˆëª…", "") for doc in all_docs if doc.metadata.get("ì œí’ˆëª…")]
                medicine_list = list(set(medicine_list))  # ì¤‘ë³µ ì œê±°
                
                # ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
                similar_medicine = find_similar_medicine_name(medicine_name, medicine_list, cutoff=0.8)
                if similar_medicine:
                    print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{medicine_name}' â†’ '{similar_medicine}'")
                    # ìœ ì‚¬í•œ ì•½í’ˆëª…ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰
                    exact_matches = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == similar_medicine]
                    # medicine_infoì˜ ì œí’ˆëª…ì„ ì˜¬ë°”ë¥¸ ì•½í’ˆëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    medicine_info["ì œí’ˆëª…"] = similar_medicine
                else:
                    print(f"ğŸ” ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨: '{medicine_name}'")
                    # ê¸°ì¡´ ì •ê·œí™” ë°©ì‹ë„ ì‹œë„
                    normalized_medicine = re.sub(r"[^\wê°€-í£]", "", medicine_name.lower())
                    for doc in all_docs:
                        doc_name = doc.metadata.get("ì œí’ˆëª…", "")
                        normalized_doc_name = re.sub(r"[^\wê°€-í£]", "", doc_name.lower())
                        if normalized_medicine in normalized_doc_name or normalized_doc_name in normalized_medicine:
                            exact_matches.append(doc)
                            break
            else:
                print(f"ğŸ” ë‹¨ì¼ í…ìŠ¤íŠ¸ ì§ˆë¬¸: ìœ ì‚¬ë„ ë§¤ì¹­ ê±´ë„ˆëœ€")
    
    if not exact_matches:
        return medicine_info
    
    # ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘ (ì—¬ëŸ¬ Excel íŒŒì¼ì—ì„œ ë³‘í•©)
    import os
    import re
    url_pattern = r'https?://[^\s]+'
    
    # ìƒˆ Excel íŒŒì¼ ìš°ì„ ìˆœìœ„ ì„¤ì •
    new_excel_file = r"C:\Users\jung\Desktop\33\OpenData_ItemPermitDetail20251115.xls"
    
    # ëª¨ë“  ë§¤ì¹­ëœ ë¬¸ì„œë¥¼ íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
    docs_by_file = {}
    for doc in exact_matches:
        excel_file = doc.metadata.get("excel_file")
        if excel_file:
            if excel_file not in docs_by_file:
                docs_by_file[excel_file] = []
            docs_by_file[excel_file].append(doc)
    
    # ìƒˆ Excel íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •
    file_priority = []
    if new_excel_file in docs_by_file:
        file_priority.append(new_excel_file)
    for file in docs_by_file.keys():
        if file != new_excel_file:
            file_priority.append(file)
    
    print(f"ğŸ“‚ ì•½í’ˆ ì •ë³´ ì¶œì²˜ íŒŒì¼: {len(file_priority)}ê°œ íŒŒì¼ì—ì„œ ë°œê²¬")
    for file in file_priority:
        print(f"  - {os.path.basename(file)} ({len(docs_by_file[file])}ê°œ ì²­í¬)")
    
    # ëª¨ë“  Excel íŒŒì¼ì—ì„œ ì •ë³´ ìˆ˜ì§‘ (íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”)
    excel_file = None
    excel_row_index = None
    
    # ê° íŒŒì¼ë³„ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
    all_efficacy_info = []  # [(íŒŒì¼ëª…, íš¨ëŠ¥ì •ë³´), ...]
    all_side_effects_info = []  # [(íŒŒì¼ëª…, ë¶€ì‘ìš©ì •ë³´), ...]
    all_usage_info = []  # [(íŒŒì¼ëª…, ì‚¬ìš©ë²•ì •ë³´), ...]
    
    for file in file_priority:
        file_name = os.path.basename(file)
        file_efficacy = None
        file_side_effects = None
        file_usage = None
        
        for doc in docs_by_file[file]:
            content = doc.page_content
            doc_type = doc.metadata.get("type", "")
            
            # Excel íŒŒì¼ ì •ë³´ ì €ì¥ (ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ íŒŒì¼ì—ì„œ)
            if not excel_file:
                excel_file = doc.metadata.get("excel_file")
                excel_row_index = doc.metadata.get("excel_row_index")
            
            # íš¨ëŠ¥ê³¼ ë¶€ì‘ìš©ì€ main íƒ€ì…ì—ì„œ ì¶”ì¶œ
            if doc_type == "main" or doc_type == "":
                efficacy = extract_field_from_doc(content, "íš¨ëŠ¥")
                side_effects = extract_field_from_doc(content, "ë¶€ì‘ìš©")
                
                # URLì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìˆ˜ì§‘
                if efficacy != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(efficacy)):
                    if file_efficacy is None:
                        file_efficacy = efficacy
                    else:
                        # ê°™ì€ íŒŒì¼ ë‚´ì—ì„œ ì—¬ëŸ¬ ì²­í¬ê°€ ìˆìœ¼ë©´ ë” ê¸´ ê²ƒì„ ì„ íƒ
                        if len(efficacy) > len(file_efficacy):
                            file_efficacy = efficacy
                
                if side_effects != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(side_effects)):
                    if file_side_effects is None:
                        file_side_effects = side_effects
                    else:
                        if len(side_effects) > len(file_side_effects):
                            file_side_effects = side_effects
            
            # ì‚¬ìš©ë²•ì€ usage íƒ€ì…ì—ì„œ ì¶”ì¶œ
            if doc_type == "usage":
                usage = extract_field_from_doc(content, "ì‚¬ìš©ë²•")
                if usage != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(usage)):
                    if file_usage is None:
                        file_usage = usage
                    else:
                        if len(usage) > len(file_usage):
                            file_usage = usage
        
        # íŒŒì¼ë³„ë¡œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        if file_efficacy:
            all_efficacy_info.append((file_name, file_efficacy))
            print(f"ğŸ“‹ {file_name}ì—ì„œ íš¨ëŠ¥ ì •ë³´ ìˆ˜ì§‘: {len(file_efficacy)}ì")
        if file_side_effects:
            all_side_effects_info.append((file_name, file_side_effects))
            print(f"ğŸ“‹ {file_name}ì—ì„œ ë¶€ì‘ìš© ì •ë³´ ìˆ˜ì§‘: {len(file_side_effects)}ì")
        if file_usage:
            all_usage_info.append((file_name, file_usage))
            print(f"ğŸ“‹ {file_name}ì—ì„œ ì‚¬ìš©ë²• ì •ë³´ ìˆ˜ì§‘: {len(file_usage)}ì")
    
    # ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ LLMìœ¼ë¡œ ë³‘í•©
    if len(all_efficacy_info) > 1:
        print(f"ğŸ”„ {len(all_efficacy_info)}ê°œ ì†ŒìŠ¤ì˜ íš¨ëŠ¥ ì •ë³´ ë³‘í•© ì¤‘...")
        merged_efficacy = merge_multiple_sources_with_llm(all_efficacy_info, "íš¨ëŠ¥")
        medicine_info["íš¨ëŠ¥"] = merged_efficacy
    elif len(all_efficacy_info) == 1:
        medicine_info["íš¨ëŠ¥"] = all_efficacy_info[0][1]
    
    if len(all_side_effects_info) > 1:
        print(f"ğŸ”„ {len(all_side_effects_info)}ê°œ ì†ŒìŠ¤ì˜ ë¶€ì‘ìš© ì •ë³´ ë³‘í•© ì¤‘...")
        merged_side_effects = merge_multiple_sources_with_llm(all_side_effects_info, "ë¶€ì‘ìš©")
        medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
    elif len(all_side_effects_info) == 1:
        medicine_info["ë¶€ì‘ìš©"] = all_side_effects_info[0][1]
    
    if len(all_usage_info) > 1:
        print(f"ğŸ”„ {len(all_usage_info)}ê°œ ì†ŒìŠ¤ì˜ ì‚¬ìš©ë²• ì •ë³´ ë³‘í•© ì¤‘...")
        merged_usage = merge_multiple_sources_with_llm(all_usage_info, "ì‚¬ìš©ë²•")
        medicine_info["ì‚¬ìš©ë²•"] = merged_usage
    elif len(all_usage_info) == 1:
        medicine_info["ì‚¬ìš©ë²•"] = all_usage_info[0][1]
    
    # PDF ë§í¬ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ (ëª¨ë“  íŒŒì¼ì—ì„œ ìˆ˜ì§‘í•˜ì—¬ ë³‘í•©)
    from pdf_link_extractor import enrich_excel_row_with_pdf_content
    from retrievers import file_column_mappings, default_columns
    
    # ëª¨ë“  íŒŒì¼ì—ì„œ PDF ì •ë³´ ìˆ˜ì§‘
    all_pdf_efficacy = []
    all_pdf_side_effects = []
    all_pdf_usage = []
    
    for file in file_priority:
        # í•´ë‹¹ íŒŒì¼ì˜ ë¬¸ì„œì—ì„œ excel_row_index ì°¾ê¸°
        file_row_index = None
        for doc in docs_by_file[file]:
            if doc.metadata.get("excel_file") == file:
                file_row_index = doc.metadata.get("excel_row_index")
                if file_row_index is not None:
                    break
        
        if file_row_index is None:
            continue
        
        print(f"ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì‹œë„: {os.path.basename(file)}, í–‰ {file_row_index}")
        try:
            # íŒŒì¼ë³„ ì»¬ëŸ¼ ë§¤í•‘ í™•ì¸
            if file in file_column_mappings:
                col_mapping = file_column_mappings[file]
            else:
                col_mapping = default_columns
            
            pdf_column_mapping = {
                'íš¨ëŠ¥': col_mapping['íš¨ëŠ¥'],
                'ë³µìš©ë²•': col_mapping['ì‚¬ìš©ë²•'],
                'ì£¼ì˜ì‚¬í•­': col_mapping['ë¶€ì‘ìš©']
            }
            
            # íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²•ì´ URLì¸ì§€ í™•ì¸í•˜ê³  PDF ë‹¤ìš´ë¡œë“œ
            pdf_content = enrich_excel_row_with_pdf_content(
                file, file_row_index, ['íš¨ëŠ¥', 'ì£¼ì˜ì‚¬í•­', 'ë³µìš©ë²•'], pdf_column_mapping
            )
            
            print(f"ğŸ“‹ PDF ë‚´ìš© í™•ì¸: {list(pdf_content.keys())}")
            for key, value in pdf_content.items():
                if value:
                    print(f"  - {key}: {len(str(value))}ì - {str(value)[:100]}...")
                    # PDF ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    file_name = os.path.basename(file)
                    if key == 'íš¨ëŠ¥' and value:
                        all_pdf_efficacy.append((file_name, value))
                    elif key == 'ì£¼ì˜ì‚¬í•­' and value:
                        all_pdf_side_effects.append((file_name, value))
                    elif key == 'ë³µìš©ë²•' and value:
                        all_pdf_usage.append((file_name, value))
                else:
                    print(f"  - {key}: None")
        
        except Exception as e:
            print(f"âš ï¸ {os.path.basename(file)} PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
    
    # PDF ì •ë³´ë¥¼ ê¸°ì¡´ Excel ì •ë³´ì™€ ë³‘í•©
    if all_pdf_efficacy:
        current_efficacy = medicine_info.get("íš¨ëŠ¥", "ì •ë³´ ì—†ìŒ")
        if current_efficacy != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_efficacy_sources = all_efficacy_info + all_pdf_efficacy
            if len(all_efficacy_sources) > 1:
                print(f"ğŸ”„ Excel + PDF íš¨ëŠ¥ ì •ë³´ ë³‘í•© ì¤‘... ({len(all_efficacy_sources)}ê°œ ì†ŒìŠ¤)")
                merged_efficacy = merge_multiple_sources_with_llm(all_efficacy_sources, "íš¨ëŠ¥")
                medicine_info["íš¨ëŠ¥"] = merged_efficacy
            else:
                medicine_info["íš¨ëŠ¥"] = all_efficacy_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_efficacy) > 1:
                merged_efficacy = merge_multiple_sources_with_llm(all_pdf_efficacy, "íš¨ëŠ¥")
                medicine_info["íš¨ëŠ¥"] = merged_efficacy
            elif len(all_pdf_efficacy) == 1:
                medicine_info["íš¨ëŠ¥"] = all_pdf_efficacy[0][1]
    
    if all_pdf_side_effects:
        current_side_effects = medicine_info.get("ë¶€ì‘ìš©", "ì •ë³´ ì—†ìŒ")
        if current_side_effects != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_side_effects_sources = all_side_effects_info + all_pdf_side_effects
            if len(all_side_effects_sources) > 1:
                print(f"ğŸ”„ Excel + PDF ë¶€ì‘ìš© ì •ë³´ ë³‘í•© ì¤‘... ({len(all_side_effects_sources)}ê°œ ì†ŒìŠ¤)")
                merged_side_effects = merge_multiple_sources_with_llm(all_side_effects_sources, "ë¶€ì‘ìš©")
                medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
            else:
                medicine_info["ë¶€ì‘ìš©"] = all_side_effects_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_side_effects) > 1:
                merged_side_effects = merge_multiple_sources_with_llm(all_pdf_side_effects, "ë¶€ì‘ìš©")
                medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
            elif len(all_pdf_side_effects) == 1:
                medicine_info["ë¶€ì‘ìš©"] = all_pdf_side_effects[0][1]
    
    if all_pdf_usage:
        current_usage = medicine_info.get("ì‚¬ìš©ë²•", "ì •ë³´ ì—†ìŒ")
        if current_usage != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_usage_sources = all_usage_info + all_pdf_usage
            if len(all_usage_sources) > 1:
                print(f"ğŸ”„ Excel + PDF ì‚¬ìš©ë²• ì •ë³´ ë³‘í•© ì¤‘... ({len(all_usage_sources)}ê°œ ì†ŒìŠ¤)")
                merged_usage = merge_multiple_sources_with_llm(all_usage_sources, "ì‚¬ìš©ë²•")
                medicine_info["ì‚¬ìš©ë²•"] = merged_usage
            else:
                medicine_info["ì‚¬ìš©ë²•"] = all_usage_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_usage) > 1:
                merged_usage = merge_multiple_sources_with_llm(all_pdf_usage, "ì‚¬ìš©ë²•")
                medicine_info["ì‚¬ìš©ë²•"] = merged_usage
            elif len(all_pdf_usage) == 1:
                medicine_info["ì‚¬ìš©ë²•"] = all_pdf_usage[0][1]
    
    # ì—°ë ¹ëŒ€ ê¸ˆê¸° ì„±ë¶„ ì •ë³´ ì¶”ê°€
    try:
        from retrievers import get_medicine_age_contraindications
        age_contraindications = get_medicine_age_contraindications(medicine_name)
        if age_contraindications:
            medicine_info["ì—°ë ¹ëŒ€_ê¸ˆê¸°_ì •ë³´"] = age_contraindications
            print(f"âœ… ì—°ë ¹ëŒ€ ê¸ˆê¸° ì •ë³´ ì¶”ê°€: {len(age_contraindications)}ê°œ ì„±ë¶„")
    except Exception as e:
        print(f"âš ï¸ ì—°ë ¹ëŒ€ ê¸ˆê¸° ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    # ì¼ì¼ ìµœëŒ€ íˆ¬ì—¬ëŸ‰ ì •ë³´ ì¶”ê°€
    try:
        from retrievers import get_medicine_daily_max_dosage
        daily_max_dosage = get_medicine_daily_max_dosage(medicine_name)
        if daily_max_dosage:
            medicine_info["ì¼ì¼_ìµœëŒ€_íˆ¬ì—¬ëŸ‰_ì •ë³´"] = daily_max_dosage
            print(f"âœ… ì¼ì¼ ìµœëŒ€ íˆ¬ì—¬ëŸ‰ ì •ë³´ ì¶”ê°€: {len(daily_max_dosage)}ê°œ ì„±ë¶„")
    except Exception as e:
        print(f"âš ï¸ ì¼ì¼ ìµœëŒ€ íˆ¬ì—¬ëŸ‰ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    return medicine_info

def extract_field_from_doc(text: str, label: str) -> str:
    """ë¬¸ì„œì—ì„œ íŠ¹ì • í•„ë“œ ì¶”ì¶œ"""
    pattern = rf"\[{label}\]:\s*((?:.|\n)*?)(?=\n\[|\Z)"
    match = re.search(pattern, text)
    return match.group(1).strip() if match else "ì •ë³´ ì—†ìŒ"

def merge_multiple_sources_with_llm(sources_info: List[tuple], field_name: str) -> str:
    """
    ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ LLMìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
    ì¤‘ë³µ ë‚´ìš©ì€ ì œê±°í•˜ê³ , ê° ì†ŒìŠ¤ì˜ ê³ ìœ í•œ ë‚´ìš©ì€ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.
    
    Args:
        sources_info: [(ì†ŒìŠ¤ëª…, ì •ë³´), ...] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
        field_name: í•„ë“œëª… (íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²• ë“±)
    
    Returns:
        ë³‘í•©ëœ ì •ë³´
    """
    if not sources_info:
        return "ì •ë³´ ì—†ìŒ"
    
    if len(sources_info) == 1:
        return sources_info[0][1]
    
    try:
        print(f"ğŸ”„ {len(sources_info)}ê°œ ì†ŒìŠ¤ì˜ {field_name} ì •ë³´ ë³‘í•© ì¤‘...")
        
        # ì†ŒìŠ¤ë³„ ì •ë³´ë¥¼ ì •ë¦¬
        sources_text = ""
        for i, (source_name, info) in enumerate(sources_info, 1):
            sources_text += f"\n**ì†ŒìŠ¤ {i} ({source_name}):**\n{info}\n"
        
        merge_prompt = f"""ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ {field_name} ì •ë³´ë¥¼ ë³‘í•©í•˜ì—¬ ì™„ì „í•œ ì •ë³´ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

**ë³‘í•© ì›ì¹™:**
1. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ í•˜ë‚˜ë¡œ í†µí•© (ê°™ì€ ì˜ë¯¸ì˜ ë‚´ìš©ì´ ì—¬ëŸ¬ ì†ŒìŠ¤ì— ìˆìœ¼ë©´ í•˜ë‚˜ë§Œ ìœ ì§€)
2. ê° ì†ŒìŠ¤ì˜ ê³ ìœ í•œ ë‚´ìš©ì€ ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨ (ì†ŒìŠ¤ë³„ë¡œ ë‹¤ë¥¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ëª¨ë‘ ì¶”ê°€)
3. ëª¨ë“  ì¤‘ìš”í•œ ì •ë³´ë¥¼ í¬í•¨ (ê¸ˆê¸°ì‚¬í•­, ì£¼ì˜ì‚¬í•­, ìš©ëŸ‰ ì •ë³´, íŠ¹ìˆ˜ ì‚¬ìš©ë²• ë“±)
4. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ìš©ëŸ‰ ì •ë³´ëŠ” ëª¨ë‘ ìœ ì§€
5. ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í†µí•©
6. ì†ŒìŠ¤ë³„ë¡œ ì•½ê°„ì”© ë‹¤ë¥¸ í‘œí˜„ì´ë¼ë„ ì˜ë¯¸ê°€ ë‹¤ë¥´ë©´ ëª¨ë‘ í¬í•¨

**ìˆ˜ì§‘ëœ {field_name} ì •ë³´ (ì—¬ëŸ¬ ì†ŒìŠ¤):**
{sources_text}

**ë³‘í•©ëœ {field_name} ì •ë³´ (ì¤‘ë³µ ì œê±°, ëª¨ë“  ê³ ìœ  ì •ë³´ í¬í•¨):**
"""
        
        # ìºì‹œ í™•ì¸
        cached_response = cache_manager.get_llm_response_cache(merge_prompt, f"merge_multiple_{field_name}")
        if cached_response:
            merged = cached_response
        else:
            response = llm.invoke(merge_prompt)
            merged = response.content if hasattr(response, 'content') else str(response)
            # ìºì‹œ ì €ì¥
            if merged and len(merged) > 50:
                cache_manager.save_llm_response_cache(merge_prompt, merged, f"merge_multiple_{field_name}")
        
        if merged and len(merged) > 50:
            print(f"âœ… {field_name} ì •ë³´ ë³‘í•© ì™„ë£Œ: {len(merged)}ì (ì›ë³¸: {sum(len(info) for _, info in sources_info)}ì)")
            return merged.strip()
        else:
            print(f"âš ï¸ ë³‘í•© ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ì•„ ì²« ë²ˆì§¸ ì†ŒìŠ¤ ì •ë³´ ìœ ì§€")
            return sources_info[0][1]
    
    except Exception as e:
        print(f"âš ï¸ {field_name} ì •ë³´ ë³‘í•© ì‹¤íŒ¨, ì²« ë²ˆì§¸ ì†ŒìŠ¤ ì •ë³´ ìœ ì§€: {e}")
        return sources_info[0][1]

def merge_medicine_info_with_llm(current_info: str, pdf_info: str, field_name: str) -> str:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
    ì¤‘ë³µ ë‚´ìš©ì€ ì œê±°í•˜ê³ , ìƒˆë¡œìš´ ë‚´ìš©ì€ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        current_info: ê¸°ì¡´ ì •ë³´
        pdf_info: PDFì—ì„œ ì¶”ì¶œí•œ ì •ë³´
        field_name: í•„ë“œëª… (íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²• ë“±)
    
    Returns:
        ë³‘í•©ëœ ì •ë³´
    """
    # URLì´ê±°ë‚˜ ì •ë³´ ì—†ìŒì´ë©´ PDF ì •ë³´ë¡œ êµì²´
    url_pattern = r'https?://[^\s]+'
    if current_info == "ì •ë³´ ì—†ìŒ" or re.search(url_pattern, str(current_info)):
        return pdf_info
    
    # ë‘ ì •ë³´ê°€ ë¹„ìŠ·í•˜ë©´ ê·¸ëƒ¥ ê¸°ì¡´ ì •ë³´ ìœ ì§€ (ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ë°©ì§€)
    if current_info.strip() == pdf_info.strip():
        return current_info
    
    try:
        print(f"ğŸ”„ {field_name} ì •ë³´ ë³‘í•© ì¤‘... (ê¸°ì¡´: {len(current_info)}ì, PDF: {len(pdf_info)}ì)")
        
        merge_prompt = f"""ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ ì •ë³´ì™€ PDFì—ì„œ ì¶”ì¶œí•œ ì •ë³´ë¥¼ ë³‘í•©í•˜ì—¬ ì™„ì „í•œ {field_name} ì •ë³´ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

**ë³‘í•© ì›ì¹™:**
1. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ í•˜ë‚˜ë¡œ í†µí•©
2. ê¸°ì¡´ ì •ë³´ì— ì—†ëŠ” ìƒˆë¡œìš´ ë‚´ìš©ì€ ë°˜ë“œì‹œ ì¶”ê°€
3. ëª¨ë“  ì¤‘ìš”í•œ ì •ë³´ë¥¼ í¬í•¨ (ê¸ˆê¸°ì‚¬í•­, ì£¼ì˜ì‚¬í•­, ìš©ëŸ‰ ì •ë³´ ë“±)
4. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ìš©ëŸ‰ ì •ë³´ëŠ” ëª¨ë‘ ìœ ì§€
5. ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í†µí•©

**ê¸°ì¡´ {field_name} ì •ë³´:**
{current_info}

**PDFì—ì„œ ì¶”ì¶œí•œ {field_name} ì •ë³´:**
{pdf_info}

**ë³‘í•©ëœ {field_name} ì •ë³´ (ì¤‘ë³µ ì œê±°, ì‹ ê·œ ë‚´ìš© ì¶”ê°€):**
"""
        
        # ìºì‹œ í™•ì¸
        cached_response = cache_manager.get_llm_response_cache(merge_prompt, f"merge_{field_name}")
        if cached_response:
            merged = cached_response
        else:
            response = llm.invoke(merge_prompt)
            merged = response.content if hasattr(response, 'content') else str(response)
            # ìºì‹œ ì €ì¥
            if merged and len(merged) > 50:
                cache_manager.save_llm_response_cache(merge_prompt, merged, f"merge_{field_name}")
        
        if merged and len(merged) > 50:
            print(f"âœ… {field_name} ì •ë³´ ë³‘í•© ì™„ë£Œ: {len(merged)}ì")
            return merged.strip()
        else:
            print(f"âš ï¸ ë³‘í•© ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ì•„ ê¸°ì¡´ ì •ë³´ ìœ ì§€")
            return current_info
    
    except Exception as e:
        print(f"âš ï¸ {field_name} ì •ë³´ ë³‘í•© ì‹¤íŒ¨, ê¸°ì¡´ ì •ë³´ ìœ ì§€: {e}")
        return current_info

def check_medicine_usage_safety(medicine_info: dict, usage_context: str) -> dict:
    """ì•½í’ˆ ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨"""
    
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸ (ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ë¦¬ìŠ¤íŠ¸ í†µí•©ìœ¼ë¡œ ì¸í•´ ìºì‹œ ë¹„í™œì„±í™”)
    cache_key = f"{medicine_info['ì œí’ˆëª…']}_{usage_context}"
    cache_file = cache_manager.matching_cache_dir / f"{cache_key}.pkl"
    
    # ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ë¦¬ìŠ¤íŠ¸ê°€ í†µí•©ë˜ì—ˆìœ¼ë¯€ë¡œ ìºì‹œë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ê³„ì‚°
    print(f"ğŸ” ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ë¦¬ìŠ¤íŠ¸ í†µí•©ìœ¼ë¡œ ì¸í•´ ìºì‹œ ë¬´ì‹œ: {cache_key}")
    cached_result = None
    
    # ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ì •ë³´ í™•ì¸
    dosage_warnings = get_medicine_dosage_warnings(medicine_info['ì œí’ˆëª…'])
    dosage_warning_text = ""
    if dosage_warnings:
        dosage_warning_text = "\n\n## âš ï¸ ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ì •ë³´\n"
        for warning in dosage_warnings:
            ingredient = warning['ingredient']
            dosage_info = warning['dosage_info']
            dosage_warning_text += f"- **{ingredient}**: 1ì¼ ìµœëŒ€ìš©ëŸ‰ {dosage_info['max_daily_dose']}\n"
            if dosage_info['remarks'] and dosage_info['remarks'] != 'nan':
                dosage_warning_text += f"  - ë¹„ê³ : {dosage_info['remarks']}\n"
        dosage_warning_text += "\n**ì¤‘ìš”**: ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ì´ í¬í•¨ëœ ì•½í’ˆì€ ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì˜ ì²˜ë°©ì— ë”°ë¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
    
    # LLMì„ ì‚¬ìš©í•œ ì•ˆì „ì„± íŒë‹¨ - ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ì•ˆì „ì„± í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì—¬ ê·¼ê±° ìˆëŠ” íŒë‹¨ì„ ë‚´ë¦¬ì„¸ìš”.

## ğŸ“‹ ì•½í’ˆ ì •ë³´
- ì œí’ˆëª…: {medicine_info['ì œí’ˆëª…']}
- íš¨ëŠ¥: {medicine_info['íš¨ëŠ¥']}
- ë¶€ì‘ìš©: {medicine_info['ë¶€ì‘ìš©']}
- ì‚¬ìš©ë²•: {medicine_info['ì‚¬ìš©ë²•']}{dosage_warning_text}

## ğŸ¯ ì‚¬ìš© ìƒí™©
{usage_context}

## ğŸ” 3ë‹¨ê³„ í‰ê°€ í”„ë¡œì„¸ìŠ¤

### STEP 1: íš¨ëŠ¥-ì¦ìƒ ë§¤ì¹­ ë¶„ì„ (ê°€ì¥ ì¤‘ìš”)
ì•„ë˜ ì˜í•™ì  ì¦ìƒ ë§¤í•‘ì„ ì°¸ê³ í•˜ì—¬ ì•½í’ˆ íš¨ëŠ¥ê³¼ ì‚¬ìš© ìƒí™©ì˜ ì—°ê´€ì„±ì„ í‰ê°€í•˜ì„¸ìš”.

**ì˜í•™ì  ì¦ìƒ ë§¤í•‘:**
- í”¼ë¶€ ì§ˆí™˜: ìŠµì§„ â†” ì•„í† í”¼ â†” í”¼ë¶€ì—¼ â†” ë°œì§„ â†” ê°€ë ¤ì›€ â†” ë‘ë“œëŸ¬ê¸°
- ìƒì²˜/ì™¸ìƒ: ìƒì²˜ â†” ì°°ê³¼ìƒ â†” ê¸í˜ â†” ë² ì¸ ìƒì²˜ â†” ì™¸ìƒ â†” í™”ìƒ
- í†µì¦: ë‘í†µ â†” í¸ë‘í†µ â†” ë¨¸ë¦¬ ì•„í”” / ê·¼ìœ¡í†µ â†” ëª¸ì‚´ / ì¹˜í†µ â†” ì‡ëª¸ í†µì¦
- í”¼ë¡œ: í”¼ë¡œ â†” í”¼ê³¤í•¨ â†” ë¬´ê¸°ë ¥ â†” ê¸°ìš´ ì—†ìŒ â†” ì²´ë ¥ ì €í•˜ â†” ìœ¡ì²´ í”¼ë¡œ
- ì†Œí™”: ì†Œí™”ë¶ˆëŸ‰ â†” ì²´í•¨ â†” ì† ë¶ˆí¸ â†” ìœ„ì¥ ì¥ì•  â†” ë”ë¶€ë£©í•¨
- ê°ì—¼: ì„¸ê·  ê°ì—¼ â†” í™”ë† â†” ì—¼ì¦ â†” ê³ ë¦„
- ê°ê¸°: ê°ê¸° â†” ì½”ê°ê¸° â†” ëª©ê°ê¸° â†” ê¸°ì¹¨ â†” ì½§ë¬¼ â†” ì¸í›„í†µ

**ë¶„ì„ ì§ˆë¬¸:**
1. ì•½í’ˆ íš¨ëŠ¥ì— ëª…ì‹œëœ ì¦ìƒì´ ì‚¬ìš© ìƒí™©ê³¼ ì§ì ‘ ì¼ì¹˜í•˜ëŠ”ê°€?
2. ìœ„ ë§¤í•‘ì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì¦ìƒì¸ê°€?
3. ë§¤ì¹­ ê°•ë„: ì™„ì „ì¼ì¹˜(100%) / ê°•í•œì—°ê´€(80%) / ì¤‘ê°„ì—°ê´€(50%) / ì•½í•œì—°ê´€(30%) / ë¬´ê´€(0%)

**STEP 1 ê²°ê³¼:**
- ë§¤ì¹­ ê°•ë„: ___%
- ê·¼ê±°: [íš¨ëŠ¥ì˜ ì–´ë–¤ ë¶€ë¶„ì´ ì‚¬ìš© ìƒí™©ê³¼ ì—°ê´€ë˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]

### STEP 2: ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ í‰ê°€ (ìƒˆë¡œ ì¶”ê°€)
**ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ì ê²€:**
- ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- 1ì¼ ìµœëŒ€ìš©ëŸ‰ ì •ë³´ê°€ ì œê³µë˜ì—ˆëŠ”ê°€?
- ë³µí•©ì œì¸ ê²½ìš° ê° ì„±ë¶„ë³„ ìš©ëŸ‰ ê³ ë ¤ í•„ìš”

**ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ì´ ìˆëŠ” ê²½ìš°:**
- ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ ì²˜ë°© í•„ìš”
- ìê°€ ì²˜ë°© ê¸ˆì§€
- ìš©ëŸ‰ ì´ˆê³¼ ì‹œ ì‹¬ê°í•œ ë¶€ì‘ìš© ê°€ëŠ¥ì„±

**STEP 2 ê²°ê³¼:**
- ìš©ëŸ‰ì£¼ì˜ ì—¬ë¶€: ìˆìŒ / ì—†ìŒ
- ì²˜ë°© í•„ìš”ì„±: í•„ìˆ˜ / ê¶Œì¥ / ë¶ˆí•„ìš”
- ê·¼ê±°: [êµ¬ì²´ì  ì„¤ëª…]

### STEP 3: ìœ„í—˜ë„ í‰ê°€
**ë¶€ì‘ìš© ì‹¬ê°ë„ ì ê²€:**
- ì‹¬ê°í•œ ë¶€ì‘ìš© ìˆìŒ? (ì‡¼í¬, ì¤‘ì¦ ì•Œë ˆë¥´ê¸° ë“±) â†’ ìœ„í—˜
- ì¼ë°˜ì  ë¶€ì‘ìš©ë§Œ ìˆìŒ? (ì¡¸ìŒ, ê°€ë²¼ìš´ ì†Œí™”ë¶ˆëŸ‰ ë“±) â†’ ë³´í†µ
- ë¶€ì‘ìš© ë¯¸ë¯¸ ë˜ëŠ” ì—†ìŒ? â†’ ì•ˆì „

**ì‚¬ìš© ìƒí™© ì í•©ì„±:**
- í•´ë‹¹ ìƒí™©ì—ì„œ ë¶€ì‘ìš©ì´ ì¹˜ëª…ì ì¸ê°€?
- ì‚¬ìš©ë²•ì´ ìƒí™©ì— ë§ëŠ”ê°€? (ê²½êµ¬/ì™¸ìš© ë“±)

**STEP 3 ê²°ê³¼:**
- ìœ„í—˜ ìˆ˜ì¤€: ë†’ìŒ / ë³´í†µ / ë‚®ìŒ
- ê·¼ê±°: [êµ¬ì²´ì  ì„¤ëª…]

### STEP 4: ìµœì¢… íŒë‹¨
**ì¢…í•© ì ìˆ˜ ê³„ì‚°:**
- ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ìˆìŒ â†’ ë°˜ë“œì‹œ ì˜ì‚¬/ì•½ì‚¬ ì²˜ë°© í•„ìš”
- ë§¤ì¹­ ê°•ë„ â‰¥ 50% + ìœ„í—˜ ìˆ˜ì¤€ ë‚®ìŒ/ë³´í†µ + ìš©ëŸ‰ì£¼ì˜ ì—†ìŒ â†’ ì‚¬ìš© ê°€ëŠ¥
- ë§¤ì¹­ ê°•ë„ < 50% ë˜ëŠ” ìœ„í—˜ ìˆ˜ì¤€ ë†’ìŒ â†’ ì‚¬ìš© ë¶ˆê°€

**ì‹ ë¢°ë„ í‰ê°€:**
- ë†’ìŒ: ëª…í™•í•œ íš¨ëŠ¥ ì¼ì¹˜ + ì•ˆì „ì„± í™•ì¸ë¨ + ìš©ëŸ‰ì£¼ì˜ ì •ë³´ í™•ì¸ë¨
- ì¤‘ê°„: ìœ ì‚¬ ì¦ìƒ + í° ìœ„í—˜ ì—†ìŒ + ìš©ëŸ‰ì£¼ì˜ ì—†ìŒ
- ë‚®ìŒ: íš¨ëŠ¥ ë¶ˆëª…í™•í•˜ê±°ë‚˜ ìœ„í—˜ ìš”ì†Œ ìˆìŒ ë˜ëŠ” ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ í¬í•¨

## ğŸ’¡ íŒë‹¨ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ë² íƒ€ë”˜ ì—°ê³  + ìƒì²˜
- STEP 1: íš¨ëŠ¥ "ìƒì²˜ ì†Œë…, ì„¸ê·  ê°ì—¼ ì˜ˆë°©" vs ì‚¬ìš© "ìƒì²˜" â†’ 100% ì¼ì¹˜
- STEP 2: ë¶€ì‘ìš© "í”¼ë¶€ ìê·¹" â†’ ê²½ë¯¸, ìœ„í—˜ ë‚®ìŒ
- STEP 3: ì‚¬ìš© ê°€ëŠ¥ (ì‹ ë¢°ë„: ë†’ìŒ)

### ì˜ˆì‹œ 2: ê°ê¸°ì•½ + ë‘í†µ
- STEP 1: íš¨ëŠ¥ "ê°ê¸° ì¦ìƒ ì™„í™”(ë‘í†µ, ë°œì—´)" vs ì‚¬ìš© "ë‘í†µ" â†’ 80% ê°•í•œ ì—°ê´€
- STEP 2: ë¶€ì‘ìš© "ì¡¸ìŒ" â†’ ê²½ë¯¸, ìœ„í—˜ ë‚®ìŒ
- STEP 3: ì‚¬ìš© ê°€ëŠ¥ (ì‹ ë¢°ë„: ë†’ìŒ)

### ì˜ˆì‹œ 3: í”¼ë¶€ ì—°ê³  + ê·¼ìœ¡í†µ
- STEP 1: íš¨ëŠ¥ "ìŠµì§„, í”¼ë¶€ì—¼ ì™„í™”" vs ì‚¬ìš© "ê·¼ìœ¡í†µ" â†’ 0% ë¬´ê´€
- STEP 2: íš¨ëŠ¥ ë¶ˆì¼ì¹˜
- STEP 3: ì‚¬ìš© ë¶ˆê°€ (ì‹ ë¢°ë„: ë†’ìŒ)

## ğŸ“¤ ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "safe_to_use": true/false,
    "confidence_score": 0.0~1.0,
    "matching_strength": 0~100,
    "has_dosage_warning": true/false,
    "prescription_required": true/false,
    "reason": "STEP 1-4 ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ êµ¬ì²´ì  ê·¼ê±° (2-3ë¬¸ì¥)",
    "precautions": "ì£¼ì˜ì‚¬í•­ (í•„ìš”ì‹œ)",
    "dosage_warnings": ["ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ ì •ë³´ (ìˆëŠ” ê²½ìš°)"],
    "alternative_suggestion": "ëŒ€ì•ˆ ì œì•ˆ (ì‚¬ìš© ë¶ˆê°€ ì‹œ)"
}}

**ì¤‘ìš”**: ì¶”ì¸¡í•˜ì§€ ë§ê³  ì£¼ì–´ì§„ ì•½í’ˆ ì •ë³´ë§Œìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”. ë¶ˆí™•ì‹¤í•˜ë©´ confidence_scoreë¥¼ ë‚®ì¶”ì„¸ìš”.
"""
    
    try:
        # ìºì‹œ í™•ì¸
        cached_response = cache_manager.get_llm_response_cache(prompt, "usage_check")
        if cached_response:
            response = cached_response
        else:
            response = llm.invoke(prompt).content.strip()
            # ìºì‹œ ì €ì¥
            cache_manager.save_llm_response_cache(prompt, response, "usage_check")
        print(f"ğŸ” LLM ì‘ë‹µ: {response[:200]}...")
        
        # JSON ì‘ë‹µ íŒŒì‹± (```json ì œê±° ì²˜ë¦¬)
        try:
            # ```jsonê³¼ ``` ì œê±°
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end != -1:
                    response = response[json_start:json_end].strip()
            elif "```" in response:
                json_start = response.find("```") + 3
                json_end = response.find("```", json_start)
                if json_end != -1:
                    response = response[json_start:json_end].strip()
            
            result = json.loads(response)
            
            # ìƒˆë¡œìš´ í•„ë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
            if "confidence_score" not in result:
                result["confidence_score"] = 0.7  # ê¸°ë³¸ ì¤‘ê°„ ì‹ ë¢°ë„
            if "matching_strength" not in result:
                result["matching_strength"] = 50  # ê¸°ë³¸ ì¤‘ê°„ ë§¤ì¹­
            if "has_dosage_warning" not in result:
                result["has_dosage_warning"] = len(dosage_warnings) > 0
            if "prescription_required" not in result:
                result["prescription_required"] = len(dosage_warnings) > 0
            if "dosage_warnings" not in result:
                result["dosage_warnings"] = [f"{w['ingredient']}: {w['dosage_info']['max_daily_dose']}" for w in dosage_warnings]
            
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: safe_to_use={result.get('safe_to_use')}, confidence={result.get('confidence_score')}, matching={result.get('matching_strength')}%, dosage_warning={result.get('has_dosage_warning')}")
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ğŸ” ì›ë³¸ ì‘ë‹µ: {response}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            result = {
                "safe_to_use": False,
                "confidence_score": 0.3,
                "matching_strength": 0,
                "has_dosage_warning": len(dosage_warnings) > 0,
                "prescription_required": len(dosage_warnings) > 0,
                "reason": "ì•½í’ˆ ì •ë³´ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "precautions": "ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.",
                "dosage_warnings": [f"{w['ingredient']}: {w['dosage_info']['max_daily_dose']}" for w in dosage_warnings],
                "alternative_suggestion": ""
            }
        
        # ìºì‹œì— ì €ì¥
        try:
            import pickle
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            print(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ ì €ì¥ë¨: {cache_key}")
        except Exception as e:
            print(f"âŒ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì•½í’ˆ ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "safe_to_use": False,
            "confidence_score": 0.0,
            "matching_strength": 0,
            "has_dosage_warning": len(dosage_warnings) > 0,
            "prescription_required": len(dosage_warnings) > 0,
            "reason": "ì•ˆì „ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "precautions": "ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.",
            "dosage_warnings": [f"{w['ingredient']}: {w['dosage_info']['max_daily_dose']}" for w in dosage_warnings],
            "alternative_suggestion": ""
        }

def generate_usage_check_response(medicine_name: str, usage_context: str, medicine_info: dict, safety_result: dict) -> str:
    """ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì‘ë‹µìœ¼ë¡œ ë³€í™˜"""
    
    # usage_contextì—ì„œ ì§ˆë¬¸ í˜•íƒœì˜ ë¬¸ì¥ì„ ì •ë¦¬í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
    clean_context = usage_context
    if "?" in usage_context:
        import re
        # ì§ˆë¬¸ í˜•íƒœì—ì„œ í•µì‹¬ ì¦ìƒ/ìƒí™©ë§Œ ì¶”ì¶œ
        # "ì´ ì—°ê³  ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìŠµì§„ì—"
        # "ë°•í…Œë¡œì‹ ì´ë¼ëŠ” ì—°ê³  ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìŠµì§„ì—"
        # "ë‘í†µì— ë¨¹ì–´ë„ ë˜ë‚˜?" â†’ "ë‘í†µì—"
        # "ìƒì²˜ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìƒì²˜ì—"
        
        # ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë°œë¼ë„\s+ë˜ë‚˜\?',  # "ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë¨¹ì–´ë„\s+ë˜ë‚˜\?',   # "ë‘í†µì— ë¨¹ì–´ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì¨ë„\s+ë˜ë‚˜\?',     # "ìƒì²˜ì— ì¨ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì‚¬ìš©í•´ë„\s+ë˜ë‚˜\?', # "ìƒì²˜ì— ì‚¬ìš©í•´ë„ ë˜ë‚˜?"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, usage_context)
            if match:
                clean_context = match.group(1)
                break
        
        # íŒ¨í„´ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        if clean_context == usage_context:
            clean_context = usage_context.replace("?", "").strip()
    
    # ì‹ ë¢°ë„ ë° ë§¤ì¹­ ê°•ë„ ì •ë³´
    confidence = safety_result.get("confidence_score", 0.7)
    matching = safety_result.get("matching_strength", 50)
    
    # ì‹ ë¢°ë„ ë ˆë²¨ í‘œì‹œ
    if confidence >= 0.8:
        confidence_text = "ë†’ìŒ ğŸŸ¢"
    elif confidence >= 0.5:
        confidence_text = "ì¤‘ê°„ ğŸŸ¡"
    else:
        confidence_text = "ë‚®ìŒ ğŸ”´"
    
    # ìš©ëŸ‰ì£¼ì˜ ì •ë³´ í™•ì¸
    has_dosage_warning = safety_result.get("has_dosage_warning", False)
    prescription_required = safety_result.get("prescription_required", False)
    dosage_warnings = safety_result.get("dosage_warnings", [])
    
    if safety_result["safe_to_use"]:
        response = f"âœ… **{medicine_name}**ì„(ë¥¼) {clean_context} ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **ê°€ëŠ¥**í•©ë‹ˆë‹¤.\n\n"
        response += f"**íŒë‹¨ ê·¼ê±°:** {safety_result['reason']}\n\n"
        response += f"**ì‹ ë¢°ë„:** {confidence_text} (íš¨ëŠ¥ ë§¤ì¹­: {matching}%)\n\n"
        
        # ìš©ëŸ‰ì£¼ì˜ ì •ë³´ ì¶”ê°€
        if has_dosage_warning:
            response += f"**âš ï¸ ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ í¬í•¨:**\n"
            for warning in dosage_warnings:
                response += f"- {warning}\n"
            response += f"\n**ì¤‘ìš”:** ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ì´ í¬í•¨ëœ ì•½í’ˆì€ ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì˜ ì²˜ë°©ì— ë”°ë¼ ì‚¬ìš©í•˜ì„¸ìš”.\n\n"
        
        if safety_result.get("precautions"):
            response += f"**âš ï¸ ì£¼ì˜ì‚¬í•­:** {safety_result['precautions']}\n\n"
    else:
        response = f"âŒ **{medicine_name}**ì„(ë¥¼) {clean_context} ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**.\n\n"
        response += f"**íŒë‹¨ ê·¼ê±°:** {safety_result['reason']}\n\n"
        response += f"**ì‹ ë¢°ë„:** {confidence_text} (íš¨ëŠ¥ ë§¤ì¹­: {matching}%)\n\n"
        
        # ìš©ëŸ‰ì£¼ì˜ ì •ë³´ ì¶”ê°€
        if has_dosage_warning:
            response += f"**âš ï¸ ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ í¬í•¨:**\n"
            for warning in dosage_warnings:
                response += f"- {warning}\n"
            response += f"\n**ì¤‘ìš”:** ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„ì´ í¬í•¨ëœ ì•½í’ˆì€ ë°˜ë“œì‹œ ì˜ì‚¬ë‚˜ ì•½ì‚¬ì˜ ì²˜ë°©ì— ë”°ë¼ ì‚¬ìš©í•˜ì„¸ìš”.\n\n"
        
        if safety_result.get("precautions"):
            response += f"**âš ï¸ ì£¼ì˜ì‚¬í•­:** {safety_result['precautions']}\n\n"
        
        if safety_result.get("alternative_suggestion"):
            response += f"**ğŸ’¡ ëŒ€ì•ˆ ì œì•ˆ:** {safety_result['alternative_suggestion']}\n\n"
    
    # ì•½í’ˆ ì •ë³´ ìš”ì•½ ì¶”ê°€
    response += "**ì•½í’ˆ ì •ë³´ ìš”ì•½:**\n"
    response += f"- íš¨ëŠ¥: {medicine_info['íš¨ëŠ¥']}\n"
    response += f"- ë¶€ì‘ìš©: {medicine_info['ë¶€ì‘ìš©']}\n"
    response += f"- ì‚¬ìš©ë²•: {medicine_info['ì‚¬ìš©ë²•']}\n\n"
    
    response += "âš ï¸ **ì¤‘ìš”:** ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ê³¼ ì²˜ë°©ì„ ìœ„í•´ì„œëŠ” ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
    
    return response

def medicine_usage_check_node(state: QAState) -> QAState:
    """ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ë…¸ë“œ"""
    
    # âš ï¸ ì¤‘ìš”: question_refinement_nodeì—ì„œ ë³´ì •ëœ ì•½í’ˆëª…ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    medicine_name = state.get("extracted_medicine_name") or state.get("medicine_name", "")
    usage_context = state.get("usage_context", "")
    
    if not medicine_name or not usage_context:
        state["usage_check_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì•½í’ˆëª…ì´ë‚˜ ì‚¬ìš© ìƒí™© ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state
    
    # ë³´ì •ëœ ì•½í’ˆëª…ìœ¼ë¡œ state ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ë…¸ë“œì—ì„œë„ ì‚¬ìš©í•˜ë„ë¡)
    if state.get("extracted_medicine_name") and state.get("extracted_medicine_name") != state.get("medicine_name"):
        state["medicine_name"] = medicine_name
        print(f"âœ… ë³´ì •ëœ ì•½í’ˆëª…ìœ¼ë¡œ state ì—…ë°ì´íŠ¸: '{state.get('medicine_name', '')}' â†’ '{medicine_name}'")
    
    print(f"ğŸ” ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ì‹œì‘: {medicine_name} â†’ {usage_context}")
    
    # Excel DBì—ì„œë§Œ ê²€ìƒ‰ (PDF DB ì œê±°)
    print("ğŸ“Š Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
    # ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ê²½ìš°(OCR ê²°ê³¼)ì¸ì§€ í™•ì¸
    is_ocr_result = state.get("has_image", False) or state.get("extracted_text") is not None
    medicine_info = find_medicine_info(medicine_name, excel_docs, is_ocr_result)
    
    # ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
    if medicine_info["íš¨ëŠ¥"] == "ì •ë³´ ì—†ìŒ":
        state["usage_check_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{medicine_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ì•½í’ˆëª…ì„ í™•ì¸í•˜ì‹œê±°ë‚˜ ì˜ì‚¬/ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        return state
    
    print(f"âœ… ì•½í’ˆ ì •ë³´ ë°œê²¬: {medicine_info['ì œí’ˆëª…']}")
    print(f"ğŸ“Š ìµœì¢… medicine_info ìƒíƒœ:")
    print(f"  - íš¨ëŠ¥: {medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')[:100]}... (ê¸¸ì´: {len(str(medicine_info.get('íš¨ëŠ¥', '')))})")
    print(f"  - ë¶€ì‘ìš©: {medicine_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')[:100]}... (ê¸¸ì´: {len(str(medicine_info.get('ë¶€ì‘ìš©', '')))})")
    print(f"  - ì‚¬ìš©ë²•: {medicine_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')[:100]}... (ê¸¸ì´: {len(str(medicine_info.get('ì‚¬ìš©ë²•', '')))})")
    
    # ë³‘í•©ëœ ì•½í’ˆ ì •ë³´ë¥¼ stateì— ì €ì¥ (enhanced_rag_systemì—ì„œ ì‚¬ìš©)
    state["merged_medicine_info"] = medicine_info
    print(f"ğŸ’¾ ë³‘í•©ëœ ì•½í’ˆ ì •ë³´ state ì €ì¥ ì™„ë£Œ: {medicine_info.get('ì œí’ˆëª…', '')} (íš¨ëŠ¥: {len(str(medicine_info.get('íš¨ëŠ¥', '')))}ì, ë¶€ì‘ìš©: {len(str(medicine_info.get('ë¶€ì‘ìš©', '')))}ì)")
    
    # ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨
    print("ğŸ” ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨ ì¤‘...")
    safety_result = check_medicine_usage_safety(medicine_info, usage_context)
    
    # ìµœì¢… ì‘ë‹µ ìƒì„±
    print("ğŸ“ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
    final_response = generate_usage_check_response(medicine_name, usage_context, medicine_info, safety_result)
    
    state["usage_check_answer"] = final_response
    
    print("âœ… ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ì™„ë£Œ")
    return state
