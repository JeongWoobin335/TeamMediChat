# medicine_usage_check_node.py

from qa_state import QAState
from retrievers import llm, pdf_structured_docs, excel_docs
from langchain_core.documents import Document
from typing import List, Optional
import json
import re
from cache_manager import cache_manager
from difflib import get_close_matches

def normalize_medicine_name(name: str) -> str:
    """
    ì•½í’ˆëª… ì •ê·œí™” (ìœ ì‚¬ë„ ë§¤ì¹­ì„ ìœ„í•´)
    """
    if not name:
        return ""
    
    # ì†Œë¬¸ì ë³€í™˜
    normalized = name.lower()
    
    # íŠ¹ìˆ˜ë¬¸ì, ê³µë°±, ìˆ«ì ì œê±° (í•œê¸€ê³¼ ì˜ë¬¸ë§Œ ìœ ì§€)
    normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    normalized = re.sub(r'\s+', '', normalized)
    
    return normalized.strip()

def calculate_similarity(str1: str, str2: str) -> float:
    """
    ë‘ ë¬¸ìì—´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    """
    if not str1 or not str2:
        return 0.0
    
    if str1 == str2:
        return 1.0
    
    # ê¸¸ì´ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ
    len_diff = abs(len(str1) - len(str2))
    if len_diff > max(len(str1), len(str2)) * 0.5:
        return 0.0
    
    # Levenshtein distance ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    distance = levenshtein_distance(str1, str2)
    max_len = max(len(str1), len(str2))
    similarity = 1.0 - (distance / max_len)
    
    return similarity

def find_similar_medicine_name(ocr_result: str, medicine_list: List[str], cutoff: float = 0.8) -> Optional[str]:
    """
    OCR ê²°ê³¼ì™€ ìœ ì‚¬í•œ ì•½í’ˆëª… ì°¾ê¸°
    """
    if not ocr_result or not medicine_list:
        return None
    
    # OCR ê²°ê³¼ ì •ê·œí™”
    normalized_ocr = normalize_medicine_name(ocr_result)
    print(f"ğŸ” ì •ê·œí™”ëœ OCR ê²°ê³¼: '{normalized_ocr}'")
    
    # ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ë„ ì •ê·œí™”
    normalized_medicines = [(normalize_medicine_name(med), med) for med in medicine_list]
    
    
    # ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
    best_match = None
    best_similarity = 0.0
    
    for norm, orig in normalized_medicines:
        similarity = calculate_similarity(normalized_ocr, norm)
        
        # ìœ ì‚¬ë„ê°€ ë†’ì€ ê²½ìš°ë§Œ ë¡œê·¸ ì¶œë ¥ (ì„±ëŠ¥ ê°œì„ )
        if similarity > 0.3:
            print(f"ğŸ” '{orig}' ìœ ì‚¬ë„: {similarity:.3f}")
        
        if similarity > best_similarity and similarity >= cutoff:
            best_similarity = similarity
            best_match = orig
    
    if best_match:
        print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
        return best_match
    
    # cutoffë¥¼ ë‚®ì¶°ì„œ ë‹¤ì‹œ ì‹œë„
    if cutoff > 0.5:
        print(f"ğŸ” cutoffë¥¼ ë‚®ì¶°ì„œ ì¬ì‹œë„ (0.5)")
        for norm, orig in normalized_medicines:
            similarity = calculate_similarity(normalized_ocr, norm)
            if similarity > best_similarity and similarity >= 0.5:
                best_similarity = similarity
                best_match = orig
        
        if best_match:
            print(f"âœ… ë‚®ì€ cutoff ë§¤ì¹­ ì„±ê³µ: '{ocr_result}' â†’ '{best_match}' (ìœ ì‚¬ë„: {best_similarity:.3f})")
            return best_match
    
    print(f"âŒ ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨: '{ocr_result}' (ìµœê³  ìœ ì‚¬ë„: {best_similarity:.3f})")
    return None

def find_medicine_info(medicine_name: str, all_docs: List[Document]) -> dict:
    """ì•½í’ˆëª…ìœ¼ë¡œ ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜"""
    medicine_info = {
        "ì œí’ˆëª…": medicine_name,
        "íš¨ëŠ¥": "ì •ë³´ ì—†ìŒ",
        "ë¶€ì‘ìš©": "ì •ë³´ ì—†ìŒ", 
        "ì‚¬ìš©ë²•": "ì •ë³´ ì—†ìŒ",
        "ì£¼ì˜ì‚¬í•­": "ì •ë³´ ì—†ìŒ"
    }
    
    # ì •í™•í•œ ì œí’ˆëª… ë§¤ì¹­ ì‹œë„
    exact_matches = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == medicine_name]
    
    if not exact_matches:
        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì•½í’ˆëª…ì´ í¬í•¨ëœ ê²½ìš°)
        partial_matches = []
        for doc in all_docs:
            doc_name = doc.metadata.get("ì œí’ˆëª…", "")
            if medicine_name in doc_name or doc_name in medicine_name:
                partial_matches.append(doc)
        
        if partial_matches:
            exact_matches = partial_matches
        else:
            # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ì‹œë„
            print(f"ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ì•½í’ˆëª… ë§¤ì¹­ ì‹œë„: '{medicine_name}'")
            
            # ëª¨ë“  ì•½í’ˆëª… ë¦¬ìŠ¤íŠ¸ ìƒì„±
            medicine_list = [doc.metadata.get("ì œí’ˆëª…", "") for doc in all_docs if doc.metadata.get("ì œí’ˆëª…")]
            medicine_list = list(set(medicine_list))  # ì¤‘ë³µ ì œê±°
            
            # ìœ ì‚¬ë„ ë§¤ì¹­ ì‹œë„
            similar_medicine = find_similar_medicine_name(medicine_name, medicine_list, cutoff=0.8)
            if similar_medicine:
                print(f"âœ… ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ: '{medicine_name}' â†’ '{similar_medicine}'")
                # ìœ ì‚¬í•œ ì•½í’ˆëª…ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰
                exact_matches = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == similar_medicine]
                # medicine_infoì˜ ì œí’ˆëª…ì„ ì˜¬ë°”ë¥¸ ì•½í’ˆëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                medicine_info["ì œí’ˆëª…"] = similar_medicine
            else:
                print(f"ğŸ” ìœ ì‚¬ë„ ë§¤ì¹­ ì‹¤íŒ¨: '{medicine_name}'")
                # ê¸°ì¡´ ì •ê·œí™” ë°©ì‹ë„ ì‹œë„
                normalized_medicine = re.sub(r"[^\wê°€-í£]", "", medicine_name.lower())
                for doc in all_docs:
                    doc_name = doc.metadata.get("ì œí’ˆëª…", "")
                    normalized_doc_name = re.sub(r"[^\wê°€-í£]", "", doc_name.lower())
                    if normalized_medicine in normalized_doc_name or normalized_doc_name in normalized_medicine:
                        exact_matches.append(doc)
                        break
    
    if not exact_matches:
        return medicine_info
    
    # ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘
    for doc in exact_matches:
        content = doc.page_content
        doc_type = doc.metadata.get("type", "")
        
        # íš¨ëŠ¥ê³¼ ë¶€ì‘ìš©ì€ main íƒ€ì…ì—ì„œ ì¶”ì¶œ
        if doc_type == "main" or doc_type == "":
            efficacy = extract_field_from_doc(content, "íš¨ëŠ¥")
            side_effects = extract_field_from_doc(content, "ë¶€ì‘ìš©")
            
            if efficacy != "ì •ë³´ ì—†ìŒ":
                medicine_info["íš¨ëŠ¥"] = efficacy
            if side_effects != "ì •ë³´ ì—†ìŒ":
                medicine_info["ë¶€ì‘ìš©"] = side_effects
        
        # ì‚¬ìš©ë²•ì€ usage íƒ€ì…ì—ì„œ ì¶”ì¶œ
        if doc_type == "usage":
            usage = extract_field_from_doc(content, "ì‚¬ìš©ë²•")
            if usage != "ì •ë³´ ì—†ìŒ":
                medicine_info["ì‚¬ìš©ë²•"] = usage
    
    return medicine_info

def extract_field_from_doc(text: str, label: str) -> str:
    """ë¬¸ì„œì—ì„œ íŠ¹ì • í•„ë“œ ì¶”ì¶œ"""
    pattern = rf"\[{label}\]:\s*((?:.|\n)*?)(?=\n\[|\Z)"
    match = re.search(pattern, text)
    return match.group(1).strip() if match else "ì •ë³´ ì—†ìŒ"

def check_medicine_usage_safety(medicine_info: dict, usage_context: str) -> dict:
    """ì•½í’ˆ ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨"""
    
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    cache_key = f"{medicine_info['ì œí’ˆëª…']}_{usage_context}"
    cache_file = cache_manager.matching_cache_dir / f"{cache_key}.pkl"
    
    if cache_file.exists():
        try:
            import pickle
            with open(cache_file, 'rb') as f:
                cached_result = pickle.load(f)
            print(f"ğŸ“‚ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ íˆíŠ¸: {cache_key}")
            return cached_result
        except Exception as e:
            print(f"âŒ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ìºì‹œì— ì—†ìœ¼ë©´ None ë°˜í™˜
    cached_result = None
    
    # LLMì„ ì‚¬ìš©í•œ ì•ˆì „ì„± íŒë‹¨
    prompt = f"""
ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ì•ˆì „ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì•½í’ˆì„ ì£¼ì–´ì§„ ìƒí™©ì—ì„œ ì‚¬ìš©í•´ë„ ì•ˆì „í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**ì•½í’ˆ ì •ë³´:**
- ì œí’ˆëª…: {medicine_info['ì œí’ˆëª…']}
- íš¨ëŠ¥: {medicine_info['íš¨ëŠ¥']}
- ë¶€ì‘ìš©: {medicine_info['ë¶€ì‘ìš©']}
- ì‚¬ìš©ë²•: {medicine_info['ì‚¬ìš©ë²•']}

**ì‚¬ìš© ìƒí™©:**
{usage_context}

**íŒë‹¨ ê¸°ì¤€:**
1. ì•½í’ˆì˜ íš¨ëŠ¥ì´ í•´ë‹¹ ìƒí™©ì— ì í•©í•œê°€?
   - íš¨ëŠ¥ì— ëª…ì‹œëœ ì¦ìƒ/ìƒí™©ê³¼ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ìƒí™©ì´ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ê°€?
   - ì˜ˆ: "ìœ¡ì²´í”¼ë¡œ" â†” "í”¼ê³¤í•  ë•Œ", "ë‘í†µ" â†” "ë¨¸ë¦¬ê°€ ì•„í”Œ ë•Œ", "ê°ê¸°" â†” "ê°ê¸°ì— ê±¸ë ¸ì„ ë•Œ"
2. ë¶€ì‘ìš©ì´ í•´ë‹¹ ìƒí™©ì—ì„œ ìœ„í—˜í•˜ì§€ ì•Šì€ê°€?
3. ì‚¬ìš©ë²•ì´ ì˜¬ë°”ë¥¸ê°€?
4. íŠ¹ë³„í•œ ì£¼ì˜ì‚¬í•­ì´ ìˆëŠ”ê°€?

**ì¤‘ìš”í•œ ì§€ì¹¨:**
- íš¨ëŠ¥ ì •ë³´ë¥¼ ê¼¼ê¼¼íˆ ë¶„ì„í•˜ì—¬ ì‚¬ìš© ìƒí™©ê³¼ì˜ ì—°ê´€ì„±ì„ ì°¾ìœ¼ì„¸ìš”
- ë™ì˜ì–´ë‚˜ ìœ ì‚¬í•œ í‘œí˜„ì„ ê³ ë ¤í•˜ì„¸ìš” (ì˜ˆ: í”¼ë¡œ â†” í”¼ê³¤í•¨, ë‘í†µ â†” ë¨¸ë¦¬ ì•„í””, ìŠµì§„ â†” í”¼ë¶€ì—¼ â†” ì•„í† í”¼)
- ì˜í•™ì ìœ¼ë¡œ ê´€ë ¨ëœ ì¦ìƒë“¤ì„ ì˜ë¯¸ì ìœ¼ë¡œ ì´í•´í•˜ì„¸ìš” (ì˜ˆ: ìŠµì§„, ì•„í† í”¼, í”¼ë¶€ì—¼, ë°œì§„, ê°€ë ¤ì›€ ë“±ì€ ëª¨ë‘ í”¼ë¶€ ê´€ë ¨)
- ì•½í’ˆì˜ ì£¼ìš” íš¨ëŠ¥ì´ ì‚¬ìš© ìƒí™©ê³¼ ì¼ì¹˜í•˜ë©´ ì‚¬ìš© ê°€ëŠ¥ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”
- ë¶€ì‘ìš©ì´ ì‹¬ê°í•˜ì§€ ì•Šê³  ì‚¬ìš©ë²•ì´ ì ì ˆí•˜ë©´ ì‚¬ìš© ê°€ëŠ¥ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”
- ëª…í™•í•œ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "safe_to_use": true/false,
    "reason": "ì‚¬ìš© ê°€ëŠ¥/ë¶ˆê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì´ìœ  (íš¨ëŠ¥ê³¼ ì‚¬ìš© ìƒí™©ì˜ ì—°ê´€ì„± í¬í•¨)",
    "precautions": "ì£¼ì˜ì‚¬í•­ (ìˆëŠ” ê²½ìš°)",
    "alternative_suggestion": "ëŒ€ì•ˆ ì œì•ˆ (í•„ìš”í•œ ê²½ìš°)"
}}
"""
    
    try:
        response = llm.invoke(prompt).content.strip()
        print(f"ğŸ” LLM ì‘ë‹µ: {response[:200]}...")
        
        # JSON ì‘ë‹µ íŒŒì‹± (```json ì œê±° ì²˜ë¦¬)
        try:
            # ```jsonê³¼ ``` ì œê±°
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end != -1:
                    response = response[json_start:json_end].strip()
            elif "```" in response:
                json_start = response.find("```") + 3
                json_end = response.find("```", json_start)
                if json_end != -1:
                    response = response[json_start:json_end].strip()
            
            result = json.loads(response)
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {result}")
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ğŸ” ì›ë³¸ ì‘ë‹µ: {response}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            result = {
                "safe_to_use": False,
                "reason": "ì•½í’ˆ ì •ë³´ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "precautions": "ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.",
                "alternative_suggestion": ""
            }
        
        # ìºì‹œì— ì €ì¥
        try:
            import pickle
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            print(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ ì €ì¥ë¨: {cache_key}")
        except Exception as e:
            print(f"âŒ ì‚¬ìš© ê°€ëŠ¥ì„± ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì•½í’ˆ ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "safe_to_use": False,
            "reason": "ì•ˆì „ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "precautions": "ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”.",
            "alternative_suggestion": ""
        }

def generate_usage_check_response(medicine_name: str, usage_context: str, medicine_info: dict, safety_result: dict) -> str:
    """ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì‘ë‹µìœ¼ë¡œ ë³€í™˜"""
    
    # usage_contextì—ì„œ ì§ˆë¬¸ í˜•íƒœì˜ ë¬¸ì¥ì„ ì •ë¦¬í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
    clean_context = usage_context
    if "?" in usage_context:
        import re
        # ì§ˆë¬¸ í˜•íƒœì—ì„œ í•µì‹¬ ì¦ìƒ/ìƒí™©ë§Œ ì¶”ì¶œ
        # "ì´ ì—°ê³  ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìŠµì§„ì—"
        # "ë°•í…Œë¡œì‹ ì´ë¼ëŠ” ì—°ê³  ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìŠµì§„ì—"
        # "ë‘í†µì— ë¨¹ì–´ë„ ë˜ë‚˜?" â†’ "ë‘í†µì—"
        # "ìƒì²˜ì— ë°œë¼ë„ ë˜ë‚˜?" â†’ "ìƒì²˜ì—"
        
        # ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë°œë¼ë„\s+ë˜ë‚˜\?',  # "ìŠµì§„ì— ë°œë¼ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ë¨¹ì–´ë„\s+ë˜ë‚˜\?',   # "ë‘í†µì— ë¨¹ì–´ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì¨ë„\s+ë˜ë‚˜\?',     # "ìƒì²˜ì— ì¨ë„ ë˜ë‚˜?"
            r'([ê°€-í£]+ì—)\s+[ê°€-í£\s]*ì‚¬ìš©í•´ë„\s+ë˜ë‚˜\?', # "ìƒì²˜ì— ì‚¬ìš©í•´ë„ ë˜ë‚˜?"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, usage_context)
            if match:
                clean_context = match.group(1)
                break
        
        # íŒ¨í„´ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        if clean_context == usage_context:
            clean_context = usage_context.replace("?", "").strip()
    
    if safety_result["safe_to_use"]:
        response = f"âœ… **{medicine_name}**ì„(ë¥¼) {clean_context} ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **ê°€ëŠ¥**í•©ë‹ˆë‹¤.\n\n"
        response += f"**ì´ìœ :** {safety_result['reason']}\n\n"
        
        if safety_result.get("precautions"):
            response += f"**ì£¼ì˜ì‚¬í•­:** {safety_result['precautions']}\n\n"
    else:
        response = f"âŒ **{medicine_name}**ì„(ë¥¼) {clean_context} ì‚¬ìš©í•˜ëŠ” ê²ƒì€ **ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**.\n\n"
        response += f"**ì´ìœ :** {safety_result['reason']}\n\n"
        
        if safety_result.get("precautions"):
            response += f"**ì£¼ì˜ì‚¬í•­:** {safety_result['precautions']}\n\n"
        
        if safety_result.get("alternative_suggestion"):
            response += f"**ëŒ€ì•ˆ ì œì•ˆ:** {safety_result['alternative_suggestion']}\n\n"
    
    # ì•½í’ˆ ì •ë³´ ìš”ì•½ ì¶”ê°€
    response += "**ì•½í’ˆ ì •ë³´ ìš”ì•½:**\n"
    response += f"- íš¨ëŠ¥: {medicine_info['íš¨ëŠ¥']}\n"
    response += f"- ë¶€ì‘ìš©: {medicine_info['ë¶€ì‘ìš©']}\n"
    response += f"- ì‚¬ìš©ë²•: {medicine_info['ì‚¬ìš©ë²•']}\n\n"
    
    response += "âš ï¸ **ì¤‘ìš”:** ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ê³¼ ì²˜ë°©ì„ ìœ„í•´ì„œëŠ” ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
    
    return response

def medicine_usage_check_node(state: QAState) -> QAState:
    """ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ë…¸ë“œ"""
    
    medicine_name = state.get("medicine_name", "")
    usage_context = state.get("usage_context", "")
    
    if not medicine_name or not usage_context:
        state["usage_check_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì•½í’ˆëª…ì´ë‚˜ ì‚¬ìš© ìƒí™© ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state
    
    print(f"ğŸ” ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ì‹œì‘: {medicine_name} â†’ {usage_context}")
    
    # Excel DBì—ì„œ ë¨¼ì € ê²€ìƒ‰
    print("ğŸ“Š Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    # Excelì—ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° PDFì—ì„œ ê²€ìƒ‰
    if medicine_info["íš¨ëŠ¥"] == "ì •ë³´ ì—†ìŒ":
        print("ğŸ“„ PDF DBì—ì„œ ì•½í’ˆ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
        pdf_medicine_info = find_medicine_info(medicine_name, pdf_structured_docs)
        
        # PDFì—ì„œ ì°¾ì€ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸
        if pdf_medicine_info["íš¨ëŠ¥"] != "ì •ë³´ ì—†ìŒ":
            medicine_info = pdf_medicine_info
            print(f"âœ… PDFì—ì„œ {medicine_name} ì •ë³´ ë°œê²¬")
        else:
            print(f"âŒ {medicine_name} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    
    # ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
    if medicine_info["íš¨ëŠ¥"] == "ì •ë³´ ì—†ìŒ":
        state["usage_check_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{medicine_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ì•½í’ˆëª…ì„ í™•ì¸í•˜ì‹œê±°ë‚˜ ì˜ì‚¬/ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        return state
    
    print(f"âœ… ì•½í’ˆ ì •ë³´ ë°œê²¬: {medicine_info['ì œí’ˆëª…']}")
    
    # ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨
    print("ğŸ” ì‚¬ìš© ì•ˆì „ì„± íŒë‹¨ ì¤‘...")
    safety_result = check_medicine_usage_safety(medicine_info, usage_context)
    
    # ìµœì¢… ì‘ë‹µ ìƒì„±
    print("ğŸ“ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...")
    final_response = generate_usage_check_response(medicine_name, usage_context, medicine_info, safety_result)
    
    state["usage_check_answer"] = final_response
    
    print("âœ… ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ ì™„ë£Œ")
    return state
