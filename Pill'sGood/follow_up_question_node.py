# follow_up_question_node.py - ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ë…¸ë“œ

from qa_state import QAState
from retrievers import llm, excel_docs, find_products_by_ingredient
from entity_classifier import classify_medicine_vs_ingredient, extract_target_from_query
from config import PromptConfig
from prompt_utils import (
    get_role_definition, get_common_instructions, get_source_mention_examples,
    get_medical_consultation_footer
)
from typing import Dict, List, Optional
import re
import json

# YouTube ê²€ìƒ‰ í•¨ìˆ˜ import
from sns_node import search_youtube_videos, get_video_transcript, summarize_video_content

def search_youtube_for_followup(target: str, intent_type: str) -> List[Dict]:
    """ì—°ì† ì§ˆë¬¸ìš© YouTube ê²€ìƒ‰ (ì˜ë„ì— ë§ê²Œ)"""
    try:
        # ì˜ë„ì— ë”°ë¼ ê²€ìƒ‰ì–´ ìƒì„± (ë‹¨ìˆœí•˜ê³  ëª…ë£Œí•˜ê²Œ)
        if intent_type == "ingredient_info":
            search_queries = [
                f"{target}",  # ì„±ë¶„ëª…ë§Œ
            ]
        elif intent_type == "usage_info":
            search_queries = [
                f"{target}",  # ì•½í’ˆëª…ë§Œ
            ]
        elif intent_type == "side_effect":
            search_queries = [
                f"{target} ë¶€ì‘ìš©",  # ë¶€ì‘ìš©ì€ ëª…ì‹œì ìœ¼ë¡œ ê²€ìƒ‰
            ]
        else:
            search_queries = [
                f"{target}",  # ê¸°ë³¸ì€ ë‹¨ìˆœí•˜ê²Œ
            ]
        
        collected_videos = []
        
        # ê° ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰
        for query in search_queries:
            try:
                videos = search_youtube_videos(query, max_videos=4)
                
                for video in videos:
                    # ìë§‰ ì¶”ì¶œ
                    transcript = get_video_transcript(video["video_id"])
                    
                    if transcript:
                        summary = summarize_video_content(transcript, max_length=400)
                        video['transcript'] = transcript
                        video['summary'] = summary
                        video['has_transcript'] = True
                    else:
                        video['transcript'] = ''
                        video['summary'] = f"{video['title']} - {video.get('description', '')[:150]}"
                        video['has_transcript'] = False
                    
                    collected_videos.append(video)
                    
            except Exception as e:
                print(f"  âš ï¸ '{query}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        # ì¤‘ë³µ ì œê±° (video_id ê¸°ì¤€)
        unique_videos = {}
        for video in collected_videos:
            vid = video["video_id"]
            if vid not in unique_videos:
                unique_videos[vid] = video
        
        return list(unique_videos.values())[:5]  # ìµœëŒ€ 5ê°œë¡œ ì¦ê°€
        
    except Exception as e:
        print(f"âŒ YouTube ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

def follow_up_question_node(state: QAState) -> QAState:
    """ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ë…¸ë“œ - ì´ì „ ë‹µë³€ì˜ ë§¥ë½ì„ í™œìš©í•œ ì¶”ê°€ ì§ˆë¬¸ ì²˜ë¦¬"""
    
    follow_up_type = state.get("follow_up_type", "")
    conversation_context = state.get("conversation_context", "")
    current_query = state.get("query", "")
    
    print(f"ğŸ” ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {follow_up_type}")
    print(f"ğŸ” í˜„ì¬ ì§ˆë¬¸: {current_query}")
    
    try:
        # ğŸ” í˜„ì¬ ì§ˆë¬¸ì„ LLMì´ ì§ì ‘ ë¶„ì„í•˜ì—¬ ì˜ë„ íŒŒì•…
        answer = analyze_and_respond_to_followup(current_query, conversation_context, follow_up_type)
        
        if answer:
            state["final_answer"] = answer
            print(f"âœ… ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ: {follow_up_type}")
            return state
        
        # LLM ë¶„ì„ì´ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        print("âš ï¸ LLM ë¶„ì„ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬")
        
        # ë””ë²„ê¹…: stateì— ì €ì¥ëœ ê°’ í™•ì¸
        extracted_ingredient = state.get("extracted_ingredient_name")
        extracted_medicine = state.get("extracted_medicine_name")
        medicine_name_from_state = state.get("medicine_name")
        print(f"ğŸ” state í™•ì¸ - extracted_ingredient_name: {extracted_ingredient}")
        print(f"ğŸ” state í™•ì¸ - extracted_medicine_name: {extracted_medicine}")
        print(f"ğŸ” state í™•ì¸ - medicine_name: {medicine_name_from_state}")
        
        # ë¨¼ì € stateì— ì´ë¯¸ ì €ì¥ëœ ì•½í’ˆëª…/ì„±ë¶„ëª… í™•ì¸ (question_refinement_nodeì—ì„œ ì¶”ì¶œí•œ ê°’)
        medicine_name = extracted_ingredient or extracted_medicine or medicine_name_from_state
        
        if medicine_name:
            print(f"âœ… stateì—ì„œ ì•½í’ˆëª…/ì„±ë¶„ëª… ë°œê²¬: {medicine_name}")
        else:
            # ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª… ì¶”ì¶œ
            medicine_name = extract_medicine_from_context(conversation_context)
            
            # ëŒ€í™” ë§¥ë½ì—ì„œ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            if not medicine_name:
                medicine_name = extract_medicine_from_user_question(current_query)
        
        if not medicine_name:
            state["final_answer"] = "ì•„, ì–´ë–¤ ì•½í’ˆì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ì§€ ëª…í™•í•˜ì§€ ì•Šë„¤ìš”! ì•½í’ˆëª…ì„ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ê²Œìš”!"
            return state
            
        print(f"ğŸ” ì¶”ì¶œëœ ì•½í’ˆëª…: {medicine_name}")
        
        # ì—°ì† ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
        if follow_up_type == "usage":
            answer = handle_usage_question(medicine_name, conversation_context)
        elif follow_up_type == "ingredient":
            # í˜„ì¬ ì§ˆë¬¸ì„ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
            full_context = f"{conversation_context}\nì‚¬ìš©ì: {current_query}" if current_query else conversation_context
            answer = handle_ingredient_question(medicine_name, full_context)
        elif follow_up_type == "side_effect":
            answer = handle_side_effect_question(medicine_name, conversation_context)
        elif follow_up_type == "mechanism":
            answer = handle_mechanism_question(medicine_name, conversation_context)
        elif follow_up_type == "precaution":
            answer = handle_precaution_question(medicine_name, conversation_context)
        elif follow_up_type == "alternative_medicines":
            answer = handle_alternative_medicines_question(medicine_name, conversation_context, current_query)
        elif follow_up_type == "similar_medicines":
            answer = handle_similar_medicines_question(medicine_name, conversation_context, current_query)
        else:
            answer = handle_general_question(medicine_name, conversation_context, current_query)
        
        state["final_answer"] = answer
        print(f"âœ… ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ: {follow_up_type}")
        
    except Exception as e:
        print(f"âŒ ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        state["final_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    return state

def extract_usage_context_from_query(current_query: str, conversation_context: str) -> str:
    """ì§ˆë¬¸ê³¼ ëŒ€í™” ë§¥ë½ì—ì„œ ì‚¬ìš© ëª©ì ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ì¶”ì¶œ"""
    
    context_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ê³¼ ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆì˜ ì‚¬ìš© ëª©ì ì´ë‚˜ ì¦ìƒì„ íŒŒì•…í•´ì£¼ì„¸ìš”.

**ì´ì „ ëŒ€í™”:**
{conversation_context[:600]}

**í˜„ì¬ ì§ˆë¬¸:**
{current_query}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ì¦ìƒì´ë‚˜ ìƒí™© íŒŒì•…
2. ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì¦ìƒì´ë‚˜ ìƒí™© ê³ ë ¤
3. êµ¬ì²´ì ì¸ ì‚¬ìš© ëª©ì  ì¶”ì¶œ

**ê°€ëŠ¥í•œ ì‚¬ìš© ë§¥ë½ ì˜ˆì‹œ:**
- ê°ê¸° (ê°ê¸°, ëª¸ì‚´, ì¸í›„í†µ, ê¸°ì¹¨, ì½§ë¬¼ ë“±)
- ë‘í†µ (ë¨¸ë¦¬ì•„í””, í¸ë‘í†µ ë“±)
- ì¹˜í†µ (ì¹˜ì•„ í†µì¦, ì‡ëª¸ ì•„í”” ë“±)
- ìƒë¦¬í†µ (ì›”ê²½í†µ, ìƒë¦¬ ë“±)
- ê·¼ìœ¡í†µ (ì–´ê¹¨ í†µì¦, ìš”í†µ, ëª© ì•„í”” ë“±)
- ê´€ì ˆí†µ (ë¬´ë¦ ì•„í””, ê´€ì ˆì—¼ ë“±)
- ë°œì—´ (ì—´, ê³ ì—´ ë“±)
- ì†Œí™”ë¶ˆëŸ‰ (ì†ì“°ë¦¼, ìœ„ì¥ì¥ì•  ë“±)
- ìƒì²˜ (ìƒì²˜, ì™¸ìƒ, ì—¼ì¦ ë“±)
- ìŠµì§„ (ìŠµì§„, í”¼ë¶€ì—¼, ë°œì§„, ê°€ë ¤ì›€ ë“±ë“±)
- ì¼ë°˜ì  ì‚¬ìš© (êµ¬ì²´ì  ì¦ìƒì´ ì—†ëŠ” ê²½ìš°)

í•œ ë‹¨ì–´ë‚˜ ê°„ë‹¨í•œ êµ¬ë¬¸ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì˜ˆ: "ê°ê¸°", "ë‘í†µ", "ê·¼ìœ¡í†µ", "ì¼ë°˜ì  ì‚¬ìš©"
"""
    
    try:
        response = llm.invoke(context_prompt)
        usage_context = response.content.strip().replace('"', '').replace("'", "")
        
        # ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ ì‚¬ìš©
        if len(usage_context) > 20:
            usage_context = usage_context.split()[0] if usage_context.split() else "ì¼ë°˜ì  ì‚¬ìš©"
        
        print(f"ğŸ” ì¶”ì¶œëœ ì‚¬ìš© ë§¥ë½: '{usage_context}'")
        return usage_context if usage_context else "ì¼ë°˜ì  ì‚¬ìš©"
        
    except Exception as e:
        print(f"âš ï¸ ì‚¬ìš© ë§¥ë½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "ì¼ë°˜ì  ì‚¬ìš©"

def analyze_and_respond_to_followup(current_query: str, conversation_context: str, follow_up_type: str) -> Optional[str]:
    """ì—°ì† ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì‹¤ì œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ë‹µë³€í•˜ëŠ” í†µí•© í•¨ìˆ˜"""
    if not current_query or not conversation_context:
        return None
    
    print(f"ğŸ§  ì—°ì† ì§ˆë¬¸ ë¶„ì„ ë° ë°ì´í„° ì¡°íšŒ ì‹œì‘")
    print(f"ğŸ” ì§ˆë¬¸ ìœ í˜•: {follow_up_type}")
    
    # 1ë‹¨ê³„: ì§ˆë¬¸ ì˜ë„ ë° í•„ìš”í•œ ì •ë³´ ë¶„ì„
    intent_analysis = analyze_question_intent(current_query, conversation_context)
    if not intent_analysis:
        return None
    
    print(f"ğŸ¯ ì§ˆë¬¸ ì˜ë„: {intent_analysis.get('intent_type', 'unknown')}")
    print(f"ğŸ” ëŒ€ìƒ: {intent_analysis.get('target', 'unknown')}")
    
    # 2ë‹¨ê³„: ì˜ë„ì— ë”°ë¥¸ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
    collected_data = collect_relevant_data(intent_analysis, current_query, conversation_context)
    
    # 3ë‹¨ê³„: ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±
    if collected_data:
        answer = generate_data_driven_answer(current_query, conversation_context, collected_data, intent_analysis)
        if answer:
            print(f"âœ… ë°ì´í„° ê¸°ë°˜ ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
            return answer
    
    print("âš ï¸ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ê¸°ë³¸ LLM ë‹µë³€ìœ¼ë¡œ fallback")
    return None

def analyze_question_intent(current_query: str, conversation_context: str) -> Optional[Dict]:
    """ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ ëŒ€ìƒì„ íŒŒì•…"""
    
    analysis_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í™” ë§¥ë½ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

## ğŸ“‹ ëŒ€í™” ì •ë³´
**ì´ì „ ëŒ€í™”:**
{conversation_context[:800]}

**í˜„ì¬ ì§ˆë¬¸:**
{current_query}

## ğŸ” 3ë‹¨ê³„ ì˜ë„ ë¶„ì„ í”„ë¡œì„¸ìŠ¤

### STEP 1: ì§ˆë¬¸ ìœ í˜• ì‹ë³„
ë‹¤ìŒ ì¤‘ ì–´ë””ì— í•´ë‹¹í•˜ëŠ”ê°€?
- ingredient_info: ì„±ë¶„ ì„¤ëª… ìš”ì²­ ("~ì´ ë­”ë°?", "~ì´ ë­ì•¼?")
- usage_info: ì‚¬ìš©ë²• ì§ˆë¬¸ ("ì–´ë–»ê²Œ ë¨¹ì–´?", "ì‚¬ìš©ë²•ì€?")
- side_effect: ë¶€ì‘ìš© ì§ˆë¬¸ ("ë¶€ì‘ìš©ì€?", "ì£¼ì˜ì‚¬í•­ì€?")
- new_medicine: ìƒˆ ì•½í’ˆ ì§ˆë¬¸ (ì´ì „ê³¼ ë‹¤ë¥¸ ì•½í’ˆëª… ë“±ì¥)
- general: ê¸°íƒ€

**íŒë‹¨ ê¸°ì¤€:**
- ìƒˆ ì•½í’ˆ: ì´ì „ ëŒ€í™”ì— ì—†ë˜ ì•½í’ˆëª… ë“±ì¥
- ì„±ë¶„: "~ì´ ë­", "~ì´ ë­”", "~ë¬´ì—‡" íŒ¨í„´
- ì‚¬ìš©ë²•: "ì–´ë–»ê²Œ", "ì‚¬ìš©ë²•", "ë³µìš©ë²•"
- ë¶€ì‘ìš©: "ë¶€ì‘ìš©", "ì£¼ì˜ì‚¬í•­", "ìœ„í—˜"

### STEP 2: ëŒ€ìƒ ì¶”ì¶œ
ëˆ„êµ¬/ë¬´ì—‡ì— ëŒ€í•œ ì§ˆë¬¸ì¸ê°€?
- ì•½í’ˆëª… ë˜ëŠ” ì„±ë¶„ëª… ì¶”ì¶œ
- ì—¬ëŸ¬ ëŒ€ìƒì´ë©´ ì‰¼í‘œë¡œ êµ¬ë¶„

**ì¶”ì¶œ ì˜ˆì‹œ:**
- "í‘¸ë¥´ì„¤í‹°ì•„ë¯¼ì´ ë­”ë°?" â†’ "í‘¸ë¥´ì„¤í‹°ì•„ë¯¼"
- "ê·¸ëŸ¼ ë‡Œì„ ì€?" â†’ "ë‡Œì„ "
- "íƒ€ì´ë ˆë†€ ì‚¬ìš©ë²•ì€?" â†’ "íƒ€ì´ë ˆë†€"

### STEP 3: ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
í•„ìš”í•œ ì •ë³´ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:

**ê¸°ë³¸ (í•­ìƒ í¬í•¨):**
- excel_db: í•œêµ­ ì•½í’ˆ ê¸°ë³¸ ì •ë³´
- youtube: ì „ë¬¸ê°€ ì˜ê²¬/ê²½í—˜ë‹´/ì¶”ê°€ ì •ë³´ (ëª¨ë“  ì§ˆë¬¸ì— í¬í•¨)

**ì¶”ê°€ (ì¡°ê±´ë¶€):**
- enhanced_rag: ìƒˆ ì•½í’ˆ ì¢…í•© ë¶„ì„ (new_medicineì¼ ë•Œ)
- health_kr + pubchem: ì„±ë¶„ ìƒì„¸ ì •ë³´ (ingredient_infoì¼ ë•Œ)

**ì„ íƒ ë¡œì§:**
- new_medicine â†’ excel_db + youtube + enhanced_rag
- ingredient_info â†’ excel_db + youtube + health_kr + pubchem
- usage_info â†’ excel_db + youtube
- side_effect â†’ excel_db + youtube
- general â†’ excel_db + youtube

## ğŸ’¡ ë¶„ì„ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: "í‘¸ë¥´ì„¤í‹°ì•„ë¯¼ì´ ë­”ë°?"
STEP 1: ingredient_info (ì„±ë¶„ ì„¤ëª… ìš”ì²­)
STEP 2: ëŒ€ìƒ = "í‘¸ë¥´ì„¤í‹°ì•„ë¯¼"
STEP 3: ["excel_db", "youtube", "health_kr", "pubchem"]

### ì˜ˆì‹œ 2: "ê·¸ëŸ¼ ë‡Œì„ ì€ ê°ê¸°ì— ë¨¹ì–´ë„ ë˜ë‚˜?"
STEP 1: new_medicine (ì´ì „ ëŒ€í™”ì™€ ë‹¤ë¥¸ ì•½í’ˆ)
STEP 2: ëŒ€ìƒ = "ë‡Œì„ "
STEP 3: ["excel_db", "youtube", "enhanced_rag"]

### ì˜ˆì‹œ 3: "ê·¸ëŸ¼ ë¶€ì‘ìš©ì€?"
STEP 1: side_effect
STEP 2: ëŒ€ìƒ = [ì´ì „ ëŒ€í™”ì˜ ì•½í’ˆëª…]
STEP 3: ["excel_db", "youtube"]

### ì˜ˆì‹œ 4: "ì‚¬ìš©ë²•ì€?"
STEP 1: usage_info
STEP 2: ëŒ€ìƒ = [ì´ì „ ëŒ€í™”ì˜ ì•½í’ˆëª…]
STEP 3: ["excel_db", "youtube"]

## ğŸ“¤ ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "intent_type": "ingredient_info|usage_info|side_effect|new_medicine|general",
    "target": "ëŒ€ìƒ ì´ë¦„",
    "data_sources": ["excel_db", ...],
    "specific_info_needed": "êµ¬ì²´ì  ì •ë³´ ìš”êµ¬ì‚¬í•­",
    "is_new_medicine": true/false
}}

**ì¤‘ìš”:** ê°„ê²°í•˜ê²Œ íŒë‹¨í•˜ê³ , ë¶ˆí•„ìš”í•œ ì†ŒìŠ¤ëŠ” ì œì™¸í•˜ì„¸ìš”.
"""
    
    try:
        response = llm.invoke(analysis_prompt)
        content = response.content.strip()
        
        # JSON íŒŒì‹±
        if content.startswith("```json"):
            content = content[7:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        import json
        result = json.loads(content)
        print(f"ğŸ¯ ì˜ë„ ë¶„ì„ ê²°ê³¼: {result}")
        return result
        
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def collect_relevant_data(intent_analysis: Dict, current_query: str, conversation_context: str = "") -> Optional[Dict]:
    """ì˜ë„ ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘"""
    
    intent_type = intent_analysis.get("intent_type", "")
    target = intent_analysis.get("target", "")
    data_sources = intent_analysis.get("data_sources", [])
    
    collected_data = {}
    
    print(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {intent_type} - {target}")
    print(f"ğŸ” ìš”ì²­ëœ ë°ì´í„° ì†ŒìŠ¤: {data_sources}")
    
    try:
        # Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘ (ëª¨ë“  íƒ€ì…ì— ëŒ€í•´)
        if "excel_db" in data_sources and target:
            # ì—¬ëŸ¬ ì•½í’ˆëª…ì´ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            medicine_names = [name.strip() for name in target.split(',') if name.strip()]
            print(f"ğŸ“‹ Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘: {medicine_names}")
            
            excel_info_list = []
            for medicine_name in medicine_names:
                print(f"  ê°œë³„ ì•½í’ˆ ì¡°íšŒ: {medicine_name}")
                excel_info = find_medicine_info(medicine_name, excel_docs)
                print(f"  ì¡°íšŒ ê²°ê³¼: {excel_info}")
                if excel_info and excel_info.get("ì œí’ˆëª…") != "ì •ë³´ ì—†ìŒ":
                    excel_info_list.append(excel_info)
                    print(f"  âœ… {medicine_name} ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    print(f"  âŒ {medicine_name} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            if excel_info_list:
                collected_data["excel_info"] = excel_info_list
                print(f"âœ… Excel DB ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(excel_info_list)}ê°œ ì•½í’ˆ")
            else:
                print(f"âŒ Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        else:
            print(f"âš ï¸ Excel DB ì¡°íšŒ ì¡°ê±´ ë¯¸ì¶©ì¡±: excel_db in data_sources={('excel_db' in data_sources)}, target={bool(target)}")
        
        # Enhanced RAG ì‹œìŠ¤í…œ í˜¸ì¶œ (ìƒˆë¡œìš´ ì•½í’ˆì¸ ê²½ìš°)
        if "enhanced_rag" in data_sources and target:
            # ì—¬ëŸ¬ ì•½í’ˆëª…ì´ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            medicine_names = [name.strip() for name in target.split(',') if name.strip()]
            print(f"ğŸ”¬ Enhanced RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì•½í’ˆ ì¢…í•© ë¶„ì„ ì¤‘: {medicine_names}")
            
            try:
                from enhanced_rag_system import EnhancedRAGSystem
                enhanced_rag_system = EnhancedRAGSystem()
                
                # ì‚¬ìš© ë§¥ë½ ì§€ëŠ¥ì  ì¶”ì¶œ
                usage_context = extract_usage_context_from_query(current_query, conversation_context)
                
                enhanced_analysis_list = []
                for medicine_name in medicine_names:
                    print(f"  ê°œë³„ ì•½í’ˆ ë¶„ì„: {medicine_name}")
                    enhanced_analysis = enhanced_rag_system.analyze_medicine_comprehensively(medicine_name, usage_context)
                    if enhanced_analysis:
                        enhanced_analysis_list.append(enhanced_analysis)
                        print(f"  âœ… {medicine_name} ë¶„ì„ ì™„ë£Œ")
                    else:
                        print(f"  âŒ {medicine_name} ë¶„ì„ ì‹¤íŒ¨")
                
                if enhanced_analysis_list:
                    collected_data["enhanced_rag_info"] = enhanced_analysis_list
                    print(f"âœ… Enhanced RAG ì¢…í•© ë¶„ì„ ì™„ë£Œ: {len(enhanced_analysis_list)}ê°œ ì•½í’ˆ")
            except Exception as e:
                print(f"âš ï¸ Enhanced RAG ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ì„±ë¶„ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ì™¸ë¶€ API í˜¸ì¶œ
        if intent_type == "ingredient_info" and target:
            print(f"ğŸ§ª ì„±ë¶„ ì •ë³´ ìˆ˜ì§‘: {target}")
            
            # ì™¸ë¶€ ì•½í•™ì •ë³´ì› ìŠ¤í¬ë˜í•‘ ì œê±° (ì €ì‘ê¶Œ ë¬¸ì œ, Excel DB ì‚¬ìš©)
            
            # PubChem ì •ë³´ ìˆ˜ì§‘ + ë²ˆì—­ (í•µì‹¬!)
            if "pubchem" in data_sources:
                try:
                    from pubchem_api import PubChemAPI
                    from translation_rag import TranslationRAG
                    
                    pubchem = PubChemAPI()
                    pubchem_info = pubchem.analyze_ingredient_comprehensive(target)
                    
                    if pubchem_info:
                        collected_data["pubchem_info"] = pubchem_info
                        print(f"âœ… PubChem ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
                        
                        # ğŸ†• ë²ˆì—­ ì¶”ê°€ (ê°€ì¥ ì¤‘ìš”!)
                        print(f"ğŸ”„ PubChem ì •ë³´ ë²ˆì—­ ì¤‘...")
                        translation_rag = TranslationRAG()
                        translated_info = translation_rag.translate_pharmacology_info(
                            pubchem_info.get('pharmacology_info', {})
                        )
                        
                        if translated_info:
                            collected_data["translated_pubchem_info"] = translated_info
                            print(f"âœ… PubChem ì •ë³´ ë²ˆì—­ ì™„ë£Œ (ìš”ì•½ ê¸¸ì´: {len(translated_info.get('summary_kr', ''))}ì)")
                        
                except Exception as e:
                    print(f"âš ï¸ PubChem ì •ë³´ ìˆ˜ì§‘/ë²ˆì—­ ì‹¤íŒ¨: {e}")
            
            # ğŸ†• ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆ ëª©ë¡ ì¶”ê°€ (ì¤‘ìš”!)
            print(f"ğŸ’Š '{target}' ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆ ê²€ìƒ‰ ì¤‘...")
            products_with_ingredient = find_products_by_ingredient(target)
            if products_with_ingredient:
                collected_data["products_with_ingredient"] = products_with_ingredient
                print(f"âœ… ì œí’ˆ {len(products_with_ingredient)}ê°œ ë°œê²¬: {', '.join(products_with_ingredient[:3])}...")
            else:
                print(f"âš ï¸ í•œêµ­ DBì—ì„œ '{target}' ì„±ë¶„ì„ í¬í•¨í•œ ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        # ğŸ†• YouTube ê²€ìƒ‰ (ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ ì‹œë„)
        if target:
            print(f"ğŸ“º YouTubeì—ì„œ {target} ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
            try:
                youtube_videos = search_youtube_for_followup(target, intent_type)
                if youtube_videos:
                    collected_data["youtube_info"] = youtube_videos
                    print(f"âœ… YouTube ì˜ìƒ {len(youtube_videos)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ (ìë§‰ ìˆëŠ” ì˜ìƒ: {sum(1 for v in youtube_videos if v.get('has_transcript'))}ê°œ)")
                else:
                    print(f"âš ï¸ YouTubeì—ì„œ {target} ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)")
            except Exception as e:
                print(f"âš ï¸ YouTube ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return collected_data if collected_data else None
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def generate_data_driven_answer(current_query: str, conversation_context: str, collected_data: Dict, intent_analysis: Dict) -> Optional[str]:
    """ìˆ˜ì§‘ëœ ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„± (YouTube í†µí•©)"""
    
    intent_type = intent_analysis.get("intent_type", "")
    target = intent_analysis.get("target", "")
    
    # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    data_summary = ""
    
    # Enhanced RAG ì •ë³´ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš©
    if "enhanced_rag_info" in collected_data:
        enhanced_info_list = collected_data["enhanced_rag_info"]
        data_summary += f"**Enhanced RAG ì¢…í•© ë¶„ì„:**\n"
        
        # ì—¬ëŸ¬ ì•½í’ˆ ì •ë³´ ì²˜ë¦¬
        if isinstance(enhanced_info_list, list):
            for i, enhanced_info in enumerate(enhanced_info_list, 1):
                data_summary += f"\n**ì•½í’ˆ {i}:**\n"
                if enhanced_info.get('excel_info'):
                    excel_info = enhanced_info['excel_info']
                    data_summary += f"- ì œí’ˆëª…: {excel_info.get('ì œí’ˆëª…', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ì£¼ì„±ë¶„: {excel_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- íš¨ëŠ¥: {excel_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ì‚¬ìš©ë²•: {excel_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ë¶€ì‘ìš©: {excel_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        else:
            # ë‹¨ì¼ ì•½í’ˆ ì •ë³´ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            enhanced_info = enhanced_info_list
            if enhanced_info.get('excel_info'):
                excel_info = enhanced_info['excel_info']
                data_summary += f"- ì œí’ˆëª…: {excel_info.get('ì œí’ˆëª…', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ì£¼ì„±ë¶„: {excel_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- íš¨ëŠ¥: {excel_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ì‚¬ìš©ë²•: {excel_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ë¶€ì‘ìš©: {excel_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
        
        if enhanced_info.get('combined_analysis'):
            analysis = enhanced_info['combined_analysis']
            data_summary += f"- ì•ˆì „ì„± í‰ê°€: {analysis.get('safety_assessment', 'ì •ë³´ ì—†ìŒ')}\n"
            data_summary += f"- ì‘ìš©ê¸°ì „: {analysis.get('mechanism_analysis', 'ì •ë³´ ì—†ìŒ')}\n"
            data_summary += f"- ì „ë¬¸ê°€ ê¶Œê³ : {analysis.get('expert_recommendation', 'ì •ë³´ ì—†ìŒ')}\n"
            if analysis.get('alternative_suggestions'):
                data_summary += f"- ëŒ€ì•ˆ ì•½í’ˆ: {', '.join(analysis['alternative_suggestions'])}\n"
        
        data_summary += "\n"
    else:
        # Enhanced RAG ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if "excel_info" in collected_data:
            excel_info_list = collected_data["excel_info"]
            data_summary += f"**Excel DB ì •ë³´:**\n"
            
            # ì—¬ëŸ¬ ì•½í’ˆ ì •ë³´ ì²˜ë¦¬
            if isinstance(excel_info_list, list):
                for i, excel_info in enumerate(excel_info_list, 1):
                    data_summary += f"\n**ì•½í’ˆ {i}:**\n"
                    data_summary += f"- ì œí’ˆëª…: {excel_info.get('ì œí’ˆëª…', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ì£¼ì„±ë¶„: {excel_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- íš¨ëŠ¥: {excel_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ì‚¬ìš©ë²•: {excel_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}\n"
                    data_summary += f"- ë¶€ì‘ìš©: {excel_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
            else:
                # ë‹¨ì¼ ì•½í’ˆ ì •ë³´ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
                excel_info = excel_info_list
                data_summary += f"- ì œí’ˆëª…: {excel_info.get('ì œí’ˆëª…', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ì£¼ì„±ë¶„: {excel_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- íš¨ëŠ¥: {excel_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ì‚¬ìš©ë²•: {excel_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}\n"
                data_summary += f"- ë¶€ì‘ìš©: {excel_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}\n"
            data_summary += "\n"
        
        if "health_kr_info" in collected_data:
            health_kr_info = collected_data["health_kr_info"]
            data_summary += f"**í•œêµ­ ì˜ì•½í’ˆ DB ì •ë³´:**\n"
            data_summary += f"- í•œêµ­ëª…: {health_kr_info.get('korean_name', 'ì •ë³´ ì—†ìŒ')}\n"
            data_summary += f"- ì˜ë¬¸ëª…: {health_kr_info.get('english_name', 'ì •ë³´ ì—†ìŒ')}\n"
            if health_kr_info.get('mechanism_of_action'):
                data_summary += f"- ì‘ìš©ê¸°ì „: {health_kr_info['mechanism_of_action']}\n"
            if health_kr_info.get('side_effects'):
                data_summary += f"- ë¶€ì‘ìš©: {health_kr_info['side_effects']}\n"
            data_summary += "\n"
        
        if "pubchem_info" in collected_data:
            pubchem_info = collected_data["pubchem_info"]
            data_summary += f"**PubChem ìƒì„¸ ì •ë³´:**\n"
            
            # ì„±ë¶„ëª…
            if pubchem_info.get('ingredient_name'):
                data_summary += f"- ì„±ë¶„ëª…: {pubchem_info['ingredient_name']}\n"
            
            # ê¸°ë³¸ ì •ë³´
            if pubchem_info.get('basic_info'):
                basic = pubchem_info['basic_info']
                if basic.get('MolecularFormula'):
                    data_summary += f"- ë¶„ìì‹: {basic['MolecularFormula']}\n"
                if basic.get('MolecularWeight'):
                    data_summary += f"- ë¶„ìëŸ‰: {basic['MolecularWeight']}\n"
            
            # ì•½ë¦¬í•™ ì •ë³´ (í•µì‹¬!)
            if pubchem_info.get('pharmacology_info'):
                pharm = pubchem_info['pharmacology_info']
                if pharm.get('mechanism_of_action'):
                    data_summary += f"- ì‘ìš©ê¸°ì „: {pharm['mechanism_of_action'][:500]}...\n"
                if pharm.get('pharmacodynamics'):
                    data_summary += f"- ì•½ë ¥í•™: {pharm['pharmacodynamics'][:500]}...\n"
                if pharm.get('atc_codes'):
                    data_summary += f"- ATC ë¶„ë¥˜: {', '.join(pharm['atc_codes'][:3])}\n"
                if pharm.get('mesh_classification'):
                    mesh_names = [m.get('name', '') for m in pharm['mesh_classification'][:3]]
                    data_summary += f"- MeSH ë¶„ë¥˜: {', '.join(mesh_names)}\n"
            
            # ì„¤ëª… ì •ë³´
            if pubchem_info.get('description'):
                desc = pubchem_info['description']
                data_summary += f"- ì„¤ëª…: {desc[:500]}...\n"
            
            data_summary += "\n"
        
        # ğŸ†• ë²ˆì—­ëœ PubChem ì •ë³´ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  í™œìš©
        if "translated_pubchem_info" in collected_data:
            translated_info = collected_data["translated_pubchem_info"]
            data_summary += f"**ë²ˆì—­ëœ ì•½ë¦¬í•™ ì •ë³´ (ê°€ì¥ ìƒì„¸):**\n"
            
            if translated_info.get('summary_kr'):
                data_summary += f"{translated_info['summary_kr']}\n\n"
            
            if translated_info.get('mechanism_of_action_kr'):
                data_summary += f"- ì‘ìš©ê¸°ì „ (í•œêµ­ì–´): {translated_info['mechanism_of_action_kr'][:800]}\n\n"
            
            if translated_info.get('pharmacodynamics_kr'):
                data_summary += f"- ì•½ë ¥í•™ (í•œêµ­ì–´): {translated_info['pharmacodynamics_kr'][:800]}\n\n"
            
            if translated_info.get('atc_codes_kr'):
                data_summary += f"- ATC ë¶„ë¥˜ (í•œêµ­ì–´):\n"
                for atc in translated_info['atc_codes_kr'][:3]:
                    data_summary += f"  * {atc.get('code', '')}: {atc.get('korean_description', '')}\n"
                data_summary += "\n"
            
            if translated_info.get('mesh_classification_kr'):
                data_summary += f"- MeSH ì•½ë¦¬í•™ ë¶„ë¥˜ (í•œêµ­ì–´):\n"
                for mesh in translated_info['mesh_classification_kr'][:3]:
                    data_summary += f"  * {mesh.get('korean_name', '')}: {mesh.get('korean_description', '')}\n"
                data_summary += "\n"
        
        # ğŸ†• ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆ ëª©ë¡ (ë§¤ìš° ì¤‘ìš”!)
        if "products_with_ingredient" in collected_data:
            products = collected_data["products_with_ingredient"]
            data_summary += f"**ğŸ’Š ì´ ì„±ë¶„({target})ì´ í¬í•¨ëœ í•œêµ­ ì œí’ˆë“¤:**\n"
            if len(products) > 0:
                # ìƒìœ„ 10ê°œ ì œí’ˆë§Œ í‘œì‹œ
                for i, product in enumerate(products[:10], 1):
                    data_summary += f"{i}. {product}\n"
                if len(products) > 10:
                    data_summary += f"... ì™¸ {len(products) - 10}ê°œ ì œí’ˆ\n"
                data_summary += f"\nì´ {len(products)}ê°œ ì œí’ˆì—ì„œ ì‚¬ìš©ë¨\n\n"
            else:
                data_summary += "í•œêµ­ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ\n\n"
    
    # ğŸ†• ì¶”ê°€ ì‹¤ì „ ì •ë³´ (YouTube ì¶œì²˜ ìˆ¨ê¹€)
    if "youtube_info" in collected_data:
        youtube_videos = collected_data["youtube_info"]
        data_summary += f"**ğŸ’¡ ì „ë¬¸ê°€ ì˜ê²¬ ë° ì‹¤ì‚¬ìš© ì •ë³´:**\n"
        data_summary += f"(ì´ {len(youtube_videos)}ê°œ ì •ë³´ì› ì°¸ì¡°)\n\n"
        
        for i, video in enumerate(youtube_videos[:5], 1):  # 5ê°œë¡œ ì¦ê°€
            data_summary += f"{i}. {video.get('title', '')}\n"
            if video.get('has_transcript'):
                data_summary += f"   ë‚´ìš©: {video.get('summary', '')[:400]}...\n"  # ë‚´ìš©ë„ ë” ê¸¸ê²Œ
            else:
                data_summary += f"   ì„¤ëª…: {video.get('description', '')[:250]}...\n"  # ì„¤ëª…ë„ ë” ê¸¸ê²Œ
            data_summary += "\n"
    
    # ì„±ë¶„ ì§ˆë¬¸ ì—¬ë¶€ í™•ì¸
    is_ingredient_question = intent_type == "ingredient_info"
    has_translated_pubchem = "translated_pubchem_info" in collected_data
    
    # ë°ì´í„° ê¸°ë°˜ ë‹µë³€ ìƒì„± - ìµœì í™” ë²„ì „
    answer_prompt = f"""{get_role_definition("pharmacist_friendly")} ìˆ˜ì§‘ëœ ì‹¤ì œ ë°ì´í„°ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ë§Œë“œì„¸ìš”.

## ğŸ“‹ ëŒ€í™” ë§¥ë½
**ì´ì „ ëŒ€í™”:** {conversation_context[:500]}
**í˜„ì¬ ì§ˆë¬¸:** {current_query}
**ì§ˆë¬¸ ìœ í˜•:** {'ì„±ë¶„ ì •ë³´ ì§ˆë¬¸' if is_ingredient_question else 'ì¼ë°˜ ì§ˆë¬¸'}

## ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„°
{data_summary}

**âš ï¸ ë§¤ìš° ì¤‘ìš”: ë°ì´í„° ìˆ˜ì§‘ ì›ì¹™**
- ì•„ë˜ ìˆ˜ì§‘ëœ ë°ì´í„°ì—ëŠ” Excel DB, PDF, PubChem, YouTube, ë„¤ì´ë²„ ë‰´ìŠ¤, ìš©ëŸ‰ì£¼ì˜ ì„±ë¶„, ì—°ë ¹ëŒ€ ê¸ˆê¸°, ì¼ì¼ ìµœëŒ€ íˆ¬ì—¬ëŸ‰ ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- **ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë¹ ì§ì—†ì´ í™•ì¸í•˜ì„¸ìš”**: ë¹„ìŠ·í•œ ì •ë³´ë¼ë„ ê° ì†ŒìŠ¤ë§ˆë‹¤ ê³ ìœ í•œ ì„¸ë¶€ì‚¬í•­ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëª¨ë“  ì†ŒìŠ¤ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”
- **ì¤‘ë³µì´ë¼ê³  ì§€ë‚˜ì¹˜ì§€ ë§ ê²ƒ**: ê°™ì€ ë‚´ìš©ì´ë¼ë„ ê° ì†ŒìŠ¤ì˜ í‘œí˜„ì´ë‚˜ ì¶”ê°€ ì •ë³´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì„¸ìš”
- **ë‹¨ê³„ë³„ í™•ì¸**: ê° ë°ì´í„° ì†ŒìŠ¤ë¥¼ ìˆœì„œëŒ€ë¡œ í™•ì¸í•˜ê³ , ë°œê²¬í•œ ëª¨ë“  ê³ ìœ í•œ ì •ë³´ë¥¼ ê¸°ë¡í•˜ì„¸ìš”

## ğŸ“ ë‹µë³€ ì‘ì„± ê°€ì´ë“œ

### í•µì‹¬ ì›ì¹™ (í•„ìˆ˜)
1. **ì¶œì²˜ ìˆ¨ê¸°ê¸°**: {PromptConfig.COMMON_INSTRUCTIONS['no_source_mention']}
{get_source_mention_examples()}

2. **ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©**: ëª¨ë“  ì •ë³´ë¥¼ í•˜ë‚˜ì˜ í†µí•© ì§€ì‹ìœ¼ë¡œ í‘œí˜„
   - **ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ í¬í•¨í•˜ì„¸ìš”**
   - ê° ì†ŒìŠ¤ì˜ ê³ ìœ í•œ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì„¸ìš”

3. **ëŒ€í™”í˜• í†¤**: "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! ğŸ˜Š" ê°™ì€ ì¹œê·¼í•œ ì‹œì‘

### ì§ˆë¬¸ ìœ í˜•ë³„ ë‹µë³€ ì „ëµ

**ğŸ§ª ì„±ë¶„ ì§ˆë¬¸ (ingredient_info)ì¼ ë•Œ:**
{'- ìƒì„¸ ì„¤ëª… (' + str(PromptConfig.MIN_INGREDIENT_ANSWER_LENGTH) + '-' + str(PromptConfig.MAX_INGREDIENT_ANSWER_LENGTH) + 'ì)' if is_ingredient_question and has_translated_pubchem else ''}
{'- ì‘ìš©ê¸°ì „ êµ¬ì²´ì  ì„¤ëª… (ì–´ë–»ê²Œ/ì–´ë””ì— ì‘ìš©)' if is_ingredient_question and has_translated_pubchem else ''}
{'- ì•½ë¦¬í•™ì  íŠ¹ì„± (í¡ìˆ˜, ëŒ€ì‚¬, ë°˜ê°ê¸°)' if is_ingredient_question and has_translated_pubchem else ''}
{'- ì˜í•™ ë¶„ë¥˜ ì–¸ê¸‰ (ATC, MeSH)' if is_ingredient_question and has_translated_pubchem else ''}
{'- **ğŸ’Š í•œêµ­ ì œí’ˆ ëª©ë¡ í•„ìˆ˜ ì•ˆë‚´** (ì˜ˆ: "ì´ ì„±ë¶„ì€ ì•„ë¡œë‚˜ë¯¼ê³¨ë“œ, ë²¤í¬ë²¨ ë“± ì´ Xê°œ ì œí’ˆì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤")' if is_ingredient_question and has_translated_pubchem else ''}
{'- ì „ë¬¸ ìš©ì–´ëŠ” (ì˜ë¬¸) ë³‘ê¸°' if is_ingredient_question and has_translated_pubchem else ''}

**ì¼ë°˜ ì§ˆë¬¸ì¼ ë•Œ:**
{'- Enhanced RAG ìˆìŒ: ì¢…í•© ë‹µë³€ (' + str(PromptConfig.MIN_SECTION_LENGTH) + '-' + str(PromptConfig.MAX_SECTION_LENGTH) + 'ì)' if not (is_ingredient_question and has_translated_pubchem) else ''}
{'- ì¼ë°˜ ì •ë³´ë§Œ: í•µì‹¬ ë‹µë³€ (' + str(PromptConfig.MIN_CONVERSATIONAL_LENGTH) + '-' + str(PromptConfig.MAX_CONVERSATIONAL_LENGTH) + 'ì)' if not (is_ingredient_question and has_translated_pubchem) else ''}
{'- ìƒˆ ì•½í’ˆ: ì‘ìš©ê¸°ì „ + ì•ˆì „ì„± + ëŒ€ì•ˆ í¬í•¨' if not (is_ingredient_question and has_translated_pubchem) else ''}

### ë‹µë³€ êµ¬ì¡°
1. **ì¹œê·¼í•œ ì‹œì‘**: "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”!"
2. **í•µì‹¬ ì •ë³´**: ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ ì„¤ëª… (ê¸°ë³¸ íš¨ëŠ¥, ì‘ìš©ê¸°ì „, ì•½ë¦¬í•™ì  íŠ¹ì„±)
3. **ğŸ’¡ ì¶”ê°€ ì‹¤ì „ ì •ë³´ (ì¤‘ìš”!)**: 
   - **ì „ë¬¸ê°€ ì˜ê²¬ ë° ì‹¤ì‚¬ìš© ì •ë³´ì—ì„œ ë°œê²¬í•œ í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”**
   - ì˜ˆì‹œ: "ì¹˜ë§¤ ì˜ˆë°©ì—ë„ ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤ê³  ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤", "ë‡Œì„¸í¬ ë³´í˜¸ íš¨ê³¼ë„ ìˆë‹¤ê³  í•©ë‹ˆë‹¤", "ì§‘ì¤‘ë ¥ í–¥ìƒì— íš¨ê³¼ì ì´ë¼ëŠ” ì—°êµ¬ ê²°ê³¼ë„ ìˆìŠµë‹ˆë‹¤" ë“±
   - **ìˆ˜ì§‘ëœ YouTube/ì „ë¬¸ê°€ ì •ë³´ê°€ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—¬ë‹´ì²˜ëŸ¼ ì¶”ê°€í•˜ì„¸ìš”**
   - í˜•ì‹: "ë˜í•œ, ~í•œ íš¨ê³¼ë„ ìˆë‹¤ê³  ì•Œë ¤ì ¸ ìˆì–´ìš”", "ì¬ë¯¸ìˆëŠ” ì ì€ ~", "ì¶”ê°€ë¡œ ~ì—ë„ ë„ì›€ì´ ëœë‹¤ê³  í•´ìš”"
4. **ë§ˆë¬´ë¦¬**: "ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ë¬¼ì–´ë³´ì„¸ìš”!"

### íŠ¹ë³„ ì§€ì¹¨
- ì—¬ëŸ¬ ì•½í’ˆ ì–¸ê¸‰ ì‹œ ëª¨ë‘ ê· ë“±í•˜ê²Œ ì„¤ëª…
- ì•½í’ˆ ëˆ„ë½ ê¸ˆì§€ - ìˆ˜ì§‘ëœ ëª¨ë“  ì•½í’ˆ í¬í•¨
- ê° ì•½í’ˆì˜ ì£¼ì„±ë¶„, íš¨ëŠ¥, ì£¼ì˜ì‚¬í•­ ê°œë³„ ì„¤ëª…
- **YouTube/ì „ë¬¸ê°€ ì •ë³´ê°€ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í™œìš©í•˜ì—¬ ë¶€ê°€ íš¨ëŠ¥ì´ë‚˜ í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤ì„ ì¶”ê°€í•˜ì„¸ìš”** (ì¹˜ë§¤, ë‡Œì„¸í¬ ë³´í˜¸, ì§‘ì¤‘ë ¥ ë“±)

ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
"""
    
    try:
        response = llm.invoke(answer_prompt)
        answer = response.content.strip()
        
        if answer and len(answer) > 50:
            return answer
        else:
            return None
            
    except Exception as e:
        print(f"âŒ ë°ì´í„° ê¸°ë°˜ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def extract_medicine_from_context(conversation_context: str) -> Optional[str]:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ - ê°•í™”ëœ ë²„ì „"""
    if not conversation_context:
        return None
    
    print(f"ğŸ” ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ ì‹œë„: {conversation_context[:200]}...")
    
    # 1. ë¨¼ì € ì‚¬ìš©ìì˜ ìµœê·¼ ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ ì‹œë„ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    user_question_patterns = [
        r'([ê°€-í£]{2,}ì •)ì˜',  # ìš±ì”¬ì •ì˜, íƒ€ì´ë ˆë†€ì •ì˜ ë“±
        r'([ê°€-í£]{2,}ì—°ê³ )ì˜',  # ë°”ìŠ¤í¬ì—°ê³ ì˜ ë“±
        r'([ê°€-í£]{2,}ì •)',  # ìš±ì”¬ì •, íƒ€ì´ë ˆë†€ì • ë“±
        r'([ê°€-í£]{2,}ì—°ê³ )',  # ë°”ìŠ¤í¬ì—°ê³  ë“±
        r'([ê°€-í£]{2,})ì˜',  # ë‡Œì„ ì˜, íƒ€ì´ë ˆë†€ì˜ ë“± (2ê¸€ì ì´ìƒ)
    ]
    
    # ëŒ€í™”ë¥¼ ì˜ì‚¬ ë‹µë³€ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ
    conversation_parts = conversation_context.split("ì˜ì‚¬:")
    if len(conversation_parts) > 1:
        # ê°€ì¥ ìµœê·¼ ì‚¬ìš©ì ì§ˆë¬¸ ë¶€ë¶„
        recent_user_question = conversation_parts[-1].split("ì‚¬ìš©ì:")[-1] if "ì‚¬ìš©ì:" in conversation_parts[-1] else conversation_parts[-1]
        
        for pattern in user_question_patterns:
            try:
                matches = re.findall(pattern, recent_user_question)
                if matches:
                    medicine = matches[-1]
                    print(f"âœ… ìµœê·¼ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ: {medicine}")
                    return medicine
            except Exception as e:
                print(f"âš ï¸ ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
                continue
    
    # 2. ì´ì „ ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª… íŒ¨í„´ ì°¾ê¸° (fallback)
    patterns = [
        r'\*\*([^*]{2,})\*\*ì„\(ë¥¼\)',  # **ë‡Œì„ **ì„(ë¥¼)
        r'\*\*([^*]{2,})\*\*ì€\(ëŠ”\)',  # **ë‡Œì„ **ì€(ëŠ”)
        r'([ê°€-í£]{2,}ì •)ì€',  # ìš±ì”¬ì •ì€
        r'([ê°€-í£]{2,}ì—°ê³ )ëŠ”',  # ë°”ìŠ¤í¬ì—°ê³ ëŠ”
        r'([ê°€-í£]{2,})ì˜',  # ë‡Œì„ ì˜ (2ê¸€ì ì´ìƒ)
        r'([ê°€-í£]{2,}ì •)',  # ìš±ì”¬ì •
        r'([ê°€-í£]{2,}ì—°ê³ )',  # ë°”ìŠ¤í¬ì—°ê³ 
    ]
    
    for pattern in patterns:
        try:
            matches = re.findall(pattern, conversation_context)
            if matches:
                medicine = matches[-1]  # ê°€ì¥ ìµœê·¼ ì–¸ê¸‰ëœ ì•½í’ˆëª…
                print(f"âœ… íŒ¨í„´ìœ¼ë¡œ ì•½í’ˆëª… ì¶”ì¶œ: {medicine}")
                return medicine
        except Exception as e:
            print(f"âš ï¸ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            continue
    
    # 2. ì‚¬ìš©ì ì§ˆë¬¸ ë§¥ë½ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ ì‹œë„
    user_context = conversation_context.split("ì˜ì‚¬:")[0] if "ì˜ì‚¬:" in conversation_context else conversation_context
    user_patterns = [
        r'([ê°€-í£]+ì •)ì€',  # ìš±ì”¬ì •ì€
        r'([ê°€-í£]+ì—°ê³ )ëŠ”',  # ë°”ìŠ¤í¬ì—°ê³ ëŠ”
        r'([ê°€-í£]+)ì˜',  # ë‡Œì„ ì˜
        r'([ê°€-í£]+ì •)',  # ìš±ì”¬ì •
        r'([ê°€-í£]+ì—°ê³ )',  # ë°”ìŠ¤í¬ì—°ê³ 
    ]
    
    for pattern in user_patterns:
        try:
            matches = re.findall(pattern, user_context)
            if matches:
                medicine = matches[-1]
                print(f"âœ… ì‚¬ìš©ì ë§¥ë½ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ: {medicine}")
                return medicine
        except Exception as e:
            print(f"âš ï¸ ì‚¬ìš©ì ë§¥ë½ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            continue
    
    print("âŒ ì•½í’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨")
    return None

# ê¸°ì¡´ íŠ¹ì • ì„±ë¶„ ì¶”ì¶œ í•¨ìˆ˜ëŠ” ì œê±°í•˜ê³  LLM ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ í†µí•©

def extract_medicine_from_user_question(user_context: str) -> Optional[str]:
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ"""
    if not user_context:
        return None
    
    print(f"ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ ì‹œë„: {user_context}")
    
    # ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ë“¤ (ë” ì •í™•í•œ íŒ¨í„´ ìš°ì„ )
    patterns = [
        r'([ê°€-í£]{2,15})(?:ì •|ì—°ê³ |í¬ë¦¼|ì ¤|ìº¡ìŠ|ì‹œëŸ½|ì•¡|ì£¼ì‚¬)(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜)',  # ì•½í’ˆëª…+í˜•íƒœ+ì¡°ì‚¬
        r'([ê°€-í£]{2,15})(?:ì •|ì—°ê³ |í¬ë¦¼|ì ¤|ìº¡ìŠ|ì‹œëŸ½|ì•¡|ì£¼ì‚¬)',  # ì•½í’ˆëª…+í˜•íƒœ
        r'([ê°€-í£]{2,15})(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜)',  # ì•½í’ˆëª…+ì¡°ì‚¬
        r'([ê°€-í£]{2,15})(?:ì •|ì—°ê³ )',  # ì•½í’ˆëª…+ì •/ì—°ê³ 
    ]
    
    for pattern in patterns:
        try:
            matches = re.findall(pattern, user_context)
            if matches:
                medicine = matches[0]  # ì²« ë²ˆì§¸ ë§¤ì¹­ ì‚¬ìš©
                # ë„ˆë¬´ ì§§ê±°ë‚˜ ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì œì™¸
                if len(medicine) >= 2 and medicine not in ['ë¬´ì—‡', 'ì–´ë–¤', 'ì´ê±°', 'ê·¸ê±°', 'ì €ê±°', 'ë¬´ì—‡ì¸ê°€ìš”', 'ë¬´ì—‡ì¸ê°€', 'ë­ì•¼', 'ë­ì˜ˆìš”']:
                    print(f"âœ… ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ: {medicine}")
                    return medicine
        except Exception as e:
            print(f"âš ï¸ ì‚¬ìš©ì ì§ˆë¬¸ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            continue
    
    print("âŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨")
    return None

def handle_usage_question(medicine_name: str, context: str) -> str:
    """ì‚¬ìš©ë²• ì§ˆë¬¸ ì²˜ë¦¬ - ChatGPT ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”"""
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    if medicine_info["ì‚¬ìš©ë²•"] == "ì •ë³´ ì—†ìŒ":
        return f"ì•„, '{medicine_name}'ì˜ ì‚¬ìš©ë²• ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë„¤ìš”! ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦´ê²Œìš”."
    
    prompt = f"""
    {get_role_definition("pharmacist")} ì‚¬ìš©ìê°€ ì´ì „ì— {medicine_name}ì— ëŒ€í•´ ë¬¼ì–´ë´¤ê³ , ì´ì œ ì‚¬ìš©ë²•ì„ ê¶ê¸ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    
    **ì•½í’ˆ ì •ë³´:**
    - ì œí’ˆëª…: {medicine_name}
    - ì‚¬ìš©ë²•: {medicine_info['ì‚¬ìš©ë²•']}
    - íš¨ëŠ¥: {medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}
    - ì£¼ì„±ë¶„: {medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}
    
    **ëŒ€í™” ìŠ¤íƒ€ì¼:**
    - ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€
    - "ë„¤, ì‚¬ìš©ë²• ì•Œë ¤ë“œë¦´ê²Œìš”!", "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘
    - ì‚¬ìš©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì‰½ê²Œ ì„¤ëª…
    - ì£¼ì˜ì‚¬í•­ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
    - ë§ˆì§€ë§‰ì— "ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬
    
    **ë‹µë³€ êµ¬ì¡°:**
    1. ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ ("ë„¤, ì‚¬ìš©ë²• ì•Œë ¤ë“œë¦´ê²Œìš”!")
    2. ì‚¬ìš©ë²• ë‹¨ê³„ë³„ ì„¤ëª…
    3. ì£¼ì˜ì‚¬í•­ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
    4. ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬
    
    ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”!
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"**{medicine_name}**ì˜ ì‚¬ìš©ë²•ì„ ì•Œë ¤ë“œë¦´ê²Œìš”!\n\n{medicine_info['ì‚¬ìš©ë²•']}\n\në” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"

def handle_ingredient_question(medicine_name: str, context: str) -> str:
    """ì„±ë¶„ ì§ˆë¬¸ ì²˜ë¦¬ - ì•½í’ˆëª…/ì„±ë¶„ëª… ë™ì  ë¶„ë¥˜ + PubChem í™œìš©"""
    
    if not medicine_name:
        return "ì•„, ì–´ë–¤ ì•½í’ˆì˜ ì„±ë¶„ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ì§€ ëª…í™•í•˜ì§€ ì•Šë„¤ìš”! ì•½í’ˆëª…ì„ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ê²Œìš”!"
    
    print(f"ğŸ§ª ì„±ë¶„ ì§ˆë¬¸ ì²˜ë¦¬: {medicine_name}")
    
    # 1ë‹¨ê³„: ì•½í’ˆëª…ì¸ì§€ ì„±ë¶„ëª…ì¸ì§€ ë¶„ë¥˜
    classification = classify_medicine_vs_ingredient(medicine_name)
    
    print(f"ğŸ” ë¶„ë¥˜ ê²°ê³¼: {classification['type']} (ì‹ ë¢°ë„: {classification['confidence']})")
    
    if classification["type"] == "ingredient":
        # ì„±ë¶„ëª…ìœ¼ë¡œ íŒë‹¨ë¨ â†’ ì„±ë¶„ ìƒì„¸ ì„¤ëª… + í¬í•¨ ì œí’ˆ ì•ˆë‚´
        return handle_specific_ingredient_question(classification)
    
    elif classification["type"] == "product":
        # ì•½í’ˆëª…ìœ¼ë¡œ íŒë‹¨ë¨ â†’ í•´ë‹¹ ì•½í’ˆì˜ ì„±ë¶„ ì„¤ëª…
        return handle_product_ingredient_question(medicine_name)
    
    else:
        # ë¶„ë¥˜ ì‹¤íŒ¨ â†’ ê¸°ë³¸ ì²˜ë¦¬
        return handle_unknown_entity_question(medicine_name)

def handle_specific_ingredient_question(classification: Dict) -> str:
    """íŠ¹ì • ì„±ë¶„ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… (PubChem í™œìš©)"""
    
    ingredient_name = classification["name"]
    products = classification.get("products", [])
    
    print(f"ğŸ§ª ì„±ë¶„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘: {ingredient_name}")
    
    # PubChemì—ì„œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    try:
        from pubchem_api import PubChemAPI
        from translation_rag import TranslationRAG
        
        pubchem_api = PubChemAPI()
        translation_rag = TranslationRAG()
        
        # PubChem ì •ë³´ ìˆ˜ì§‘
        pubchem_info = pubchem_api.analyze_ingredient_comprehensive(ingredient_name)
        
        # ë²ˆì—­ ë° ìš”ì•½
        translated_info = translation_rag.translate_pharmacology_info(pubchem_info.get('pharmacology_info', {}))
        summary = translated_info.get('summary_kr', '')
        description = pubchem_info.get('description', '')
        description_kr = translation_rag._translate_description(description) if description else ''
        
    except Exception as e:
        print(f"âš ï¸ PubChem ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        summary = ""
        description_kr = ""
    
    # LLMìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
    prompt = f"""
{get_role_definition("pharmacist")} ì‚¬ìš©ìê°€ "{ingredient_name}"ì´ë¼ëŠ” **ì„±ë¶„**ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**PubChem ì •ë³´:**
{summary if summary else "ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨"}

**ì„¤ëª…:**
{description_kr if description_kr else "ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨"}

**ì´ ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆë“¤:**
{', '.join(products[:5]) if products else "í•œêµ­ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ"}

**ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
1. "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”! ğŸ˜Š" ê°™ì€ ì¹œê·¼í•œ ì‹œì‘
2. {ingredient_name}ì´(ê°€) **ì„±ë¶„ëª…**ì„ì„ ëª…í™•íˆ ì–¸ê¸‰
3. PubChem ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ **ìƒì„¸í•˜ê²Œ** ì„¤ëª…:
   - ì‘ìš©ê¸°ì „ (ë©”ì»¤ë‹ˆì¦˜)
   - ì£¼ìš” íš¨ëŠ¥
   - ì•½ë¦¬í•™ì  íŠ¹ì„±
   - ì˜í•™ì  ë¶„ë¥˜
4. ì´ ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆë“¤ ì•ˆë‚´ (ìˆëŠ” ê²½ìš°)
5. ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì˜ì–´ ì›ë¬¸ë„ í•¨ê»˜
6. {PromptConfig.MIN_SECTION_LENGTH}-{PromptConfig.MAX_SECTION_LENGTH}ì ì •ë„ì˜ ìƒì„¸í•œ ê¸¸ì´
7. "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!" ê°™ì€ ë§ˆë¬´ë¦¬

**ì¤‘ìš”:** PubChem ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
"""
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # Fallback
        fallback = f"**{ingredient_name}**ì€(ëŠ”) ì˜ì•½í’ˆì˜ ì£¼ì„±ë¶„ì…ë‹ˆë‹¤.\n\n"
        if summary:
            fallback += f"{summary}\n\n"
        if products:
            fallback += f"ğŸ’Š **ì´ ì„±ë¶„ì´ í¬í•¨ëœ ì œí’ˆë“¤:**\n"
            for product in products[:5]:
                fallback += f"- {product}\n"
        fallback += "\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"
        return fallback

def handle_product_ingredient_question(product_name: str) -> str:
    """ì•½í’ˆì˜ ì„±ë¶„ ì„¤ëª…"""
    
    medicine_info = find_medicine_info(product_name, excel_docs)
    
    if medicine_info.get("ì£¼ì„±ë¶„") == "ì •ë³´ ì—†ìŒ":
        return f"ì£„ì†¡í•´ìš”! '{product_name}'ì˜ ì„±ë¶„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë„¤ìš”."
    
    prompt = f"""
{get_role_definition("pharmacist")} ì‚¬ìš©ìê°€ {product_name}ì˜ ì„±ë¶„ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ì•½í’ˆ ì •ë³´:**
- ì œí’ˆëª…: {product_name}
- ì£¼ì„±ë¶„: {medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}
- íš¨ëŠ¥: {medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}

**ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
- {PromptConfig.COMMON_INSTRUCTIONS['natural_tone']}
- "ì•„, ì„±ë¶„ì´ ê¶ê¸ˆí•˜ì‹œêµ°ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ìœ¼ë¡œ ì‹œì‘
- ê° ì„±ë¶„ì„ ì‰½ê²Œ ì„¤ëª…í•˜ë˜ ì „ë¬¸ì ì¸ ì •ë³´ë„ í¬í•¨
- ì„±ë¶„ë³„ë¡œ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì„¤ëª…
- {PromptConfig.MIN_CONVERSATIONAL_LENGTH}-{PromptConfig.MAX_SECTION_LENGTH}ì ì •ë„ì˜ ì ì ˆí•œ ê¸¸ì´
- "ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”!
"""
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"**{product_name}**ì˜ ì£¼ì„±ë¶„ì„ ì•Œë ¤ë“œë¦´ê²Œìš”!\n\n{medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}\n\në” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"

def handle_unknown_entity_question(entity_name: str) -> str:
    """ë¶„ë¥˜ ì‹¤íŒ¨í•œ ê²½ìš°ì˜ ê¸°ë³¸ ì²˜ë¦¬"""
    
    # ì¼ë‹¨ ì•½í’ˆìœ¼ë¡œ ê°€ì •í•˜ê³  ì‹œë„
    medicine_info = find_medicine_info(entity_name, excel_docs)
    
    if medicine_info.get("ì£¼ì„±ë¶„") != "ì •ë³´ ì—†ìŒ":
        return handle_product_ingredient_question(entity_name)
    
    return f"ì£„ì†¡í•´ìš”! '{entity_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë„¤ìš”. ì •í™•í•œ ì•½í’ˆëª…ì´ë‚˜ ì„±ë¶„ëª…ì„ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ê²Œìš”!"

def handle_side_effect_question(medicine_name: str, context: str) -> str:
    """ë¶€ì‘ìš© ì§ˆë¬¸ ì²˜ë¦¬"""
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    if medicine_info["ë¶€ì‘ìš©"] == "ì •ë³´ ì—†ìŒ":
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{medicine_name}'ì˜ ë¶€ì‘ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    prompt = f"""
    ì´ì „ ëŒ€í™”ì—ì„œ {medicine_name}ì— ëŒ€í•´ ì„¤ëª…í–ˆê³ , ì‚¬ìš©ìê°€ ë¶€ì‘ìš©ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì•½í’ˆ ì •ë³´:
    - ì œí’ˆëª…: {medicine_name}
    - ë¶€ì‘ìš©: {medicine_info['ë¶€ì‘ìš©']}
    
    ë¶€ì‘ìš©ì„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except:
        return f"**{medicine_name}**ì˜ ë¶€ì‘ìš©:\n\n{medicine_info['ë¶€ì‘ìš©']}"

def handle_mechanism_question(medicine_name: str, context: str) -> str:
    """ì‘ìš©ê¸°ì „ ì§ˆë¬¸ ì²˜ë¦¬"""
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    prompt = f"""
    ì´ì „ ëŒ€í™”ì—ì„œ {medicine_name}ì— ëŒ€í•´ ì„¤ëª…í–ˆê³ , ì‚¬ìš©ìê°€ ì‘ìš©ê¸°ì „ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì•½í’ˆ ì •ë³´:
    - ì œí’ˆëª…: {medicine_name}
    - ì£¼ì„±ë¶„: {medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}
    - íš¨ëŠ¥: {medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}
    
    ì‘ìš©ê¸°ì „ì„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except:
        return f"**{medicine_name}**ì˜ ì‘ìš©ê¸°ì „ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” {get_medical_consultation_footer('friendly').strip()}"

def handle_precaution_question(medicine_name: str, context: str) -> str:
    """ì£¼ì˜ì‚¬í•­ ì§ˆë¬¸ ì²˜ë¦¬"""
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    prompt = f"""
    ì´ì „ ëŒ€í™”ì—ì„œ {medicine_name}ì— ëŒ€í•´ ì„¤ëª…í–ˆê³ , ì‚¬ìš©ìê°€ ì£¼ì˜ì‚¬í•­ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì•½í’ˆ ì •ë³´:
    - ì œí’ˆëª…: {medicine_name}
    - ë¶€ì‘ìš©: {medicine_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}
    - ì‚¬ìš©ë²•: {medicine_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}
    
    ì£¼ì˜ì‚¬í•­ì„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except:
        return f"**{medicine_name}**ì˜ ì£¼ì˜ì‚¬í•­ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” {get_medical_consultation_footer('friendly').strip()}"

def handle_general_question(medicine_name: str, context: str, user_context: str) -> str:
    """ì¼ë°˜ì ì¸ ì¶”ê°€ ì§ˆë¬¸ ì²˜ë¦¬ - ChatGPT ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”"""
    medicine_info = find_medicine_info(medicine_name, excel_docs)
    
    prompt = f"""
    {get_role_definition("pharmacist")} ì‚¬ìš©ìê°€ ì´ì „ì— {medicine_name}ì— ëŒ€í•´ ë¬¼ì–´ë´¤ê³ , ì´ì œ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    
    **ì‚¬ìš©ì ì§ˆë¬¸:** {user_context}
    
    **ì•½í’ˆ ì •ë³´:**
    - ì œí’ˆëª…: {medicine_name}
    - íš¨ëŠ¥: {medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}
    - ë¶€ì‘ìš©: {medicine_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}
    - ì‚¬ìš©ë²•: {medicine_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}
    - ì£¼ì„±ë¶„: {medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}
    
    **ëŒ€í™” ìŠ¤íƒ€ì¼:**
    - {PromptConfig.COMMON_INSTRUCTIONS['natural_tone']}
    - "ì•„, ê·¸ê±° ê¶ê¸ˆí•˜ì‹œêµ°ìš”!", "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€
    - í•„ìš”ì‹œ ì¶”ê°€ ì •ë³´ë‚˜ ì£¼ì˜ì‚¬í•­ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
    - ë§ˆì§€ë§‰ì— "ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬
    
    **ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
    - ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
    - {PromptConfig.COMMON_INSTRUCTIONS['natural_tone']}
    - í•„ìš”ì‹œ ì˜ë£Œì§„ ìƒë‹´ ê¶Œê³ 
    
    ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”!
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"**{medicine_name}**ì— ëŒ€í•œ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”. ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"

def find_medicine_info(medicine_name: str, all_docs: List) -> Dict:
    """ì•½í’ˆëª…ìœ¼ë¡œ ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë°˜í™˜ - type êµ¬ë¶„ ì§€ì›, PDF ë§í¬ ìë™ ë‹¤ìš´ë¡œë“œ"""
    medicine_info = {
        "ì œí’ˆëª…": medicine_name,
        "íš¨ëŠ¥": "ì •ë³´ ì—†ìŒ",
        "ë¶€ì‘ìš©": "ì •ë³´ ì—†ìŒ", 
        "ì‚¬ìš©ë²•": "ì •ë³´ ì—†ìŒ",
        "ì£¼ì„±ë¶„": "ì •ë³´ ì—†ìŒ"
    }
    
    # ì •í™•í•œ ì œí’ˆëª… ë§¤ì¹­ ì‹œë„
    exact_matches = [doc for doc in all_docs if doc.metadata.get("ì œí’ˆëª…") == medicine_name]
    
    # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ìˆ˜ì¶œëª… ë¬¸ì œ í•´ê²°)
    if not exact_matches:
        print(f"ğŸ” ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨, ë¶€ë¶„ ë§¤ì¹­ ì‹œë„: {medicine_name}")
        partial_matches = []
        for doc in all_docs:
            product_name = doc.metadata.get("ì œí’ˆëª…", "")
            # ì•½í’ˆëª…ì´ ì œí’ˆëª…ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if product_name.startswith(medicine_name) or medicine_name in product_name:
                partial_matches.append(doc)
                print(f"  ë¶€ë¶„ ë§¤ì¹­ ë°œê²¬: '{product_name}' (ê²€ìƒ‰ì–´: '{medicine_name}')")
        
        if partial_matches:
            exact_matches = partial_matches
            print(f"âœ… ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ '{medicine_name}' ì•½í’ˆ ì •ë³´ ë°œê²¬: {len(exact_matches)}ê°œ ì²­í¬")
        else:
            print(f"âŒ '{medicine_name}' ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return medicine_info
    else:
        print(f"âœ… '{medicine_name}' ì•½í’ˆ ì •ë³´ ë°œê²¬: {len(exact_matches)}ê°œ ì²­í¬")
    
    # ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘ (ì—¬ëŸ¬ Excel íŒŒì¼ì—ì„œ ë³‘í•©) - medicine_usage_check_nodeì™€ ë™ì¼í•œ ë¡œì§
    import os
    import re
    url_pattern = r'https?://[^\s]+'
    
    # ìƒˆ Excel íŒŒì¼ ìš°ì„ ìˆœìœ„ ì„¤ì •
    new_excel_file = r"C:\Users\jung\Desktop\33\OpenData_ItemPermitDetail20251115.xls"
    
    # ëª¨ë“  ë§¤ì¹­ëœ ë¬¸ì„œë¥¼ íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
    docs_by_file = {}
    for doc in exact_matches:
        excel_file = doc.metadata.get("excel_file")
        if excel_file:
            if excel_file not in docs_by_file:
                docs_by_file[excel_file] = []
            docs_by_file[excel_file].append(doc)
    
    # ìƒˆ Excel íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •
    file_priority = []
    if new_excel_file in docs_by_file:
        file_priority.append(new_excel_file)
    for file in docs_by_file.keys():
        if file != new_excel_file:
            file_priority.append(file)
    
    print(f"ğŸ“‚ ì•½í’ˆ ì •ë³´ ì¶œì²˜ íŒŒì¼: {len(file_priority)}ê°œ íŒŒì¼ì—ì„œ ë°œê²¬")
    for file in file_priority:
        print(f"  - {os.path.basename(file)} ({len(docs_by_file[file])}ê°œ ì²­í¬)")
    
    # ëª¨ë“  Excel íŒŒì¼ì—ì„œ ì •ë³´ ìˆ˜ì§‘ (íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”)
    excel_file = None
    excel_row_index = None
    
    # ê° íŒŒì¼ë³„ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
    all_efficacy_info = []  # [(íŒŒì¼ëª…, íš¨ëŠ¥ì •ë³´), ...]
    all_side_effects_info = []  # [(íŒŒì¼ëª…, ë¶€ì‘ìš©ì •ë³´), ...]
    all_usage_info = []  # [(íŒŒì¼ëª…, ì‚¬ìš©ë²•ì •ë³´), ...]
    
    for file in file_priority:
        file_name = os.path.basename(file)
        file_efficacy = None
        file_side_effects = None
        file_usage = None
        
        for doc in docs_by_file[file]:
            content = doc.page_content
            doc_type = doc.metadata.get("type", "")
            
            # Excel íŒŒì¼ ì •ë³´ ì €ì¥ (ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ íŒŒì¼ì—ì„œ)
            if not excel_file:
                excel_file = doc.metadata.get("excel_file")
                excel_row_index = doc.metadata.get("excel_row_index")
            
            # íš¨ëŠ¥ê³¼ ë¶€ì‘ìš©ì€ main íƒ€ì…ì—ì„œ ì¶”ì¶œ
            if doc_type == "main" or doc_type == "":
                efficacy = extract_field_from_doc(content, "íš¨ëŠ¥")
                side_effects = extract_field_from_doc(content, "ë¶€ì‘ìš©")
                main_ingredient = doc.metadata.get("ì£¼ì„±ë¶„", "ì •ë³´ ì—†ìŒ")
                
                # ì£¼ì„±ë¶„ì€ ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œë§Œ ì €ì¥
                if not medicine_info.get("ì£¼ì„±ë¶„") or medicine_info["ì£¼ì„±ë¶„"] == "ì •ë³´ ì—†ìŒ":
                    if main_ingredient != "ì •ë³´ ì—†ìŒ":
                        medicine_info["ì£¼ì„±ë¶„"] = main_ingredient
                
                # URLì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìˆ˜ì§‘
                if efficacy != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(efficacy)):
                    if file_efficacy is None:
                        file_efficacy = efficacy
                    else:
                        # ê°™ì€ íŒŒì¼ ë‚´ì—ì„œ ì—¬ëŸ¬ ì²­í¬ê°€ ìˆìœ¼ë©´ ë” ê¸´ ê²ƒì„ ì„ íƒ
                        if len(efficacy) > len(file_efficacy):
                            file_efficacy = efficacy
                
                if side_effects != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(side_effects)):
                    if file_side_effects is None:
                        file_side_effects = side_effects
                    else:
                        if len(side_effects) > len(file_side_effects):
                            file_side_effects = side_effects
            
            # ì‚¬ìš©ë²•ì€ usage íƒ€ì…ì—ì„œ ì¶”ì¶œ
            if doc_type == "usage":
                usage = extract_field_from_doc(content, "ì‚¬ìš©ë²•")
                if usage != "ì •ë³´ ì—†ìŒ" and not re.search(url_pattern, str(usage)):
                    if file_usage is None:
                        file_usage = usage
                    else:
                        if len(usage) > len(file_usage):
                            file_usage = usage
        
        # íŒŒì¼ë³„ë¡œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        if file_efficacy:
            all_efficacy_info.append((file_name, file_efficacy))
            print(f"ğŸ“‹ {file_name}ì—ì„œ íš¨ëŠ¥ ì •ë³´ ìˆ˜ì§‘: {len(file_efficacy)}ì")
        if file_side_effects:
            all_side_effects_info.append((file_name, file_side_effects))
            print(f"ğŸ“‹ {file_name}ì—ì„œ ë¶€ì‘ìš© ì •ë³´ ìˆ˜ì§‘: {len(file_side_effects)}ì")
        if file_usage:
            all_usage_info.append((file_name, file_usage))
            print(f"ğŸ“‹ {file_name}ì—ì„œ ì‚¬ìš©ë²• ì •ë³´ ìˆ˜ì§‘: {len(file_usage)}ì")
    
    # ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ LLMìœ¼ë¡œ ë³‘í•©
    from medicine_usage_check_node import merge_multiple_sources_with_llm
    
    if len(all_efficacy_info) > 1:
        print(f"ğŸ”„ {len(all_efficacy_info)}ê°œ ì†ŒìŠ¤ì˜ íš¨ëŠ¥ ì •ë³´ ë³‘í•© ì¤‘...")
        merged_efficacy = merge_multiple_sources_with_llm(all_efficacy_info, "íš¨ëŠ¥")
        medicine_info["íš¨ëŠ¥"] = merged_efficacy
    elif len(all_efficacy_info) == 1:
        medicine_info["íš¨ëŠ¥"] = all_efficacy_info[0][1]
    
    if len(all_side_effects_info) > 1:
        print(f"ğŸ”„ {len(all_side_effects_info)}ê°œ ì†ŒìŠ¤ì˜ ë¶€ì‘ìš© ì •ë³´ ë³‘í•© ì¤‘...")
        merged_side_effects = merge_multiple_sources_with_llm(all_side_effects_info, "ë¶€ì‘ìš©")
        medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
    elif len(all_side_effects_info) == 1:
        medicine_info["ë¶€ì‘ìš©"] = all_side_effects_info[0][1]
    
    if len(all_usage_info) > 1:
        print(f"ğŸ”„ {len(all_usage_info)}ê°œ ì†ŒìŠ¤ì˜ ì‚¬ìš©ë²• ì •ë³´ ë³‘í•© ì¤‘...")
        merged_usage = merge_multiple_sources_with_llm(all_usage_info, "ì‚¬ìš©ë²•")
        medicine_info["ì‚¬ìš©ë²•"] = merged_usage
    elif len(all_usage_info) == 1:
        medicine_info["ì‚¬ìš©ë²•"] = all_usage_info[0][1]
    
    # PDF ë§í¬ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ (ëª¨ë“  íŒŒì¼ì—ì„œ ìˆ˜ì§‘í•˜ì—¬ ë³‘í•©)
    from pdf_link_extractor import enrich_excel_row_with_pdf_content
    from retrievers import file_column_mappings, default_columns
    
    # ëª¨ë“  íŒŒì¼ì—ì„œ PDF ì •ë³´ ìˆ˜ì§‘
    all_pdf_efficacy = []
    all_pdf_side_effects = []
    all_pdf_usage = []
    
    for file in file_priority:
        # í•´ë‹¹ íŒŒì¼ì˜ ë¬¸ì„œì—ì„œ excel_row_index ì°¾ê¸°
        file_row_index = None
        for doc in docs_by_file[file]:
            if doc.metadata.get("excel_file") == file:
                file_row_index = doc.metadata.get("excel_row_index")
                if file_row_index is not None:
                    break
        
        if file_row_index is None:
            continue
        
        print(f"ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì‹œë„: {os.path.basename(file)}, í–‰ {file_row_index}")
        try:
            # íŒŒì¼ë³„ ì»¬ëŸ¼ ë§¤í•‘ í™•ì¸
            if file in file_column_mappings:
                col_mapping = file_column_mappings[file]
            else:
                col_mapping = default_columns
            
            pdf_column_mapping = {
                'íš¨ëŠ¥': col_mapping['íš¨ëŠ¥'],
                'ë³µìš©ë²•': col_mapping['ì‚¬ìš©ë²•'],
                'ì£¼ì˜ì‚¬í•­': col_mapping['ë¶€ì‘ìš©']
            }
            
            # íš¨ëŠ¥, ë¶€ì‘ìš©, ì‚¬ìš©ë²•ì´ URLì¸ì§€ í™•ì¸í•˜ê³  PDF ë‹¤ìš´ë¡œë“œ
            # ì—°ì† ì§ˆë¬¸ì¼ ë•ŒëŠ” ìš”ì•½ì„ ëœ ì‹¬í•˜ê²Œ í•˜ì—¬ ë” ìƒì„¸í•œ ë‚´ìš© ì œê³µ
            pdf_content = enrich_excel_row_with_pdf_content(
                file, file_row_index, ['íš¨ëŠ¥', 'ì£¼ì˜ì‚¬í•­', 'ë³µìš©ë²•'], pdf_column_mapping,
                summarize=True,  # ìš”ì•½ì€ í•˜ë˜
                max_length=5000  # ì—°ì† ì§ˆë¬¸ì¼ ë•ŒëŠ” ë” ê¸´ ë‚´ìš© ì œê³µ (ê¸°ë³¸ê°’ 2000ì â†’ 5000ì)
            )
            
            print(f"ğŸ“‹ PDF ë‚´ìš© í™•ì¸: {list(pdf_content.keys())}")
            for key, value in pdf_content.items():
                if value:
                    print(f"  - {key}: {len(str(value))}ì - {str(value)[:100]}...")
                    # PDF ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    file_name = os.path.basename(file)
                    if key == 'íš¨ëŠ¥' and value:
                        all_pdf_efficacy.append((file_name, value))
                    elif key == 'ì£¼ì˜ì‚¬í•­' and value:
                        all_pdf_side_effects.append((file_name, value))
                    elif key == 'ë³µìš©ë²•' and value:
                        all_pdf_usage.append((file_name, value))
                else:
                    print(f"  - {key}: None")
        
        except Exception as e:
            print(f"âš ï¸ {os.path.basename(file)} PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
    
    # PDF ì •ë³´ë¥¼ ê¸°ì¡´ Excel ì •ë³´ì™€ ë³‘í•©
    if all_pdf_efficacy:
        current_efficacy = medicine_info.get("íš¨ëŠ¥", "ì •ë³´ ì—†ìŒ")
        if current_efficacy != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_efficacy_sources = all_efficacy_info + all_pdf_efficacy
            if len(all_efficacy_sources) > 1:
                print(f"ğŸ”„ Excel + PDF íš¨ëŠ¥ ì •ë³´ ë³‘í•© ì¤‘... ({len(all_efficacy_sources)}ê°œ ì†ŒìŠ¤)")
                merged_efficacy = merge_multiple_sources_with_llm(all_efficacy_sources, "íš¨ëŠ¥")
                medicine_info["íš¨ëŠ¥"] = merged_efficacy
            else:
                medicine_info["íš¨ëŠ¥"] = all_efficacy_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_efficacy) > 1:
                merged_efficacy = merge_multiple_sources_with_llm(all_pdf_efficacy, "íš¨ëŠ¥")
                medicine_info["íš¨ëŠ¥"] = merged_efficacy
            elif len(all_pdf_efficacy) == 1:
                medicine_info["íš¨ëŠ¥"] = all_pdf_efficacy[0][1]
    
    if all_pdf_side_effects:
        current_side_effects = medicine_info.get("ë¶€ì‘ìš©", "ì •ë³´ ì—†ìŒ")
        if current_side_effects != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_side_effects_sources = all_side_effects_info + all_pdf_side_effects
            if len(all_side_effects_sources) > 1:
                print(f"ğŸ”„ Excel + PDF ë¶€ì‘ìš© ì •ë³´ ë³‘í•© ì¤‘... ({len(all_side_effects_sources)}ê°œ ì†ŒìŠ¤)")
                merged_side_effects = merge_multiple_sources_with_llm(all_side_effects_sources, "ë¶€ì‘ìš©")
                medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
            else:
                medicine_info["ë¶€ì‘ìš©"] = all_side_effects_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_side_effects) > 1:
                merged_side_effects = merge_multiple_sources_with_llm(all_pdf_side_effects, "ë¶€ì‘ìš©")
                medicine_info["ë¶€ì‘ìš©"] = merged_side_effects
            elif len(all_pdf_side_effects) == 1:
                medicine_info["ë¶€ì‘ìš©"] = all_pdf_side_effects[0][1]
    
    if all_pdf_usage:
        current_usage = medicine_info.get("ì‚¬ìš©ë²•", "ì •ë³´ ì—†ìŒ")
        if current_usage != "ì •ë³´ ì—†ìŒ":
            # Excel ì •ë³´ì™€ PDF ì •ë³´ë¥¼ ëª¨ë‘ ë³‘í•©
            all_usage_sources = all_usage_info + all_pdf_usage
            if len(all_usage_sources) > 1:
                print(f"ğŸ”„ Excel + PDF ì‚¬ìš©ë²• ì •ë³´ ë³‘í•© ì¤‘... ({len(all_usage_sources)}ê°œ ì†ŒìŠ¤)")
                merged_usage = merge_multiple_sources_with_llm(all_usage_sources, "ì‚¬ìš©ë²•")
                medicine_info["ì‚¬ìš©ë²•"] = merged_usage
            else:
                medicine_info["ì‚¬ìš©ë²•"] = all_usage_sources[0][1]
        else:
            # Excel ì •ë³´ê°€ ì—†ìœ¼ë©´ PDF ì •ë³´ë§Œ ì‚¬ìš©
            if len(all_pdf_usage) > 1:
                merged_usage = merge_multiple_sources_with_llm(all_pdf_usage, "ì‚¬ìš©ë²•")
                medicine_info["ì‚¬ìš©ë²•"] = merged_usage
            elif len(all_pdf_usage) == 1:
                medicine_info["ì‚¬ìš©ë²•"] = all_pdf_usage[0][1]
    
    return medicine_info

def extract_field_from_doc(text: str, label: str) -> str:
    """ë¬¸ì„œì—ì„œ íŠ¹ì • í•„ë“œ ì¶”ì¶œ"""
    pattern = rf"\[{label}\]:\s*((?:.|\n)*?)(?=\n\[|\Z)"
    match = re.search(pattern, text)
    return match.group(1).strip() if match else "ì •ë³´ ì—†ìŒ"

def handle_alternative_medicines_question(medicine_name: str, conversation_context: str, current_query: str) -> str:
    """ëŒ€ì•ˆ ì•½í’ˆ ì§ˆë¬¸ ì²˜ë¦¬ (ì„±ë¶„ ì¤‘ì‹¬ ì„¤ëª…)"""
    print(f"ğŸ” ëŒ€ì•ˆ ì•½í’ˆ ì§ˆë¬¸ ì²˜ë¦¬: {medicine_name}")
    
    # ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤ ì¶”ì¶œ
    alternative_medicines_from_context = extract_alternative_medicines_from_context(conversation_context)
    print(f"  ëŒ€í™”ì—ì„œ ì¶”ì¶œëœ ëŒ€ì•ˆ ì•½í’ˆë“¤: {alternative_medicines_from_context}")
    
    if not alternative_medicines_from_context:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ëŒ€ì•ˆ ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ê° ëŒ€ì•ˆ ì•½í’ˆì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    detailed_alternatives = []
    for alt_medicine in alternative_medicines_from_context:
        print(f"  ê°œë³„ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘: {alt_medicine}")
        alt_info = find_medicine_info_in_excel(alt_medicine)
        if alt_info and alt_info["íš¨ëŠ¥"] != "ì •ë³´ ì—†ìŒ":
            ingredients = extract_ingredients_from_medicine_info(alt_info)
            print(f"    ì„±ë¶„ ì¶”ì¶œ: {ingredients}")
            detailed_alternatives.append({
                "name": alt_medicine,
                "ingredients": ingredients,
                "efficacy": alt_info.get("íš¨ëŠ¥", "ì •ë³´ ì—†ìŒ"),
                "side_effects": alt_info.get("ë¶€ì‘ìš©", "ì •ë³´ ì—†ìŒ"),
                "usage": alt_info.get("ì‚¬ìš©ë²•", "ì •ë³´ ì—†ìŒ"),
                "content": f"íš¨ëŠ¥: {alt_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}\në¶€ì‘ìš©: {alt_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}\nì‚¬ìš©ë²•: {alt_info.get('ì‚¬ìš©ë²•', 'ì •ë³´ ì—†ìŒ')}"
            })
        else:
            print(f"    ì•½í’ˆ ì •ë³´ ì—†ìŒ: {alt_medicine}")
    
    if not detailed_alternatives:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì–¸ê¸‰ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì›ë³¸ ì•½í’ˆ ì •ë³´ ì°¾ê¸°
    target_medicine_info = find_medicine_info_in_excel(medicine_name)
    target_ingredients = extract_ingredients_from_medicine_info(target_medicine_info) if target_medicine_info else []
    
    # ìƒì„¸í•œ ëŒ€ì•ˆ ë¶„ì„ ìƒì„± (ì„±ë¶„ ì¤‘ì‹¬)
    return generate_ingredient_focused_alternative_analysis(medicine_name, detailed_alternatives, target_medicine_info or {}, target_ingredients)

def handle_similar_medicines_question(medicine_name: str, conversation_context: str, current_query: str) -> str:
    """ìœ ì‚¬ ì•½í’ˆ ì§ˆë¬¸ ì²˜ë¦¬"""
    print(f"ğŸ” ìœ ì‚¬ ì•½í’ˆ ì§ˆë¬¸ ì²˜ë¦¬: {medicine_name}")
    
    # Excel DBì—ì„œ ëŒ€ìƒ ì•½í’ˆ ì •ë³´ ì°¾ê¸°
    target_medicine_info = find_medicine_info_in_excel(medicine_name)
    if not target_medicine_info or target_medicine_info["íš¨ëŠ¥"] == "ì •ë³´ ì—†ìŒ":
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{medicine_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ìœ ì‚¬ ì•½í’ˆì„ ì œì•ˆí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë™ì  ìœ ì‚¬ ì•½í’ˆ ê²€ìƒ‰
    similar_medicines = find_similar_medicines_dynamically(medicine_name, target_medicine_info)
    
    if not similar_medicines:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{medicine_name}'ê³¼ ìœ ì‚¬í•œ ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ìƒì„¸í•œ ìœ ì‚¬ ì•½í’ˆ ë¶„ì„ ìƒì„±
    return generate_detailed_similar_analysis(medicine_name, similar_medicines, target_medicine_info)

def find_medicine_info_in_excel(medicine_name: str) -> Dict:
    """Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ì°¾ê¸°"""
    for doc in excel_docs:
        if doc.metadata.get("ì œí’ˆëª…") == medicine_name:
            return {
                "ì œí’ˆëª…": doc.metadata.get("ì œí’ˆëª…", ""),
                "ì£¼ì„±ë¶„": doc.metadata.get("ì£¼ì„±ë¶„", ""),
                "íš¨ëŠ¥": extract_field_from_doc(doc.page_content, "íš¨ëŠ¥"),
                "ë¶€ì‘ìš©": extract_field_from_doc(doc.page_content, "ë¶€ì‘ìš©"),
                "ì‚¬ìš©ë²•": extract_field_from_doc(doc.page_content, "ì‚¬ìš©ë²•"),
                "content": doc.page_content
            }
    return {}

def find_alternative_medicines_dynamically(medicine_name: str, target_medicine_info: Dict) -> List[Dict]:
    """ë™ì ìœ¼ë¡œ ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰"""
    print(f"ğŸ” ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰: {medicine_name}")
    
    # ëŒ€ìƒ ì•½í’ˆì˜ ì£¼ì„±ë¶„ ì¶”ì¶œ
    target_ingredients = extract_ingredients_from_medicine_info(target_medicine_info)
    print(f"  ëŒ€ìƒ ì•½í’ˆ ì£¼ì„±ë¶„: {target_ingredients}")
    
    alternative_medicines = []
    
    # Excel DB ì „ì²´ì—ì„œ ìœ ì‚¬í•œ ì•½í’ˆë“¤ ê²€ìƒ‰
    for doc in excel_docs:
        doc_name = doc.metadata.get("ì œí’ˆëª…", "")
        if doc_name == medicine_name:  # ìê¸° ìì‹ ì€ ì œì™¸
            continue
            
        doc_ingredients = extract_ingredients_from_doc(doc)
        if not doc_ingredients:
            continue
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity_score = calculate_ingredient_similarity(target_ingredients, doc_ingredients)
        
        if similarity_score > 0.3:  # 30% ì´ìƒ ìœ ì‚¬í•˜ë©´ í›„ë³´ë¡œ ì¶”ê°€
            alternative_medicines.append({
                "name": doc_name,
                "ingredients": doc_ingredients,
                "similarity_score": similarity_score,
                "efficacy": extract_field_from_doc(doc.page_content, "íš¨ëŠ¥"),
                "side_effects": extract_field_from_doc(doc.page_content, "ë¶€ì‘ìš©"),
                "usage": extract_field_from_doc(doc.page_content, "ì‚¬ìš©ë²•"),
                "content": doc.page_content
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œ ë°˜í™˜
    alternative_medicines.sort(key=lambda x: x["similarity_score"], reverse=True)
    return alternative_medicines[:3]

def find_alternative_medicines_with_priority(medicine_name: str, target_medicine_info: Dict, target_ingredients: List[str]) -> List[Dict]:
    """ìš°ì„ ìˆœìœ„ë¥¼ ì ìš©í•œ ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰ (ë™ì¼ ì„±ë¶„ > ìœ ì‚¬ ì„±ë¶„ > íš¨ëŠ¥ ê¸°ë°˜)"""
    print(f"ğŸ” ìš°ì„ ìˆœìœ„ ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰: {medicine_name}")
    
    # 1ë‹¨ê³„: ë™ì¼ ì„±ë¶„ ì•½í’ˆ ê²€ìƒ‰
    same_ingredient_medicines = find_medicines_with_same_ingredients(medicine_name, target_ingredients)
    print(f"  ë™ì¼ ì„±ë¶„ ì•½í’ˆ: {[med['name'] for med in same_ingredient_medicines]}")
    
    # 2ë‹¨ê³„: ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ ê²€ìƒ‰
    similar_ingredient_medicines = find_medicines_with_similar_ingredients(medicine_name, target_ingredients)
    print(f"  ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ: {[med['name'] for med in similar_ingredient_medicines]}")
    
    # 3ë‹¨ê³„: íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ê²€ìƒ‰
    efficacy_based_medicines = find_medicines_by_efficacy(medicine_name, target_medicine_info, target_ingredients)
    print(f"  íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ: {[med['name'] for med in efficacy_based_medicines]}")
    
    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œ ë°˜í™˜
    result = []
    if same_ingredient_medicines:
        result.extend(same_ingredient_medicines[:2])  # ë™ì¼ ì„±ë¶„ ìµœëŒ€ 2ê°œ
    if similar_ingredient_medicines and len(result) < 3:
        remaining = 3 - len(result)
        result.extend(similar_ingredient_medicines[:remaining])
    if len(result) < 3:
        remaining = 3 - len(result)
        result.extend(efficacy_based_medicines[:remaining])
    
    return result[:3]

def find_medicines_with_same_ingredients(medicine_name: str, target_ingredients: List[str]) -> List[Dict]:
    """ë™ì¼ ì„±ë¶„ì„ ê°€ì§„ ì•½í’ˆ ê²€ìƒ‰"""
    same_ingredient_medicines = []
    
    for doc in excel_docs:
        doc_name = doc.metadata.get("ì œí’ˆëª…", "")
        if doc_name == medicine_name:
            continue
            
        doc_ingredients = extract_ingredients_from_doc(doc)
        if not doc_ingredients:
            continue
        
        # ë™ì¼ ì„±ë¶„ í™•ì¸ (ìˆœì„œ ë¬´ê´€)
        if set(target_ingredients) == set(doc_ingredients):
            same_ingredient_medicines.append({
                "name": doc_name,
                "ingredients": doc_ingredients,
                "similarity_score": 1.0,
                "efficacy": extract_field_from_doc(doc.page_content, "íš¨ëŠ¥"),
                "side_effects": extract_field_from_doc(doc.page_content, "ë¶€ì‘ìš©"),
                "usage": extract_field_from_doc(doc.page_content, "ì‚¬ìš©ë²•"),
                "content": doc.page_content,
                "priority": 1
            })
    
    return same_ingredient_medicines

def find_medicines_with_similar_ingredients(medicine_name: str, target_ingredients: List[str]) -> List[Dict]:
    """ìœ ì‚¬ ì„±ë¶„ì„ ê°€ì§„ ì•½í’ˆ ê²€ìƒ‰"""
    similar_ingredient_medicines = []
    
    for doc in excel_docs:
        doc_name = doc.metadata.get("ì œí’ˆëª…", "")
        if doc_name == medicine_name:
            continue
            
        doc_ingredients = extract_ingredients_from_doc(doc)
        if not doc_ingredients:
            continue
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity_score = calculate_ingredient_similarity(target_ingredients, doc_ingredients)
        
        # 50% ì´ìƒ ìœ ì‚¬í•˜ê³  ì™„ì „ ì¼ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°
        if 0.5 <= similarity_score < 1.0:
            similar_ingredient_medicines.append({
                "name": doc_name,
                "ingredients": doc_ingredients,
                "similarity_score": similarity_score,
                "efficacy": extract_field_from_doc(doc.page_content, "íš¨ëŠ¥"),
                "side_effects": extract_field_from_doc(doc.page_content, "ë¶€ì‘ìš©"),
                "usage": extract_field_from_doc(doc.page_content, "ì‚¬ìš©ë²•"),
                "content": doc.page_content,
                "priority": 2
            })
    
    return similar_ingredient_medicines

def find_medicines_by_efficacy(medicine_name: str, target_medicine_info: Dict, target_ingredients: List[str]) -> List[Dict]:
    """íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ê²€ìƒ‰"""
    efficacy_based_medicines = []
    target_efficacy = target_medicine_info.get("íš¨ëŠ¥", "")
    
    for doc in excel_docs:
        doc_name = doc.metadata.get("ì œí’ˆëª…", "")
        if doc_name == medicine_name:
            continue
            
        doc_ingredients = extract_ingredients_from_doc(doc)
        if not doc_ingredients:
            continue
        
        doc_efficacy = extract_field_from_doc(doc.page_content, "íš¨ëŠ¥")
        
        # íš¨ëŠ¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        efficacy_similarity = calculate_efficacy_similarity(target_efficacy, doc_efficacy)
        
        if efficacy_similarity > 0.3:
            efficacy_based_medicines.append({
                "name": doc_name,
                "ingredients": doc_ingredients,
                "similarity_score": efficacy_similarity,
                "efficacy": doc_efficacy,
                "side_effects": extract_field_from_doc(doc.page_content, "ë¶€ì‘ìš©"),
                "usage": extract_field_from_doc(doc.page_content, "ì‚¬ìš©ë²•"),
                "content": doc.page_content,
                "priority": 3
            })
    
    return efficacy_based_medicines

def calculate_efficacy_similarity(target_efficacy: str, doc_efficacy: str) -> float:
    """íš¨ëŠ¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    if not target_efficacy or not doc_efficacy or target_efficacy == "ì •ë³´ ì—†ìŒ" or doc_efficacy == "ì •ë³´ ì—†ìŒ":
        return 0.0
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
    target_keywords = set(target_efficacy.lower().split())
    doc_keywords = set(doc_efficacy.lower().split())
    
    if not target_keywords or not doc_keywords:
        return 0.0
    
    common_keywords = target_keywords & doc_keywords
    union_keywords = target_keywords | doc_keywords
    
    return len(common_keywords) / len(union_keywords) if union_keywords else 0.0

def find_similar_medicines_dynamically(medicine_name: str, target_medicine_info: Dict) -> List[Dict]:
    """ë™ì ìœ¼ë¡œ ìœ ì‚¬ ì•½í’ˆ ê²€ìƒ‰ (ëŒ€ì•ˆê³¼ ë™ì¼í•œ ë¡œì§)"""
    return find_alternative_medicines_dynamically(medicine_name, target_medicine_info)

def extract_ingredients_from_medicine_info(medicine_info: Dict) -> List[str]:
    """ì•½í’ˆ ì •ë³´ì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ"""
    ingredients = []
    
    if medicine_info.get('ì£¼ì„±ë¶„') and medicine_info['ì£¼ì„±ë¶„'] != 'ì •ë³´ ì—†ìŒ':
        main_ingredient = medicine_info['ì£¼ì„±ë¶„']
        if ',' in main_ingredient:
            ingredients = [ing.strip() for ing in main_ingredient.split(',') if ing.strip()]
        else:
            ingredients = [main_ingredient.strip()]
    
    return ingredients

def extract_ingredients_from_doc(doc) -> List[str]:
    """ë¬¸ì„œì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ"""
    ingredients = []
    
    # ë©”íƒ€ë°ì´í„°ì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ
    if doc.metadata.get("ì£¼ì„±ë¶„") and doc.metadata["ì£¼ì„±ë¶„"] != "ì •ë³´ ì—†ìŒ":
        main_ingredient = doc.metadata["ì£¼ì„±ë¶„"]
        if ',' in main_ingredient:
            ingredients = [ing.strip() for ing in main_ingredient.split(',') if ing.strip()]
        else:
            ingredients = [main_ingredient.strip()]
    
    return ingredients

def calculate_ingredient_similarity(target_ingredients: List[str], doc_ingredients: List[str]) -> float:
    """ì£¼ì„±ë¶„ ìœ ì‚¬ë„ ê³„ì‚°"""
    if not target_ingredients or not doc_ingredients:
        return 0.0
    
    # ì •ê·œí™”ëœ ì„±ë¶„ëª…ìœ¼ë¡œ ë³€í™˜
    target_normalized = [normalize_ingredient_name(ing) for ing in target_ingredients]
    doc_normalized = [normalize_ingredient_name(ing) for ing in doc_ingredients]
    
    # êµì§‘í•© ê³„ì‚°
    common_ingredients = set(target_normalized) & set(doc_normalized)
    
    if not common_ingredients:
        return 0.0
    
    # ìœ ì‚¬ë„ = êµì§‘í•© í¬ê¸° / í•©ì§‘í•© í¬ê¸°
    union_size = len(set(target_normalized) | set(doc_normalized))
    similarity = len(common_ingredients) / union_size
    
    return similarity

def normalize_ingredient_name(ingredient: str) -> str:
    """ì„±ë¶„ëª… ì •ê·œí™”"""
    if not ingredient:
        return ""
    
    # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
    normalized = ingredient.lower().strip()
    normalized = ''.join(c for c in normalized if c.isalnum() or c in 'ê°€-í£')
    
    return normalized

def generate_detailed_alternative_analysis(medicine_name: str, alternative_medicines: List[Dict], target_medicine_info: Dict) -> str:
    """ìƒì„¸í•œ ëŒ€ì•ˆ ë¶„ì„ ìƒì„±"""
    
    # LLMì—ê²Œ ìƒì„¸í•œ ëŒ€ì•ˆ ë¶„ì„ ìš”ì²­
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì•½ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {medicine_name}ì˜ ëŒ€ì•ˆ ì•½í’ˆì— ëŒ€í•´ ìƒì„¸í•˜ê³  ê·¼ê±° ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

    **ëŒ€ìƒ ì•½í’ˆ ({medicine_name}) ì •ë³´:**
    - ì£¼ì„±ë¶„: {target_medicine_info.get('ì£¼ì„±ë¶„', 'ì •ë³´ ì—†ìŒ')}
    - íš¨ëŠ¥: {target_medicine_info.get('íš¨ëŠ¥', 'ì •ë³´ ì—†ìŒ')}
    - ë¶€ì‘ìš©: {target_medicine_info.get('ë¶€ì‘ìš©', 'ì •ë³´ ì—†ìŒ')}

    **ë°œê²¬ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤:**
    {format_alternative_medicines_for_analysis(alternative_medicines)}

    **ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
    1. ê° ëŒ€ì•ˆ ì•½í’ˆì˜ ì£¼ì„±ë¶„ê³¼ íš¨ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„
    2. ëŒ€ìƒ ì•½í’ˆê³¼ì˜ ìœ ì‚¬ì ê³¼ ì°¨ì´ì ì„ ëª…í™•íˆ ì„¤ëª…
    3. ê° ëŒ€ì•ˆì˜ ì¥ë‹¨ì ì„ ê°ê´€ì ìœ¼ë¡œ ì œì‹œ
    4. ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ê³¼ ë¶€ì‘ìš©ì„ í¬í•¨
    5. ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–¤ ëŒ€ì•ˆì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ì€ì§€ ì¡°ì–¸
    
    **ì¤‘ìš” ì§€ì¹¨:**
    - ë°˜ë“œì‹œ ìœ„ì—ì„œ ì œê³µëœ ëŒ€ì•ˆ ì•½í’ˆë“¤ë§Œ ë¶„ì„í•˜ê³  ì–¸ê¸‰
    - ì´ë¶€í”„ë¡œíœ, ë‚˜í”„ë¡ì„¼ ê°™ì€ ì„±ë¶„ëª…ì„ ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œí•˜ì§€ ë§ê³ , ì‹¤ì œ ì•½í’ˆëª…ë§Œ ì‚¬ìš©
    - ë°œê²¬ëœ ëŒ€ì•ˆ ì•½í’ˆì´ ì—†ìœ¼ë©´ "í•´ë‹¹ ì•½í’ˆê³¼ ìœ ì‚¬í•œ ëŒ€ì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ

    **ë‹µë³€ êµ¬ì¡°:**
    1. **ëŒ€ì•ˆ ì•½í’ˆ ê°œìš”**: ë°œê²¬ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤ ì†Œê°œ
    2. **ìƒì„¸ ë¶„ì„**: ê° ëŒ€ì•ˆ ì•½í’ˆë³„ ìƒì„¸ ë¶„ì„
    3. **ë¹„êµ ë¶„ì„**: ëŒ€ìƒ ì•½í’ˆê³¼ì˜ ë¹„êµ
    4. **ì„ íƒ ê°€ì´ë“œ**: ìƒí™©ë³„ ì¶”ì²œ ê°€ì´ë“œ
    5. **ì£¼ì˜ì‚¬í•­**: ê³µí†µ ì£¼ì˜ì‚¬í•­ ë° ë¶€ì‘ìš©

    ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    """
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        print(f"âŒ ëŒ€ì•ˆ ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        return generate_fallback_alternative_analysis(medicine_name, alternative_medicines)

def generate_detailed_similar_analysis(medicine_name: str, similar_medicines: List[Dict], target_medicine_info: Dict) -> str:
    """ìƒì„¸í•œ ìœ ì‚¬ ì•½í’ˆ ë¶„ì„ ìƒì„± (ëŒ€ì•ˆê³¼ ë™ì¼í•œ ë¡œì§)"""
    return generate_detailed_alternative_analysis(medicine_name, similar_medicines, target_medicine_info)

def format_alternative_medicines_for_analysis(alternative_medicines: List[Dict]) -> str:
    """ë¶„ì„ìš© ëŒ€ì•ˆ ì•½í’ˆ ì •ë³´ í¬ë§·íŒ…"""
    if not alternative_medicines:
        return "ëŒ€ì•ˆ ì•½í’ˆ ì—†ìŒ"
    
    formatted = []
    for i, alt in enumerate(alternative_medicines, 1):
        formatted.append(f"{i}. {alt['name']}")
        formatted.append(f"   - ì£¼ì„±ë¶„: {', '.join(alt['ingredients'])}")
        formatted.append(f"   - ìœ ì‚¬ë„: {alt['similarity_score']:.2f}")
        formatted.append(f"   - íš¨ëŠ¥: {alt['efficacy']}")
        formatted.append(f"   - ë¶€ì‘ìš©: {alt['side_effects']}")
        formatted.append(f"   - ì‚¬ìš©ë²•: {alt['usage']}")
        formatted.append("")
    
    return "\n".join(formatted)

def generate_fallback_alternative_analysis(medicine_name: str, alternative_medicines: List[Dict]) -> str:
    """ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ëŒ€ì•ˆ ë¶„ì„"""
    response = f"**{medicine_name}ì˜ ëŒ€ì•ˆ ì•½í’ˆ ë¶„ì„**\n\n"
    
    if not alternative_medicines:
        return response + "ì£„ì†¡í•©ë‹ˆë‹¤. ëŒ€ì•ˆ ì•½í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    response += f"Excel DB ë¶„ì„ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ëŒ€ì•ˆ ì•½í’ˆë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
    
    for i, alt in enumerate(alternative_medicines, 1):
        response += f"**{i}. {alt['name']}**\n"
        response += f"- ì£¼ì„±ë¶„: {', '.join(alt['ingredients'])}\n"
        response += f"- íš¨ëŠ¥: {alt['efficacy']}\n"
        response += f"- ìœ ì‚¬ë„: {alt['similarity_score']:.2f}\n\n"
    
    response += get_medical_consultation_footer("warning")
    
    return response

def generate_ingredient_focused_alternative_analysis(medicine_name: str, alternative_medicines: List[Dict], target_medicine_info: Dict, target_ingredients: List[str]) -> str:
    """ì„±ë¶„ ì¤‘ì‹¬ì˜ ëŒ€ì•ˆ ë¶„ì„ ìƒì„±"""
    print(f"ğŸ” ì„±ë¶„ ì¤‘ì‹¬ ëŒ€ì•ˆ ë¶„ì„ ìƒì„±: {medicine_name}")
    
    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê·¸ë£¹í™”
    same_ingredient = [med for med in alternative_medicines if med.get("priority") == 1]
    similar_ingredient = [med for med in alternative_medicines if med.get("priority") == 2]
    efficacy_based = [med for med in alternative_medicines if med.get("priority") == 3]
    
    analysis_parts = []
    
    # 1. ë™ì¼ ì„±ë¶„ ì•½í’ˆ ë¶„ì„
    if same_ingredient:
        analysis_parts.append(f"**ğŸŸ¢ ë™ì¼ ì„±ë¶„ ëŒ€ì•ˆ ì•½í’ˆ:**")
        for med in same_ingredient:
            analysis_parts.append(f"â€¢ **{med['name']}**: {', '.join(med['ingredients'])}")
            analysis_parts.append(f"  - {medicine_name}ê³¼ ì™„ì „íˆ ë™ì¼í•œ ì„±ë¶„ìœ¼ë¡œ ë™ì¼í•œ íš¨ê³¼")
            analysis_parts.append(f"  - íš¨ëŠ¥: {med['efficacy']}")
            if med.get('side_effects') and med['side_effects'] != 'ì •ë³´ ì—†ìŒ':
                analysis_parts.append(f"  - ì£¼ì˜ì‚¬í•­: {med['side_effects']}")
        analysis_parts.append("")
    
    # 1-1. ì‹¤ì œ ì°¾ì€ ëŒ€ì•ˆ ì•½í’ˆë“¤ ë¶„ì„ (ìš°ì„ ìˆœìœ„ ì—†ì´)
    if not same_ingredient and not similar_ingredient and not efficacy_based:
        analysis_parts.append(f"**ğŸ” ë°œê²¬ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤:**")
        for med in alternative_medicines:
            analysis_parts.append(f"â€¢ **{med['name']}**: {', '.join(med['ingredients']) if med['ingredients'] else 'ì„±ë¶„ ì •ë³´ ì—†ìŒ'}")
            analysis_parts.append(f"  - íš¨ëŠ¥: {med['efficacy']}")
            if med.get('side_effects') and med['side_effects'] != 'ì •ë³´ ì—†ìŒ':
                analysis_parts.append(f"  - ì£¼ì˜ì‚¬í•­: {med['side_effects']}")
        analysis_parts.append("")
    
    # 2. ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ ë¶„ì„
    if similar_ingredient:
        analysis_parts.append(f"**ğŸŸ¡ ìœ ì‚¬ ì„±ë¶„ ëŒ€ì•ˆ ì•½í’ˆ:**")
        for med in similar_ingredient:
            analysis_parts.append(f"â€¢ **{med['name']}**: {', '.join(med['ingredients'])}")
            common_ingredients = set(target_ingredients) & set(med['ingredients'])
            different_ingredients = set(med['ingredients']) - set(target_ingredients)
            
            if common_ingredients:
                analysis_parts.append(f"  - ê³µí†µ ì„±ë¶„: {', '.join(common_ingredients)} (ìœ ì‚¬í•œ íš¨ê³¼)")
            if different_ingredients:
                analysis_parts.append(f"  - ì¶”ê°€ ì„±ë¶„: {', '.join(different_ingredients)} (ì¶”ê°€ íš¨ê³¼)")
            analysis_parts.append(f"  - íš¨ëŠ¥: {med['efficacy']}")
            if med.get('side_effects') and med['side_effects'] != 'ì •ë³´ ì—†ìŒ':
                analysis_parts.append(f"  - ì£¼ì˜ì‚¬í•­: {med['side_effects']}")
        analysis_parts.append("")
    
    # 3. íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ë¶„ì„
    if efficacy_based:
        analysis_parts.append(f"**ğŸ”µ íš¨ëŠ¥ ê¸°ë°˜ ëŒ€ì•ˆ ì•½í’ˆ:**")
        for med in efficacy_based:
            analysis_parts.append(f"â€¢ **{med['name']}**: {', '.join(med['ingredients'])}")
            analysis_parts.append(f"  - ë‹¤ë¥¸ ì„±ë¶„ì´ì§€ë§Œ ìœ ì‚¬í•œ íš¨ëŠ¥")
            analysis_parts.append(f"  - íš¨ëŠ¥: {med['efficacy']}")
            if med.get('side_effects') and med['side_effects'] != 'ì •ë³´ ì—†ìŒ':
                analysis_parts.append(f"  - ì£¼ì˜ì‚¬í•­: {med['side_effects']}")
        analysis_parts.append("")
    
    # 4. ì„±ë¶„ë³„ ìƒì„¸ ì„¤ëª…
    analysis_parts.append(f"**ğŸ§ª ì£¼ìš” ì„±ë¶„ë³„ ì‘ìš©ê¸°ì „:**")
    for ingredient in target_ingredients:
        analysis_parts.append(f"â€¢ **{ingredient}**:")
        if ingredient == "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ":
            analysis_parts.append("  - ì¤‘ì¶”ì‹ ê²½ê³„ì—ì„œ í”„ë¡œìŠ¤íƒ€ê¸€ë€ë”˜ í•©ì„± ì–µì œ")
            analysis_parts.append("  - í•´ì—´ì§„í†µ íš¨ê³¼, ìœ„ì¥ê´€ ë¶€ì‘ìš© ì ìŒ")
        elif ingredient == "ì¹´í˜ì¸ë¬´ìˆ˜ë¬¼":
            analysis_parts.append("  - ì•„ë°ë…¸ì‹  ìˆ˜ìš©ì²´ ì°¨ë‹¨ìœ¼ë¡œ ì¤‘ì¶”ì‹ ê²½ê³„ ìê·¹")
            analysis_parts.append("  - ì§„í†µì œ íš¨ê³¼ ì¦ê°•, ê°ì„± íš¨ê³¼")
        elif ingredient == "í‘¸ë¥´ì„¤í‹°ì•„ë¯¼":
            analysis_parts.append("  - ë¹„íƒ€ë¯¼ B1 ìœ ë„ì²´ë¡œ ì‹ ê²½ê³„ ê¸°ëŠ¥ ê°œì„ ")
            analysis_parts.append("  - í”¼ë¡œ íšŒë³µ, ì‹ ê²½ì—¼ ì˜ˆë°©")
        else:
            analysis_parts.append("  - í•´ë‹¹ ì„±ë¶„ì˜ êµ¬ì²´ì ì¸ ì‘ìš©ê¸°ì „")
    analysis_parts.append("")
    
    # 5. ì„ íƒ ê°€ì´ë“œ
    analysis_parts.append(f"**ğŸ’¡ ì„ íƒ ê°€ì´ë“œ:**")
    if same_ingredient:
        analysis_parts.append("â€¢ ë™ì¼í•œ íš¨ê³¼ë¥¼ ì›í•œë‹¤ë©´ â†’ ë™ì¼ ì„±ë¶„ ì•½í’ˆ ì¶”ì²œ")
    if similar_ingredient:
        analysis_parts.append("â€¢ ë¹„ìŠ·í•œ íš¨ê³¼ì— ì¶”ê°€ íš¨ê³¼ë¥¼ ì›í•œë‹¤ë©´ â†’ ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ ê³ ë ¤")
    if efficacy_based:
        analysis_parts.append("â€¢ ë‹¤ë¥¸ ì„±ë¶„ìœ¼ë¡œ ê°™ì€ íš¨ê³¼ë¥¼ ì›í•œë‹¤ë©´ â†’ íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ê³ ë ¤")
    
    analysis_parts.append("â€¢ ê°œì¸ ê±´ê°• ìƒíƒœì™€ ì•Œë ˆë¥´ê¸° ì´ë ¥ì„ ê³ ë ¤í•˜ì—¬ ì„ íƒ")
    analysis_parts.append("â€¢ ì¥ê¸° ë³µìš© ì‹œ ì˜ì‚¬ì™€ ìƒë‹´ ê¶Œì¥")
    
    return "\n".join(analysis_parts)

def extract_alternative_medicines_from_context(conversation_context: str) -> List[str]:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì–¸ê¸‰ëœ ëŒ€ì•ˆ ì•½í’ˆë“¤ ì¶”ì¶œ (ë™ì  ë°©ì‹)"""
    print(f"ğŸ” ëŒ€í™”ì—ì„œ ëŒ€ì•ˆ ì•½í’ˆ ì¶”ì¶œ: {conversation_context[:100]}...")
    
    # LLMì„ ì‚¬ìš©í•œ ì§€ëŠ¥ì  ì¶”ì¶œ
    try:
        from openai import OpenAI
        client = OpenAI(api_key="your-api-key")  # ì‹¤ì œ API í‚¤ë¡œ êµì²´ í•„ìš”
        
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª…ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”. 
ëŒ€í™” ë‚´ìš©: {conversation_context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{"medicines": ["ì•½í’ˆëª…1", "ì•½í’ˆëª…2", "ì•½í’ˆëª…3"]}}

ì£¼ì˜ì‚¬í•­:
- ì‹¤ì œ ì•½í’ˆëª…ë§Œ ì¶”ì¶œ (ì„±ë¶„ëª… ì œì™¸)
- ì´ë¶€í”„ë¡œíœ, ë‚˜í”„ë¡ì„¼ ê°™ì€ ì„±ë¶„ëª…ì€ ì œì™¸
- í¬íœì •, ê²Œë³´ë¦°ì •, íƒ€ì´ë ˆë†€ ê°™ì€ ì‹¤ì œ ì•½í’ˆëª…ë§Œ í¬í•¨
"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª…ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200,
            temperature=0.1
        )
        
        import json
        result = json.loads(response.choices[0].message.content.strip())
        medicines = result.get("medicines", [])
        print(f"  LLMìœ¼ë¡œ ì¶”ì¶œëœ ì•½í’ˆë“¤: {medicines}")
        return medicines
        
    except Exception as e:
        print(f"âŒ LLM ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # í´ë°±: ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­
        return extract_medicines_simple_pattern(conversation_context)

def extract_medicines_simple_pattern(conversation_context: str) -> List[str]:
    """Excel DB ê¸°ë°˜ ì•½í’ˆëª… ì¶”ì¶œ (í•˜ë“œì½”ë”© ì—†ëŠ” ë°©ì‹)"""
    print(f"ğŸ” Excel DB ê¸°ë°˜ ì•½í’ˆëª… ì¶”ì¶œ ì‹œì‘")
    
    # Excel DBì—ì„œ ëª¨ë“  ì•½í’ˆëª… ê°€ì ¸ì˜¤ê¸°
    all_medicine_names = set()
    for doc in excel_docs:
        medicine_name = doc.metadata.get("ì œí’ˆëª…", "")
        if medicine_name and medicine_name != "ì •ë³´ ì—†ìŒ":
            all_medicine_names.add(medicine_name)
    
    print(f"  Excel DBì— ìˆëŠ” ì•½í’ˆ ìˆ˜: {len(all_medicine_names)}")
    
    # ëŒ€í™”ì—ì„œ Excel DBì— ìˆëŠ” ì•½í’ˆëª…ë“¤ë§Œ ì°¾ê¸°
    found_medicines = []
    for medicine_name in all_medicine_names:
        # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ë‹¨ì–´ ê²½ê³„ ê³ ë ¤
        import re
        pattern = r'\b' + re.escape(medicine_name) + r'\b'
        if re.search(pattern, conversation_context):
            found_medicines.append(medicine_name)
            print(f"  ë°œê²¬ëœ ì•½í’ˆ: {medicine_name}")
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    unique_medicines = list(set(found_medicines))
    print(f"  ìµœì¢… ì¶”ì¶œëœ ì•½í’ˆë“¤: {unique_medicines}")
    return unique_medicines
