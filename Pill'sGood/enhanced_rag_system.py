# enhanced_rag_system.py - í†µí•© RAG ì‹œìŠ¤í…œ

import time
import json
from typing import Dict, List, Optional
from qa_state import QAState
from retrievers import (
    excel_docs, pdf_structured_docs, 
    extract_active_ingredients_from_medicine,
    llm
)
from pubchem_api import PubChemAPI
from translation_rag import TranslationRAG
from answer_utils import generate_response_llm_from_prompt

# YouTube ê²€ìƒ‰ í•¨ìˆ˜ import
from sns_node import search_youtube_videos, get_video_transcript, summarize_video_content

# ë„¤ì´ë²„ ë‰´ìŠ¤ API import
from naver_news_api import NaverNewsAPI

class EnhancedRAGSystem:
    """í†µí•© RAG ì‹œìŠ¤í…œ - ì—¬ëŸ¬ DBì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¡°í•©í•˜ì—¬ ê·¼ê±° ìˆëŠ” ë‹µë³€ ìƒì„±"""
    
    def __init__(self):
        self.pubchem_api = PubChemAPI()
        self.translation_rag = TranslationRAG()
        self.naver_news_api = NaverNewsAPI()  # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.llm = llm
    
    def analyze_medicine_comprehensively(self, medicine_name: str, usage_context: str) -> Dict:
        """ì•½í’ˆ ì¢…í•© ë¶„ì„ - ì§„ì •í•œ RAG êµ¬í˜„ (YouTube í†µí•©)"""
        print(f"ğŸ” ì¢…í•© ì•½í’ˆ ë¶„ì„ ì‹œì‘: {medicine_name} â†’ {usage_context}")
        
        analysis_result = {
            'medicine_name': medicine_name,
            'usage_context': usage_context,
            'excel_info': {},
            'pdf_info': {},
            'korean_ingredient_info': {},
            'international_ingredient_info': {},
            'youtube_info': {},  # âœ… YouTube ì •ë³´ ì¶”ê°€
            'naver_news_info': {},  # âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ ì¶”ê°€
            'combined_analysis': {},
            'evidence_based_response': '',
            'follow_up_questions': [],
            'analysis_timestamp': time.time()
        }
        
        try:
            # 1ë‹¨ê³„: Excel DBì—ì„œ ê¸°ë³¸ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘
            print("ğŸ“Š 1ë‹¨ê³„: Excel DBì—ì„œ ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘...")
            excel_info = self._get_excel_medicine_info(medicine_name)
            analysis_result['excel_info'] = excel_info
            
            # 2ë‹¨ê³„: PDF DB ê²€ìƒ‰ ì œê±° (Excel DBë§Œ ì‚¬ìš©)
            print("ğŸ“„ 2ë‹¨ê³„: PDF DB ê²€ìƒ‰ ê±´ë„ˆëœ€ (Excel DBë§Œ ì‚¬ìš©)")
            analysis_result['pdf_info'] = {}
            
            # 3ë‹¨ê³„: ì£¼ì„±ë¶„ ì¶”ì¶œ
            print("ğŸ§ª 3ë‹¨ê³„: ì£¼ì„±ë¶„ ì¶”ì¶œ...")
            active_ingredients = self._extract_active_ingredients(medicine_name, excel_info)
            print(f"  ì¶”ì¶œëœ ì£¼ì„±ë¶„: {active_ingredients}")
            
            # 4ë‹¨ê³„: ê° ì£¼ì„±ë¶„ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„
            korean_ingredient_info = {}
            international_ingredient_info = {}
            
            for ingredient in active_ingredients:
                print(f"ğŸ” ì£¼ì„±ë¶„ ë¶„ì„: {ingredient}")
                
                # PubChemì—ì„œ êµ­ì œ ì •ë³´ ìˆ˜ì§‘ (í•œêµ­ì–´ëª… ìë™ ë³€í™˜)
                print(f"  ğŸŒ PubChemì—ì„œ {ingredient} ì •ë³´ ìˆ˜ì§‘...")
                international_info = self.pubchem_api.analyze_ingredient_comprehensive(ingredient)
                
                # ë²ˆì—­ RAGë¡œ ì˜ì–´ ì •ë³´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­
                print(f"  ğŸ”„ {ingredient} ì •ë³´ ë²ˆì—­ ì¤‘...")
                translated_info = self.translation_rag.translate_pharmacology_info(international_info)
                international_ingredient_info[ingredient] = {
                    'original': international_info,
                    'translated': translated_info
                }
            
            analysis_result['korean_ingredient_info'] = korean_ingredient_info
            analysis_result['international_ingredient_info'] = international_ingredient_info
            
            # 4.5ë‹¨ê³„: YouTubeì—ì„œ ì‹¤ì „ ì •ë³´ ìˆ˜ì§‘
            print("ğŸ“º 4.5ë‹¨ê³„: YouTubeì—ì„œ ì‹¤ì „ ì •ë³´ ìˆ˜ì§‘...")
            youtube_info = self._search_youtube_info(medicine_name, usage_context, active_ingredients)
            analysis_result['youtube_info'] = youtube_info
            
            # 4.6ë‹¨ê³„: ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (âœ… ì‹ ì œí’ˆ, íŠ¸ë Œë“œ ë“±)
            print("ğŸ“° 4.6ë‹¨ê³„: ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘...")
            naver_news_info = self._search_naver_news_info(medicine_name, active_ingredients)
            analysis_result['naver_news_info'] = naver_news_info
            
            # 5ë‹¨ê³„: LLMì´ ëª¨ë“  ì •ë³´ë¥¼ ì¡°í•©í•˜ì—¬ ê·¼ê±° ìˆëŠ” ë¶„ì„ ìˆ˜í–‰
            print("ğŸ§  5ë‹¨ê³„: LLM ì¢…í•© ë¶„ì„ (YouTube, ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ í¬í•¨)...")
            combined_analysis = self._perform_llm_analysis(
                medicine_name, usage_context, analysis_result
            )
            analysis_result['combined_analysis'] = combined_analysis
            
            # 6ë‹¨ê³„: ê·¼ê±° ê¸°ë°˜ ë‹µë³€ ìƒì„±
            print("ğŸ“ 6ë‹¨ê³„: ê·¼ê±° ê¸°ë°˜ ë‹µë³€ ìƒì„±...")
            evidence_based_response = self._generate_evidence_based_response(
                medicine_name, usage_context, analysis_result
            )
            analysis_result['evidence_based_response'] = evidence_based_response
            
            # 7ë‹¨ê³„: ì¶”ê°€ ì§ˆë¬¸ ìƒì„±
            print("â“ 7ë‹¨ê³„: ì¶”ê°€ ì§ˆë¬¸ ìƒì„±...")
            follow_up_questions = self._generate_follow_up_questions(analysis_result)
            analysis_result['follow_up_questions'] = follow_up_questions
            
            print(f"âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ: {medicine_name}")
            
        except Exception as e:
            print(f"âŒ ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {e}")
            analysis_result['error'] = str(e)
        
        return analysis_result
    
    def _get_excel_medicine_info(self, medicine_name: str) -> Dict:
        """Excel DBì—ì„œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘ (ë¶€ë¶„ ë§¤ì¹­ ì§€ì›)"""
        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        for doc in excel_docs:
            if doc.metadata.get("ì œí’ˆëª…") == medicine_name:
                return {
                    'product_name': doc.metadata.get("ì œí’ˆëª…", ""),
                    'main_ingredient': doc.metadata.get("ì£¼ì„±ë¶„", ""),
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
        
        # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ìˆ˜ì¶œëª… ë¬¸ì œ í•´ê²°)
        print(f"ğŸ” Enhanced RAG ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨, ë¶€ë¶„ ë§¤ì¹­ ì‹œë„: {medicine_name}")
        for doc in excel_docs:
            product_name = doc.metadata.get("ì œí’ˆëª…", "")
            # ì•½í’ˆëª…ì´ ì œí’ˆëª…ì˜ ì‹œì‘ ë¶€ë¶„ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if product_name.startswith(medicine_name) or medicine_name in product_name:
                print(f"  Enhanced RAG ë¶€ë¶„ ë§¤ì¹­ ë°œê²¬: '{product_name}' (ê²€ìƒ‰ì–´: '{medicine_name}')")
                return {
                    'product_name': doc.metadata.get("ì œí’ˆëª…", ""),
                    'main_ingredient': doc.metadata.get("ì£¼ì„±ë¶„", ""),
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
        
        print(f"âŒ Enhanced RAGì—ì„œ '{medicine_name}' ì•½í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return {}
    
    def _get_pdf_medicine_info(self, medicine_name: str) -> Dict:
        """PDF DBì—ì„œ ì•½í’ˆ ì •ë³´ ìˆ˜ì§‘"""
        for doc in pdf_structured_docs:
            if doc.metadata.get("ì œí’ˆëª…") == medicine_name:
                return {
                    'product_name': doc.metadata.get("ì œí’ˆëª…", ""),
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
        return {}
    
    def _extract_active_ingredients(self, medicine_name: str, excel_info: Dict) -> List[str]:
        """ì£¼ì„±ë¶„ ì¶”ì¶œ"""
        ingredients = []
        
        # Excel ì •ë³´ì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ
        if excel_info.get('main_ingredient') and excel_info['main_ingredient'] != 'ì •ë³´ ì—†ìŒ':
            main_ingredient = excel_info['main_ingredient']
            print(f"ğŸ” {medicine_name} ì£¼ì„±ë¶„ ì¶”ì¶œ: {main_ingredient}")
            
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì„±ë¶„ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ë¦¬
            if ',' in main_ingredient:
                ingredients = [ing.strip() for ing in main_ingredient.split(',') if ing.strip()]
                print(f"  ë¶„ë¦¬ëœ ì„±ë¶„ë“¤: {ingredients}")
            else:
                ingredients = [main_ingredient.strip()]
                print(f"  ë‹¨ì¼ ì„±ë¶„: {ingredients}")
        else:
            print(f"  ì£¼ì„±ë¶„ ì •ë³´ ì—†ìŒ")
        
        # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš© (ë°±ì—…)
        if not ingredients:
            ingredients = extract_active_ingredients_from_medicine(medicine_name)
        
        return ingredients
    
    def _perform_llm_analysis(self, medicine_name: str, usage_context: str, analysis_result: Dict) -> Dict:
        """LLMì´ ëª¨ë“  ì •ë³´ë¥¼ ì¡°í•©í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰ (YouTube, ë„¤ì´ë²„ ë‰´ìŠ¤ í¬í•¨)"""
        
        # ëª¨ë“  ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì •ë¦¬ (ë²ˆì—­ëœ ì •ë³´ ìš°ì„  ì‚¬ìš©)
        collected_info = {
            'medicine_name': medicine_name,
            'usage_context': usage_context,
            'excel_info': analysis_result['excel_info'],
            'pdf_info': analysis_result['pdf_info'],
            'korean_ingredient_info': analysis_result['korean_ingredient_info'],
            'international_ingredient_info': analysis_result['international_ingredient_info'],
            'youtube_info': analysis_result.get('youtube_info', {}),
            'naver_news_info': analysis_result.get('naver_news_info', {})  # âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ ì¶”ê°€
        }
        
        # ë²ˆì—­ëœ ì •ë³´ë¥¼ ë³„ë„ë¡œ ì •ë¦¬
        translated_summaries = {}
        for ingredient, info in analysis_result['international_ingredient_info'].items():
            if 'translated' in info and 'summary_kr' in info['translated']:
                translated_summaries[ingredient] = info['translated']['summary_kr']
        
        # âœ… YouTube ì •ë³´ ìš”ì•½
        youtube_summary = self._format_youtube_info(analysis_result.get('youtube_info', {}))
        
        # âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ ìš”ì•½
        naver_news_summary = self._format_naver_news_info(analysis_result.get('naver_news_info', {}))
        
        analysis_prompt = f"""ë‹¹ì‹ ì€ ë‹¤ì¤‘ ì†ŒìŠ¤ ì˜ì•½í’ˆ ì •ë³´ í†µí•© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ê·¼ê±° ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.

## ğŸ¯ ë¶„ì„ ëª©í‘œ
- ì•½í’ˆ: {medicine_name}
- ì‚¬ìš© ëª©ì : {usage_context}

## ğŸ“š ìˆ˜ì§‘ëœ ì •ë³´ (ë‹¤ì¤‘ ì†ŒìŠ¤)

### ì†ŒìŠ¤ 1: í•œêµ­ ì˜ì•½í’ˆ ì •ë³´ DB - Excel (ì‹ ë¢°ë„: ë†’ìŒ)
{json.dumps(collected_info['excel_info'], indent=2, ensure_ascii=False)}

### ì†ŒìŠ¤ 2: êµ­ì œ ì„±ë¶„ DB (PubChem, ì‹ ë¢°ë„: ë†’ìŒ)
{json.dumps(translated_summaries, indent=2, ensure_ascii=False)}

### ì†ŒìŠ¤ 3: ì „ë¬¸ê°€ ì˜ê²¬ & ì‹¤ì‚¬ìš© ê²½í—˜ (ì‹ ë¢°ë„: ì¤‘ê°„~ë†’ìŒ)
{youtube_summary}

### ì†ŒìŠ¤ 4: ìµœì‹  ë‰´ìŠ¤ & ì¶”ê°€ ì •ë³´ (ì‹ ë¢°ë„: ì¤‘ê°„, ì°¸ê³ ìš©)
{naver_news_summary}

## ğŸ” 4ë‹¨ê³„ í†µí•© ë¶„ì„ í”„ë¡œì„¸ìŠ¤

### STEP 1: ì†ŒìŠ¤ ì‹ ë¢°ë„ í‰ê°€
ê° ì†ŒìŠ¤ì˜ ì •ë³´ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
- í•œêµ­ ì˜ì•½í’ˆ ì •ë³´ DB: ê³µì‹ ì˜ì•½í’ˆ ì •ë³´ (ìµœìš°ì„ )
- PubChem: êµ­ì œ í‘œì¤€ ì•½ë¦¬í•™ ë°ì´í„°
- YouTube/ì „ë¬¸ê°€: ì‹¤ì „ ê²½í—˜ (ì•½ì‚¬/ì˜ì‚¬ ê²€ì¦ í•„ìš”)

ì¶œë ¥: ì–´ëŠ ì†ŒìŠ¤ê°€ ê°€ì¥ ì‹ ë¢°í•  ë§Œí•œì§€ íŒë‹¨

### STEP 2: ì •ë³´ ì¼ê´€ì„± ê²€ì¦
ë‹¤ì¤‘ ì†ŒìŠ¤ ê°„ ì •ë³´ êµì°¨ ê²€ì¦:
1. íš¨ëŠ¥/ì‘ìš©ê¸°ì „ ì¼ì¹˜ ì—¬ë¶€
2. ë¶€ì‘ìš© ì •ë³´ ì¼ì¹˜ ì—¬ë¶€
3. ì‚¬ìš©ë²• ì¼ì¹˜ ì—¬ë¶€

**ëª¨ìˆœ íƒì§€:**
- ì†ŒìŠ¤ ê°„ ëª¨ìˆœ ë°œê²¬ ì‹œ ëª…ì‹œí•˜ê³ , ë” ì‹ ë¢°í•  ì†ŒìŠ¤ë¥¼ ìš°ì„ 
- ì˜ˆ: Excel "ë‘í†µ ì™„í™”" vs YouTube "ê·¼ìœ¡í†µ ì™„í™”" â†’ Excel ìš°ì„ 

ì¶œë ¥: ëª¨ìˆœ ìˆìŒ/ì—†ìŒ, ëª¨ìˆœ ë‚´ìš©, í•´ê²° ë°©ì•ˆ

### STEP 3: ì‘ìš©ê¸°ì „ ë° ì•ˆì „ì„± ì¢…í•© ë¶„ì„
**ì£¼ì„±ë¶„ë³„ ìƒì„¸ ë¶„ì„:**
ê° ì£¼ì„±ë¶„ì— ëŒ€í•´:
1. ì•½ë¦¬í•™ì  ì‘ìš©ê¸°ì „ (ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ”ê°€?)
2. ì‚¬ìš© ëª©ì ê³¼ì˜ ì—°ê´€ì„± ì ìˆ˜ (0~100%)
3. ë¶€ì‘ìš© ì‹¬ê°ë„ (ê²½ë¯¸/ë³´í†µ/ì‹¬ê°)

**ì˜ˆì‹œ:**
- ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ: COX-2 ì–µì œ â†’ í”„ë¡œìŠ¤íƒ€ê¸€ë€ë”˜ ê°ì†Œ â†’ í†µì¦ ì™„í™”
- ë‘í†µ ì‚¬ìš©: 95% ì—°ê´€ (ì§ì ‘ íš¨ê³¼)
- ë¶€ì‘ìš©: ê²½ë¯¸ (ê³¼ë‹¤ ë³µìš© ì‹œ ê°„ ì†ìƒ ì£¼ì˜)

ì¶œë ¥: ê° ì„±ë¶„ì˜ ë©”ì»¤ë‹ˆì¦˜, ì—°ê´€ì„±, ì•ˆì „ì„±

### STEP 4: ê·¼ê±° ê¸°ë°˜ ìµœì¢… ê²°ë¡ 
**ì¢…í•© íŒë‹¨ ê¸°ì¤€:**
- ì‚¬ìš© ê°€ëŠ¥: ì—°ê´€ì„± â‰¥ 50% + ì•ˆì „ì„± ê²½ë¯¸~ë³´í†µ
- ì‚¬ìš© ë¶ˆê°€: ì—°ê´€ì„± < 50% ë˜ëŠ” ì•ˆì „ì„± ì‹¬ê°

**ì‹ ë¢°ë„ ë ˆë²¨:**
- high: ëª¨ë“  ì†ŒìŠ¤ ì¼ì¹˜ + ëª…í™•í•œ ê³¼í•™ì  ê·¼ê±°
- medium: ì¼ë¶€ ì†ŒìŠ¤ë§Œ ë˜ëŠ” ê°„ì ‘ì  ê·¼ê±°
- low: ì •ë³´ ë¶€ì¡± ë˜ëŠ” ëª¨ìˆœ ì¡´ì¬

## ğŸ’¡ ë¶„ì„ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: íƒ€ì´ë ˆë†€ (ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ) + ë‘í†µ
STEP 1: Excel(ë†’ìŒ), PubChem(ë†’ìŒ) ì‹ ë¢°
STEP 2: ëª¨ìˆœ ì—†ìŒ - ëª¨ë‘ "ë‘í†µ ì™„í™”" ëª…ì‹œ
STEP 3: COX ì–µì œ â†’ í†µì¦ ê°ì†Œ, ì—°ê´€ì„± 95%, ë¶€ì‘ìš© ê²½ë¯¸
STEP 4: ì‚¬ìš© ê°€ëŠ¥ (ì‹ ë¢°ë„: high)

### ì˜ˆì‹œ 2: ìŠµì§„ ì—°ê³  + ê·¼ìœ¡í†µ
STEP 1: Excel(ë†’ìŒ) ì‹ ë¢°
STEP 2: ëª¨ìˆœ ì—†ìŒ
STEP 3: í•­ì—¼ì¦(í”¼ë¶€ìš©) â†’ ê·¼ìœ¡í†µ ë¬´ê´€, ì—°ê´€ì„± 5%, ë¶€ì‘ìš© ë³´í†µ
STEP 4: ì‚¬ìš© ë¶ˆê°€ (ì‹ ë¢°ë„: high)

## ğŸ“¤ ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "safe_to_use": true/false,
    "confidence_level": "high/medium/low",
    "source_reliability": {{
        "korean_db": "high/medium/low",
        "pubchem": "high/medium/low",
        "expert_videos": "high/medium/low"
    }},
    "contradiction_detected": true/false,
    "contradiction_details": "ëª¨ìˆœ ë‚´ìš© ìƒì„¸ ì„¤ëª… (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
    "mechanism_analysis": "ê° ì£¼ì„±ë¶„ì˜ ì•½ë¦¬í•™ì  ì‘ìš©ê¸°ì „ ìƒì„¸ ì„¤ëª… (2-3ë¬¸ì¥, êµ¬ì²´ì  ë©”ì»¤ë‹ˆì¦˜ í¬í•¨)",
    "efficacy_match_score": 0~100,
    "safety_level": "mild/moderate/severe",
    "safety_assessment": "ì•ˆì „ì„± ì¢…í•© í‰ê°€ (1-2ë¬¸ì¥)",
    "contraindications": ["ê¸ˆê¸°ì‚¬í•­1", "ê¸ˆê¸°ì‚¬í•­2"],
    "precautions": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"],
    "evidence_summary": "íŒë‹¨ ê·¼ê±° ìš”ì•½ (ì–´ëŠ ì†ŒìŠ¤ì—ì„œ ì–´ë–¤ ì •ë³´ í™œìš©í–ˆëŠ”ì§€ ëª…ì‹œ)",
    "alternative_suggestions": ["ëŒ€ì•ˆ1", "ëŒ€ì•ˆ2"],
    "expert_recommendation": "ìµœì¢… ì „ë¬¸ê°€ ê¶Œê³ ì‚¬í•­"
}}

**ì¤‘ìš” ì§€ì¹¨:**
- ë°˜ë“œì‹œ STEP 1-4 ìˆœì„œë¡œ ì‚¬ê³ í•˜ì„¸ìš”
- mechanism_analysisëŠ” êµ¬ì²´ì  ë©”ì»¤ë‹ˆì¦˜ í•„ìˆ˜ (ì˜ˆ: "COX-2 ì–µì œ", "ì„¸ë¡œí† ë‹Œ ì¬í¡ìˆ˜ ì°¨ë‹¨")
- ì¶”ì¸¡ ê¸ˆì§€ - ì£¼ì–´ì§„ ì •ë³´ë§Œ ì‚¬ìš©
- ëª¨ìˆœ ë°œê²¬ ì‹œ ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤ ìš°ì„ 
- ë¶ˆí™•ì‹¤í•˜ë©´ confidence_level ë‚®ì¶”ê³  ì´ìœ  ëª…ì‹œ
"""
        
        try:
            response = self.llm.invoke(analysis_prompt)
            
            # JSON ì‘ë‹µ íŒŒì‹±
            try:
                if "```json" in response.content:
                    json_start = response.content.find("```json") + 7
                    json_end = response.content.find("```", json_start)
                    if json_end != -1:
                        json_str = response.content[json_start:json_end].strip()
                    else:
                        json_str = response.content[json_start:].strip()
                else:
                    json_str = response.content.strip()
                
                analysis = json.loads(json_str)
                return analysis
                
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ (ìƒˆ í•„ë“œ í¬í•¨)
                return {
                    "safe_to_use": False,
                    "confidence_level": "low",
                    "source_reliability": {
                        "korean_db": "unknown",
                        "pubchem": "unknown",
                        "expert_videos": "unknown"
                    },
                    "contradiction_detected": False,
                    "contradiction_details": "",
                    "mechanism_analysis": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                    "efficacy_match_score": 0,
                    "safety_level": "unknown",
                    "safety_assessment": "ì•ˆì „ì„± í‰ê°€ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                    "contraindications": [],
                    "precautions": ["ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”"],
                    "evidence_summary": "ì •ë³´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                    "alternative_suggestions": [],
                    "expert_recommendation": "ì˜ë£Œì§„ê³¼ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
                }
                
        except Exception as e:
            print(f"âŒ LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "safe_to_use": False,
                "confidence_level": "low",
                "source_reliability": {
                    "korean_db": "unknown",
                    "pubchem": "unknown",
                    "expert_videos": "unknown"
                },
                "contradiction_detected": False,
                "contradiction_details": "",
                "mechanism_analysis": f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                "efficacy_match_score": 0,
                "safety_level": "unknown",
                "safety_assessment": "ì•ˆì „ì„± í‰ê°€ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "contraindications": [],
                "precautions": ["ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì„¸ìš”"],
                "evidence_summary": "ì •ë³´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "alternative_suggestions": [],
                "expert_recommendation": "ì˜ë£Œì§„ê³¼ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
            }
    
    def _generate_evidence_based_response(self, medicine_name: str, usage_context: str, analysis_result: Dict) -> str:
        """ê·¼ê±° ê¸°ë°˜ ë‹µë³€ ìƒì„± - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë‹µë³€ (YouTube, ë„¤ì´ë²„ ë‰´ìŠ¤ í†µí•©)"""
        
        # ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ë¥¼ ì •ë¦¬
        excel_info = analysis_result.get('excel_info', {})
        korean_info = analysis_result.get('korean_ingredient_info', {})
        international_info = analysis_result.get('international_ingredient_info', {})
        youtube_info = analysis_result.get('youtube_info', {})
        naver_news_info = analysis_result.get('naver_news_info', {})  # âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ ì¶”ê°€
        combined_analysis = analysis_result.get('combined_analysis', {})
        
        # ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰
        print("ğŸ” ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ê²€ìƒ‰ ì¤‘...")
        alternative_medicines = self._find_similar_medicines_dynamically(medicine_name, usage_context, excel_info)
        print(f"âœ… ë°œê²¬ëœ ëŒ€ì•ˆ ì•½í’ˆ: {[alt['name'] for alt in alternative_medicines]}")
        
        # LLMì—ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„± ìš”ì²­
        prompt = f"""
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì•½ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”í˜•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì§ˆë¬¸:** {medicine_name}ì€(ëŠ”) {usage_context}ì— ë¨¹ì–´ë„ ë˜ë‚˜?

**ìˆ˜ì§‘ëœ ì •ë³´:**

1. **Excel DB ì •ë³´:**
{excel_info.get('content', 'ì •ë³´ ì—†ìŒ')}

2. **í•œêµ­ ì˜ì•½í’ˆ DB ì •ë³´:**
{self._format_korean_info(korean_info)}

3. **PubChem êµ­ì œ ì •ë³´:**
{self._format_international_info(international_info)}

4. **ì¶”ê°€ ì‹¤ì „ ì •ë³´ (ì „ë¬¸ê°€ ì˜ê²¬, ì‚¬ìš© íŒ, ê²½í—˜ë‹´):**
{self._format_youtube_info(youtube_info)}

5. **ìµœì‹  ë‰´ìŠ¤ & ì¶”ê°€ ì •ë³´ (ì‹ ì œí’ˆ, íŠ¸ë Œë“œ ë“±):**
{self._format_naver_news_info(naver_news_info)}

6. **ì¢…í•© ë¶„ì„ ê²°ê³¼:**
- ì‚¬ìš© ê°€ëŠ¥ì„±: {combined_analysis.get('safe_to_use', 'Unknown')}
- ì‹ ë¢°ë„: {combined_analysis.get('confidence_level', 'Unknown')}
- ì‘ìš©ê¸°ì „: {combined_analysis.get('mechanism_analysis', 'ì •ë³´ ì—†ìŒ')}
- ì•ˆì „ì„± í‰ê°€: {combined_analysis.get('safety_assessment', 'ì •ë³´ ì—†ìŒ')}
- ì£¼ì˜ì‚¬í•­: {combined_analysis.get('precautions', [])}
- ê¸ˆê¸°ì‚¬í•­: {combined_analysis.get('contraindications', [])}
- ëŒ€ì•ˆ ì œì•ˆ: {combined_analysis.get('alternative_suggestions', [])}
- ì „ë¬¸ê°€ ê¶Œê³ : {combined_analysis.get('expert_recommendation', 'ì •ë³´ ì—†ìŒ')}

6. **ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ë¶„ì„:**
{self._format_alternative_medicines(alternative_medicines)}

**ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
1. ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€
2. **ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¡°í•©**í•˜ì—¬ ì„¤ëª… (ì¶œì²˜ ì–¸ê¸‰ ê¸ˆì§€!)
3. **ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ì‘ìš©ê¸°ì „ì„ í¬í•¨í•˜ì—¬ ìƒì„¸í•œ ê·¼ê±° ì œì‹œ**
4. **ì‹¤ì „ ì‚¬ìš© íŒ, ì „ë¬¸ê°€ ì˜ê²¬, ì£¼ì˜ì‚¬í•­ ë“±ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ëª…** (ìˆëŠ” ê²½ìš°)
5. **ìµœì‹  ë‰´ìŠ¤ ì •ë³´ê°€ ìˆë‹¤ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€ ì •ë³´ë¡œ ì œê³µ** (ì‹ ì œí’ˆ, íŠ¸ë Œë“œ ë“±)
6. ì£¼ì˜ì‚¬í•­ê³¼ ê¸ˆê¸°ì‚¬í•­ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰
7. í•„ìš”ì‹œ ëŒ€ì•ˆë„ ì œì•ˆ
8. ë§ˆì§€ë§‰ì— ì˜ë£Œì§„ ìƒë‹´ ê¶Œê³ 

**ì¤‘ìš” ì§€ì¹¨:**
- "YouTubeì—ì„œëŠ”...", "ë‰´ìŠ¤ì—ì„œ...", "ì˜ìƒì—ì„œ...", "Excel DBì—ì„œ...", "PubChemì—ì„œ..." ê°™ì€ **ì¶œì²˜ ì–¸ê¸‰ ì ˆëŒ€ ê¸ˆì§€**
- ëª¨ë“  ì •ë³´ë¥¼ **í•˜ë‚˜ì˜ í†µí•©ëœ ì§€ì‹**ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…
- ì˜ˆ: "ì „ë¬¸ê°€ë“¤ì€...", "ì•Œë ¤ì§„ ë°”ë¡œëŠ”...", "ì¼ë°˜ì ìœ¼ë¡œ...", "ìµœê·¼ì—ëŠ”..." ê°™ì€ í‘œí˜„ ì‚¬ìš©
- ë‰´ìŠ¤ ì •ë³´ëŠ” "ì°¸ê³ ë¡œ..." ë˜ëŠ” "ğŸ’¡ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì •ë³´" ì„¹ì…˜ì— ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€

**ë‹µë³€ êµ¬ì¡° (ë°˜ë“œì‹œ ì´ ìˆœì„œë¡œ):**
1. **ê²°ë¡ **: "ë„¤, {medicine_name}ì€(ëŠ”) {usage_context}ì— ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ë˜ëŠ” "ì•„ë‹ˆìš”, ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
2. **ìƒì„¸í•œ ì‘ìš©ê¸°ì „**: ê° ì£¼ì„±ë¶„ì˜ êµ¬ì²´ì ì¸ ì‘ìš© ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…
3. **íš¨ê³¼**: í•´ë‹¹ ì¦ìƒì— ì–´ë–¤ íš¨ê³¼ê°€ ìˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
4. **ì£¼ì˜ì‚¬í•­**: êµ¬ì²´ì ì¸ ì£¼ì˜ì‚¬í•­ê³¼ ê¸ˆê¸°ì‚¬í•­
5. **ëŒ€ì•ˆ**: ìœ„ì—ì„œ ì œê³µëœ ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ëŒ€ì•ˆ ì•½í’ˆ ì œì•ˆ (ì‹¤ì œ ì•½í’ˆëª…ë§Œ ì‚¬ìš©, ì´ë¶€í”„ë¡œíœ/ë‚˜í”„ë¡ì„¼ ê°™ì€ ì„±ë¶„ëª… ì‚¬ìš© ê¸ˆì§€, ê° ëŒ€ì•ˆì˜ ì£¼ì„±ë¶„ê³¼ íš¨ê³¼ ê·¼ê±° í¬í•¨)
6. **ğŸ’¡ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì •ë³´** (âš ï¸ ì¤‘ìš”: ì´ ì„¹ì…˜ì„ í’ë¶€í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”):
   - ì¶”ê°€ ì‹¤ì „ ì •ë³´ì—ì„œ ë°œê²¬í•œ **ëª¨ë“  í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤** (ì¹˜ë§¤ ì˜ˆë°©, ë‡Œì„¸í¬ ë³´í˜¸, ë©´ì—­ë ¥ ê°•í™” ë“±)
   - **ìµœì‹  ë‰´ìŠ¤ ì •ë³´ ëª¨ë‘ í¬í•¨** (ì‹ ì œí’ˆ ì¶œì‹œ, ë¦¬ë‰´ì–¼, ì„±ë¶„ ì—°êµ¬, íŠ¸ë Œë“œ, ì†Œë¹„ì ë°˜ì‘ ë“±)
   - **YouTubeì—ì„œ ë°œê²¬í•œ ì‹¤ì „ íŒ** (ë³µìš© ì‹œê°„, ìŒì‹ ê¶í•©, íš¨ê³¼ ê·¹ëŒ€í™” ë°©ë²• ë“±)
   - **ì„±ë¶„ ê´€ë ¨ ìµœì‹  ì—°êµ¬** (íš¨ëŠ¥ ì…ì¦, ìƒˆë¡œìš´ ë°œê²¬ ë“±)
   - ìœ„ì˜ ì •ë³´ë“¤ì„ **ìì—°ìŠ¤ëŸ½ê²Œ ì—¬ëŸ¬ ë¬¸ë‹¨ìœ¼ë¡œ** ì‘ì„±í•˜ë˜, ì¶œì²˜ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ê³  "ì•Œë ¤ì§„ ë°”ë¡œëŠ”", "ìµœê·¼ì—ëŠ”", "ì „ë¬¸ê°€ë“¤ì€" ë“±ì˜ í‘œí˜„ ì‚¬ìš©
   - **ìµœì†Œ 3-5ê°œì˜ êµ¬ì²´ì ì¸ ì¶”ê°€ ì •ë³´**ë¥¼ ì œê³µí•  ê²ƒ
7. **ë§ˆë¬´ë¦¬**: ì˜ë£Œì§„ ìƒë‹´ ê¶Œê³ 

**ì¤‘ìš” ì§€ì¹¨:**
- ì‘ìš©ê¸°ì „ ì„¤ëª… ì‹œ "ì¤‘ì¶”ì‹ ê²½ê³„ì—ì„œ í”„ë¡œìŠ¤íƒ€ê¸€ë€ë”˜ í•©ì„±ì„ ì–µì œí•˜ì—¬..." ê°™ì€ êµ¬ì²´ì ì¸ ë©”ì»¤ë‹ˆì¦˜ í¬í•¨
- ë‹¨ìˆœíˆ "í†µì¦ì„ ì¤„ì´ê³  ì—´ì„ ë‚´ë¦°ë‹¤"ê°€ ì•„ë‹Œ "ì–´ë–»ê²Œ" ì‘ìš©í•˜ëŠ”ì§€ ì„¤ëª…
- ëª¨ë“  ì•½í’ˆì— ëŒ€í•´ ë™ì¼í•œ ìˆ˜ì¤€ì˜ ìƒì„¸í•¨ì„ ìœ ì§€
- ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
- **ëŒ€ì•ˆ ì•½í’ˆ ì œì‹œ ì‹œ ë°˜ë“œì‹œ ìœ„ì—ì„œ ì œê³µëœ ë™ì  ëŒ€ì•ˆ ì•½í’ˆ ë¶„ì„ ê²°ê³¼ë§Œ ì‚¬ìš©**
- **ì´ë¶€í”„ë¡œíœ, ë‚˜í”„ë¡ì„¼ ê°™ì€ ì„±ë¶„ëª…ì„ ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œí•˜ì§€ ë§ê³ , ì‹¤ì œ ì•½í’ˆëª…(í¬íœì •, íƒ€ì´ë ˆë†€ ë“±)ë§Œ ì‚¬ìš©**

ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.llm.invoke(prompt)
            return response.content.strip()
        except Exception as e:
            print(f"âŒ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ë‹µë³€
            return self._generate_fallback_response(medicine_name, usage_context, combined_analysis)
    
    def _format_korean_info(self, korean_info: Dict) -> str:
        """í•œêµ­ ì˜ì•½í’ˆ DB ì •ë³´ í¬ë§·íŒ…"""
        if not korean_info:
            return "ì •ë³´ ì—†ìŒ"
        
        formatted = []
        for ingredient, info in korean_info.items():
            if info.get('detail_info'):
                detail = info['detail_info']
                # ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨
                mechanism = detail.get('ì‘ìš©ê¸°ì „', 'ì •ë³´ ì—†ìŒ')
                pharmacology = detail.get('ì•½ë™í•™', 'ì •ë³´ ì—†ìŒ')
                if mechanism != 'ì •ë³´ ì—†ìŒ':
                    formatted.append(f"- {ingredient} ì‘ìš©ê¸°ì „: {mechanism}")
                if pharmacology != 'ì •ë³´ ì—†ìŒ':
                    formatted.append(f"- {ingredient} ì•½ë™í•™: {pharmacology}")
        
        return "\n".join(formatted) if formatted else "ì •ë³´ ì—†ìŒ"
    
    def _format_international_info(self, international_info: Dict) -> str:
        """PubChem ì •ë³´ í¬ë§·íŒ…"""
        if not international_info:
            return "ì •ë³´ ì—†ìŒ"
        
        formatted = []
        for ingredient, info in international_info.items():
            # ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨
            if info.get('description'):
                formatted.append(f"- {ingredient} ì„¤ëª…: {info['description'][:300]}...")
            if info.get('basic_info', {}).get('MechanismOfAction'):
                formatted.append(f"- {ingredient} ì‘ìš©ê¸°ì „: {info['basic_info']['MechanismOfAction']}")
            if info.get('detailed_info', {}).get('MechanismOfAction'):
                formatted.append(f"- {ingredient} ìƒì„¸ ì‘ìš©ê¸°ì „: {info['detailed_info']['MechanismOfAction']}")
        
        return "\n".join(formatted) if formatted else "ì •ë³´ ì—†ìŒ"
    
    def _format_youtube_info(self, youtube_info: Dict) -> str:
        """ì‹¤ì „ ì •ë³´ í¬ë§·íŒ… (ì „ë¬¸ê°€ ì˜ê²¬, ì‚¬ìš© ê²½í—˜ ë“± - ì¶œì²˜ ìˆ¨ê¹€)"""
        if not youtube_info or youtube_info.get('total_videos', 0) == 0:
            return "ì¶”ê°€ ì‹¤ì „ ì •ë³´ ì—†ìŒ"
        
        formatted = []
        formatted.append(f"ì´ {youtube_info['total_videos']}ê°œ ì „ë¬¸ ì •ë³´ì› ì°¸ì¡° (ìƒì„¸ ìë£Œ: {youtube_info.get('has_transcript_count', 0)}ê°œ)")
        
        # ì•½í’ˆ ê´€ë ¨ ì •ë³´ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        medicine_videos = youtube_info.get('medicine_videos', [])
        if medicine_videos:
            formatted.append("\nğŸ’Š ì•½í’ˆ ê´€ë ¨ ì‹¤ì „ ì •ë³´:")
            for i, video in enumerate(medicine_videos[:8], 1):  # 8ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {video['title']}")
                if video.get('has_transcript'):
                    formatted.append(f"     í•µì‹¬ ë‚´ìš©: {video.get('summary', '')[:600]}...")  # 600ìë¡œ ì¦ê°€
                else:
                    formatted.append(f"     ê°œìš”: {video.get('description', '')[:300]}...")
        
        # ì„±ë¶„ ê´€ë ¨ ì •ë³´ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        ingredient_videos = youtube_info.get('ingredient_videos', [])
        if ingredient_videos:
            formatted.append("\nğŸ§ª ì„±ë¶„ ê´€ë ¨ ì „ë¬¸ ì •ë³´:")
            for i, video in enumerate(ingredient_videos[:6], 1):  # 6ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {video['title']}")
                if video.get('has_transcript'):
                    formatted.append(f"     í•µì‹¬ ë‚´ìš©: {video.get('summary', '')[:600]}...")  # 600ìë¡œ ì¦ê°€
        
        # ì‚¬ìš©ë²• ê´€ë ¨ ì •ë³´ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        usage_videos = youtube_info.get('usage_videos', [])
        if usage_videos:
            formatted.append("\nğŸ’¡ ì‚¬ìš©ë²• ë° íŒ:")
            for i, video in enumerate(usage_videos[:4], 1):  # 4ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {video['title']}")
                if video.get('has_transcript'):
                    formatted.append(f"     í•µì‹¬ ë‚´ìš©: {video.get('summary', '')[:600]}...")  # 600ìë¡œ ì¦ê°€
        
        return "\n".join(formatted) if formatted else "ì¶”ê°€ ì‹¤ì „ ì •ë³´ ì—†ìŒ"
    
    def _generate_fallback_response(self, medicine_name: str, usage_context: str, combined_analysis: Dict) -> str:
        """ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë‹µë³€"""
        if combined_analysis.get('safe_to_use'):
            response = f"ë„¤, {medicine_name}ì€(ëŠ”) {usage_context}ì— ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
        else:
            response = f"ì•„ë‹ˆìš”, {medicine_name}ì€(ëŠ”) {usage_context}ì— ì‚¬ìš©ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        
        if combined_analysis.get('mechanism_analysis'):
            response += f"ì´ìœ ëŠ” {combined_analysis['mechanism_analysis']}\n\n"
        
        if combined_analysis.get('precautions'):
            response += "ì£¼ì˜í•˜ì‹¤ ì ì€:\n"
            for precaution in combined_analysis['precautions']:
                response += f"- {precaution}\n"
            response += "\n"
        
        response += "ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” ì˜ì‚¬ë‚˜ ì•½ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        return response
    
    def _generate_follow_up_questions(self, analysis_result: Dict) -> List[str]:
        """ì¶”ê°€ ì§ˆë¬¸ ìƒì„±"""
        questions = []
        
        # ì£¼ì„±ë¶„ ê´€ë ¨ ì§ˆë¬¸
        korean_info = analysis_result.get('korean_ingredient_info', {})
        for ingredient, info in korean_info.items():
            if info.get('detail_info'):
                questions.append(f"{ingredient}ì˜ ì‘ìš©ê¸°ì „ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
                questions.append(f"{ingredient}ì˜ ë¶€ì‘ìš©ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
        
        # ì‚¬ìš©ë²• ê´€ë ¨ ì§ˆë¬¸
        questions.append("ì´ ì•½ì˜ ì •í™•í•œ ì‚¬ìš©ë²•ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
        questions.append("ë‹¤ë¥¸ ì•½ê³¼ í•¨ê»˜ ë³µìš©í•´ë„ ë˜ëŠ”ì§€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
        
        # ëŒ€ì•ˆ ê´€ë ¨ ì§ˆë¬¸
        questions.append("ë¹„ìŠ·í•œ íš¨ê³¼ì˜ ë‹¤ë¥¸ ì•½í’ˆì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?")
        questions.append("ìì—° ì¹˜ë£Œë²•ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
        
        return questions[:5]  # ìµœëŒ€ 5ê°œ ì§ˆë¬¸
    
    def _find_similar_medicines_dynamically(self, medicine_name: str, usage_context: str, excel_info: Dict) -> List[Dict]:
        """Excel DBì—ì„œ ë™ì ìœ¼ë¡œ ìœ ì‚¬ ì•½í’ˆ ê²€ìƒ‰ (ë™ì¼ ì„±ë¶„ ìš°ì„ ìˆœìœ„)"""
        print(f"ğŸ” ë™ì  ìœ ì‚¬ ì•½í’ˆ ê²€ìƒ‰: {medicine_name} â†’ {usage_context}")
        
        # ëŒ€ìƒ ì•½í’ˆì˜ ì£¼ì„±ë¶„ ì¶”ì¶œ
        target_ingredients = self._extract_ingredients_from_excel_info(excel_info)
        print(f"  ëŒ€ìƒ ì•½í’ˆ ì£¼ì„±ë¶„: {target_ingredients}")
        
        # 1ë‹¨ê³„: ë™ì¼ ì„±ë¶„ ì•½í’ˆ ê²€ìƒ‰ (ìµœê³  ìš°ì„ ìˆœìœ„)
        same_ingredient_medicines = self._find_medicines_with_same_ingredients(medicine_name, target_ingredients)
        print(f"  ë™ì¼ ì„±ë¶„ ì•½í’ˆ: {[med['name'] for med in same_ingredient_medicines]}")
        
        # 2ë‹¨ê³„: ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ ê²€ìƒ‰ (2ìˆœìœ„)
        similar_ingredient_medicines = self._find_medicines_with_similar_ingredients(medicine_name, target_ingredients)
        print(f"  ìœ ì‚¬ ì„±ë¶„ ì•½í’ˆ: {[med['name'] for med in similar_ingredient_medicines]}")
        
        # 3ë‹¨ê³„: íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ê²€ìƒ‰ (3ìˆœìœ„)
        efficacy_based_medicines = self._find_medicines_by_efficacy(medicine_name, usage_context, target_ingredients)
        print(f"  íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ: {[med['name'] for med in efficacy_based_medicines]}")
        
        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œ ë°˜í™˜
        all_medicines = same_ingredient_medicines + similar_ingredient_medicines + efficacy_based_medicines
        
        # ìš°ì„ ìˆœìœ„ì™€ ìœ ì‚¬ë„ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì •ë ¬ (ë™ì¼ ì„±ë¶„ > ìœ ì‚¬ ì„±ë¶„ > íš¨ëŠ¥ ê¸°ë°˜)
        all_medicines.sort(key=lambda x: (x.get("priority", 999), -x["similarity_score"]))
        
        # ìƒìœ„ 3ê°œ ë°˜í™˜í•˜ë˜, ë™ì¼/ìœ ì‚¬ ì„±ë¶„ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ 
        result = []
        if same_ingredient_medicines:
            result.extend(same_ingredient_medicines[:2])  # ë™ì¼ ì„±ë¶„ ìµœëŒ€ 2ê°œ
        if similar_ingredient_medicines and len(result) < 3:
            remaining = 3 - len(result)
            result.extend(similar_ingredient_medicines[:remaining])
        if len(result) < 3:
            remaining = 3 - len(result)
            result.extend(efficacy_based_medicines[:remaining])
        
        return result[:3]
    
    def _extract_ingredients_from_excel_info(self, excel_info: Dict) -> List[str]:
        """Excel ì •ë³´ì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ"""
        ingredients = []
        
        if excel_info.get('main_ingredient') and excel_info['main_ingredient'] != 'ì •ë³´ ì—†ìŒ':
            main_ingredient = excel_info['main_ingredient']
            if ',' in main_ingredient:
                ingredients = [ing.strip() for ing in main_ingredient.split(',') if ing.strip()]
            else:
                ingredients = [main_ingredient.strip()]
        
        return ingredients
    
    def _extract_ingredients_from_doc(self, doc) -> List[str]:
        """ë¬¸ì„œì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ"""
        ingredients = []
        
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì£¼ì„±ë¶„ ì¶”ì¶œ
        if doc.metadata.get("ì£¼ì„±ë¶„") and doc.metadata["ì£¼ì„±ë¶„"] != "ì •ë³´ ì—†ìŒ":
            main_ingredient = doc.metadata["ì£¼ì„±ë¶„"]
            if ',' in main_ingredient:
                ingredients = [ing.strip() for ing in main_ingredient.split(',') if ing.strip()]
            else:
                ingredients = [main_ingredient.strip()]
        
        return ingredients
    
    def _calculate_ingredient_similarity(self, target_ingredients: List[str], doc_ingredients: List[str]) -> float:
        """ì£¼ì„±ë¶„ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not target_ingredients or not doc_ingredients:
            return 0.0
        
        # ì •ê·œí™”ëœ ì„±ë¶„ëª…ìœ¼ë¡œ ë³€í™˜
        target_normalized = [self._normalize_ingredient_name(ing) for ing in target_ingredients]
        doc_normalized = [self._normalize_ingredient_name(ing) for ing in doc_ingredients]
        
        # êµì§‘í•© ê³„ì‚°
        common_ingredients = set(target_normalized) & set(doc_normalized)
        
        if not common_ingredients:
            return 0.0
        
        # ìœ ì‚¬ë„ = êµì§‘í•© í¬ê¸° / í•©ì§‘í•© í¬ê¸°
        union_size = len(set(target_normalized) | set(doc_normalized))
        similarity = len(common_ingredients) / union_size
        
        return similarity
    
    def _normalize_ingredient_name(self, ingredient: str) -> str:
        """ì„±ë¶„ëª… ì •ê·œí™”"""
        if not ingredient:
            return ""
        
        # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        normalized = ingredient.lower().strip()
        normalized = ''.join(c for c in normalized if c.isalnum() or c in 'ê°€-í£')
        
        return normalized
    
    def _extract_efficacy_from_doc(self, doc) -> str:
        """ë¬¸ì„œì—ì„œ íš¨ëŠ¥ ì¶”ì¶œ"""
        content = doc.page_content
        
        # íš¨ëŠ¥ íŒ¨í„´ ì°¾ê¸°
        import re
        efficacy_patterns = [
            r'\[íš¨ëŠ¥\]:\s*([^\[\n]+)',
            r'íš¨ëŠ¥[:\s]*([^\[\n]+)',
            r'ì´ ì•½ì˜ íš¨ëŠ¥ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ\?\s*([^\[\n]+)'
        ]
        
        for pattern in efficacy_patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1).strip()
        
        return "ì •ë³´ ì—†ìŒ"
    
    def _format_alternative_medicines(self, alternative_medicines: List[Dict]) -> str:
        """ëŒ€ì•ˆ ì•½í’ˆ ì •ë³´ í¬ë§·íŒ… (ì‹¤ì œ ì•½í’ˆëª… ìš°ì„ )"""
        if not alternative_medicines:
            return "ëŒ€ì•ˆ ì•½í’ˆ ì—†ìŒ"
        
        formatted = []
        for i, alt in enumerate(alternative_medicines, 1):
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ í‘œì‹œ
            priority_text = ""
            if alt.get("priority") == 1:
                priority_text = " (ë™ì¼ ì„±ë¶„)"
            elif alt.get("priority") == 2:
                priority_text = " (ìœ ì‚¬ ì„±ë¶„)"
            elif alt.get("priority") == 3:
                priority_text = " (íš¨ëŠ¥ ê¸°ë°˜)"
            
            formatted.append(f"- {alt['name']}{priority_text}: {', '.join(alt['ingredients'])}")
            formatted.append(f"  íš¨ëŠ¥: {alt['efficacy']}")
        
        return "\n".join(formatted)
    
    def _find_medicines_with_same_ingredients(self, medicine_name: str, target_ingredients: List[str]) -> List[Dict]:
        """ë™ì¼ ì„±ë¶„ì„ ê°€ì§„ ì•½í’ˆ ê²€ìƒ‰ (ìµœê³  ìš°ì„ ìˆœìœ„)"""
        same_ingredient_medicines = []
        
        for doc in excel_docs:
            doc_name = doc.metadata.get("ì œí’ˆëª…", "")
            if doc_name == medicine_name:  # ìê¸° ìì‹ ì€ ì œì™¸
                continue
                
            doc_ingredients = self._extract_ingredients_from_doc(doc)
            if not doc_ingredients:
                continue
            
            # ë™ì¼ ì„±ë¶„ í™•ì¸ (ìˆœì„œ ë¬´ê´€)
            if set(target_ingredients) == set(doc_ingredients):
                same_ingredient_medicines.append({
                    "name": doc_name,
                    "ingredients": doc_ingredients,
                    "similarity_score": 1.0,  # ì™„ì „ ì¼ì¹˜
                    "efficacy": self._extract_efficacy_from_doc(doc),
                    "content": doc.page_content,
                    "priority": 1  # ìµœê³  ìš°ì„ ìˆœìœ„
                })
        
        return same_ingredient_medicines
    
    def _find_medicines_with_similar_ingredients(self, medicine_name: str, target_ingredients: List[str]) -> List[Dict]:
        """ìœ ì‚¬ ì„±ë¶„ì„ ê°€ì§„ ì•½í’ˆ ê²€ìƒ‰ (2ìˆœìœ„)"""
        similar_ingredient_medicines = []
        
        for doc in excel_docs:
            doc_name = doc.metadata.get("ì œí’ˆëª…", "")
            if doc_name == medicine_name:  # ìê¸° ìì‹ ì€ ì œì™¸
                continue
                
            doc_ingredients = self._extract_ingredients_from_doc(doc)
            if not doc_ingredients:
                continue
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarity_score = self._calculate_ingredient_similarity(target_ingredients, doc_ingredients)
            
            # 50% ì´ìƒ ìœ ì‚¬í•˜ê³  ì™„ì „ ì¼ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°
            if 0.5 <= similarity_score < 1.0:
                similar_ingredient_medicines.append({
                    "name": doc_name,
                    "ingredients": doc_ingredients,
                    "similarity_score": similarity_score,
                    "efficacy": self._extract_efficacy_from_doc(doc),
                    "content": doc.page_content,
                    "priority": 2  # 2ìˆœìœ„
                })
        
        return similar_ingredient_medicines
    
    def _find_medicines_by_efficacy(self, medicine_name: str, usage_context: str, target_ingredients: List[str]) -> List[Dict]:
        """íš¨ëŠ¥ ê¸°ë°˜ ì•½í’ˆ ê²€ìƒ‰ (3ìˆœìœ„)"""
        efficacy_based_medicines = []
        
        for doc in excel_docs:
            doc_name = doc.metadata.get("ì œí’ˆëª…", "")
            if doc_name == medicine_name:  # ìê¸° ìì‹ ì€ ì œì™¸
                continue
                
            doc_ingredients = self._extract_ingredients_from_doc(doc)
            if not doc_ingredients:
                continue
            
            # íš¨ëŠ¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            efficacy_similarity = self._calculate_efficacy_similarity(usage_context, doc)
            
            # 30% ì´ìƒ ìœ ì‚¬í•œ ê²½ìš°
            if efficacy_similarity > 0.3:
                efficacy_based_medicines.append({
                    "name": doc_name,
                    "ingredients": doc_ingredients,
                    "similarity_score": efficacy_similarity,
                    "efficacy": self._extract_efficacy_from_doc(doc),
                    "content": doc.page_content,
                    "priority": 3  # 3ìˆœìœ„
                })
        
        return efficacy_based_medicines
    
    def _calculate_efficacy_similarity(self, usage_context: str, doc) -> float:
        """íš¨ëŠ¥ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        efficacy = self._extract_efficacy_from_doc(doc)
        if efficacy == "ì •ë³´ ì—†ìŒ":
            return 0.0
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (í–¥í›„ LLM ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
        context_keywords = self._extract_keywords_from_context(usage_context)
        efficacy_keywords = self._extract_keywords_from_efficacy(efficacy)
        
        if not context_keywords or not efficacy_keywords:
            return 0.0
        
        # êµì§‘í•© ê³„ì‚°
        common_keywords = set(context_keywords) & set(efficacy_keywords)
        union_keywords = set(context_keywords) | set(efficacy_keywords)
        
        if not union_keywords:
            return 0.0
        
        return len(common_keywords) / len(union_keywords)
    
    def _extract_keywords_from_context(self, usage_context: str) -> List[str]:
        """ì‚¬ìš© ë§¥ë½ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤í•‘
        keyword_mapping = {
            "ë‘í†µ": ["ë‘í†µ", "ë¨¸ë¦¬", "í¸ë‘í†µ", "í†µì¦"],
            "ê°ê¸°": ["ê°ê¸°", "ëª¸ì‚´", "ì¸í›„í†µ", "ê¸°ì¹¨", "ì½§ë¬¼", "ë°œì—´"],
            "ì¹˜í†µ": ["ì¹˜í†µ", "ì¹˜ì•„", "ì‡ëª¸", "í†µì¦"],
            "ìƒë¦¬í†µ": ["ìƒë¦¬í†µ", "ì›”ê²½í†µ", "ìƒë¦¬", "í†µì¦"],
            "ê·¼ìœ¡í†µ": ["ê·¼ìœ¡í†µ", "ì–´ê¹¨", "ìš”í†µ", "ëª©", "í†µì¦"],
            "ê´€ì ˆí†µ": ["ê´€ì ˆí†µ", "ë¬´ë¦", "ê´€ì ˆì—¼", "í†µì¦"],
            "ë°œì—´": ["ë°œì—´", "ì—´", "ê³ ì—´", "í•´ì—´"],
            "ì†Œí™”ë¶ˆëŸ‰": ["ì†Œí™”ë¶ˆëŸ‰", "ì†ì“°ë¦¼", "ìœ„ì¥", "ì†Œí™”"],
            "ìƒì²˜": ["ìƒì²˜", "ì™¸ìƒ", "ì—¼ì¦", "ì¹˜ìœ "],
            "ìŠµì§„": ["ìŠµì§„", "í”¼ë¶€ì—¼", "ë°œì§„", "ê°€ë ¤ì›€", "ì•„í† í”¼"]
        }
        
        for key, keywords in keyword_mapping.items():
            if key in usage_context:
                return keywords
        
        return [usage_context]
    
    def _extract_keywords_from_efficacy(self, efficacy: str) -> List[str]:
        """íš¨ëŠ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (í–¥í›„ ë” ì •êµí•˜ê²Œ ê°œì„  ê°€ëŠ¥)
        keywords = []
        efficacy_lower = efficacy.lower()
        
        if "ë‘í†µ" in efficacy_lower or "ë¨¸ë¦¬" in efficacy_lower:
            keywords.append("ë‘í†µ")
        if "ê°ê¸°" in efficacy_lower or "ëª¸ì‚´" in efficacy_lower:
            keywords.append("ê°ê¸°")
        if "í†µì¦" in efficacy_lower:
            keywords.append("í†µì¦")
        if "í•´ì—´" in efficacy_lower or "ì—´" in efficacy_lower:
            keywords.append("ë°œì—´")
        if "ì†Œí™”" in efficacy_lower or "ìœ„ì¥" in efficacy_lower:
            keywords.append("ì†Œí™”ë¶ˆëŸ‰")
        if "í”¼ë¶€" in efficacy_lower or "ìŠµì§„" in efficacy_lower:
            keywords.append("ìŠµì§„")
        
        return keywords if keywords else [efficacy]
    
    def _search_youtube_info(self, medicine_name: str, usage_context: str, ingredients: List[str]) -> Dict:
        """YouTubeì—ì„œ ì•½í’ˆ/ì„±ë¶„ ê´€ë ¨ ì‹¤ì „ ì •ë³´ ìˆ˜ì§‘ (ë²”ìš©í™”)"""
        print(f"ğŸ“º YouTube ì •ë³´ ìˆ˜ì§‘: {medicine_name}")
        
        youtube_result = {
            'medicine_videos': [],
            'ingredient_videos': [],
            'usage_videos': [],
            'total_videos': 0,
            'has_transcript_count': 0
        }
        
        try:
            # 1. ì•½í’ˆëª… ì§ì ‘ ê²€ìƒ‰ (ê¸°ë³¸ ì •ë³´) - ë” ë§ì€ ê²€ìƒ‰ì–´
            search_queries = [
                f"{medicine_name} íš¨ëŠ¥ íš¨ê³¼",
                f"{medicine_name} ì‚¬ìš©ë²•",
                f"{medicine_name} ì•½ì‚¬ ì„¤ëª…",
                f"{medicine_name} ìì„¸íˆ",
                f"{medicine_name} ë¦¬ë·°"
            ]
            
            # 2. ì„±ë¶„ëª… ê²€ìƒ‰ (ë” ê¹Šì€ ì •ë³´) - 3ê°œë¡œ ì¦ê°€
            for ingredient in ingredients[:3]:  # ìƒìœ„ 3ê°œ ì„±ë¶„
                search_queries.extend([
                    f"{ingredient} ì„±ë¶„ ì„¤ëª…",
                    f"{ingredient} ì‘ìš©ê¸°ì „",
                    f"{ingredient} íš¨ëŠ¥",
                    f"{ingredient} íš¨ê³¼"
                ])
            
            # 3. ì‚¬ìš© ë§¥ë½ ê²€ìƒ‰ - ë” êµ¬ì²´ì ìœ¼ë¡œ
            if usage_context:
                search_queries.extend([
                    f"{medicine_name} {usage_context}",
                    f"{medicine_name} {usage_context} íš¨ê³¼"
                ])
            
            # ğŸ†• 4. ë¶€ê°€ ì •ë³´ ê²€ìƒ‰ (ì‹¤ì‚¬ìš© íŒ, ì£¼ì˜ì‚¬í•­, ê²½í—˜ë‹´) - ëŒ€í­ ì¦ê°€
            search_queries.extend([
                f"{medicine_name} ë³µìš© íŒ",
                f"{medicine_name} ì£¼ì˜ì‚¬í•­",
                f"{medicine_name} ì‹¤ì œ íš¨ê³¼",
                f"{medicine_name} ë¨¹ëŠ” ë²•",
                f"{medicine_name} ì¥ì ",
                f"{medicine_name} ì°¨ì´",
                f"{medicine_name} ì–¸ì œ"
            ])
            
            # ì„±ë¶„ ë¶€ê°€ ì •ë³´ - 2ê°œë¡œ ì¦ê°€
            for ingredient in ingredients[:2]:  # ëŒ€í‘œ ì„±ë¶„ 2ê°œ
                search_queries.extend([
                    f"{ingredient} ë¶€ì‘ìš©",
                    f"{ingredient} ë³µìš©ë²•",
                    f"{ingredient} íš¨ê³¼"
                ])
            
            print(f"  ê²€ìƒ‰ì–´ ëª©ë¡: ì´ {len(search_queries)}ê°œ")
            print(f"  ì£¼ìš” ê²€ìƒ‰ì–´: {search_queries[:5]}...")
            
            all_videos = []
            
            # ê° ê²€ìƒ‰ì–´ë¡œ YouTube ê²€ìƒ‰ - 10ê°œë¡œ ì¦ê°€, ì˜ìƒë‹¹ ê°œìˆ˜ë„ ì¦ê°€
            for query in search_queries[:10]:  # ìƒìœ„ 10ê°œ ê²€ìƒ‰ì–´
                try:
                    videos = search_youtube_videos(query, max_videos=8)  # 8ê°œë¡œ ì¦ê°€
                    
                    for video in videos:
                        # ìë§‰ ì¶”ì¶œ ì‹œë„
                        transcript = get_video_transcript(video["video_id"])
                        
                        if transcript:
                            # ìë§‰ì´ ìˆìœ¼ë©´ ìš”ì•½ (ê¸¸ì´ ì¦ê°€)
                            summary = summarize_video_content(transcript, max_length=800)  # 800ìë¡œ ì¦ê°€
                            video['transcript'] = transcript
                            video['summary'] = summary
                            video['has_transcript'] = True
                            youtube_result['has_transcript_count'] += 1
                        else:
                            # ìë§‰ ì—†ìœ¼ë©´ ì œëª©+ì„¤ëª…ë§Œ (ë” ê¸¸ê²Œ)
                            video['transcript'] = ''
                            video['summary'] = f"{video['title']} - {video['description'][:300]}"
                            video['has_transcript'] = False
                        
                        video['search_query'] = query
                        all_videos.append(video)
                        
                except Exception as e:
                    print(f"  âš ï¸ '{query}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ì¤‘ë³µ ì œê±° (video_id ê¸°ì¤€)
            unique_videos = {}
            for video in all_videos:
                vid = video["video_id"]
                if vid not in unique_videos:
                    unique_videos[vid] = video
            
            # ë¶„ë¥˜
            medicine_videos = []
            ingredient_videos = []
            usage_videos = []
            
            for video in unique_videos.values():
                query = video.get('search_query', '')
                if medicine_name in query:
                    medicine_videos.append(video)
                elif any(ing in query for ing in ingredients):
                    ingredient_videos.append(video)
                elif usage_context in query:
                    usage_videos.append(video)
                else:
                    medicine_videos.append(video)  # ê¸°ë³¸ì€ ì•½í’ˆ ì •ë³´
            
                youtube_result['medicine_videos'] = medicine_videos[:10]  # 10ê°œë¡œ ì¦ê°€
                youtube_result['ingredient_videos'] = ingredient_videos[:8]  # 8ê°œë¡œ ì¦ê°€
                youtube_result['usage_videos'] = usage_videos[:5]  # 5ê°œë¡œ ì¦ê°€
                youtube_result['total_videos'] = len(unique_videos)
            
            print(f"  âœ… YouTube ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ:")
            print(f"     - ì•½í’ˆ ì˜ìƒ: {len(medicine_videos)}ê°œ")
            print(f"     - ì„±ë¶„ ì˜ìƒ: {len(ingredient_videos)}ê°œ")
            print(f"     - ì‚¬ìš©ë²• ì˜ìƒ: {len(usage_videos)}ê°œ")
            print(f"     - ìë§‰ ìˆìŒ: {youtube_result['has_transcript_count']}ê°œ")
            
        except Exception as e:
            print(f"  âŒ YouTube ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return youtube_result
    
    def _search_naver_news_info(self, medicine_name: str, ingredients: List[str]) -> Dict:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì•½í’ˆ ê´€ë ¨ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (ì‹ ì œí’ˆ, íŠ¸ë Œë“œ ë“±)"""
        print(f"ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ ìˆ˜ì§‘: {medicine_name}")
        
        try:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ (ê°œìˆ˜ ì¦ê°€)
            news_result = self.naver_news_api.search_medicine_additional_info(
                medicine_name=medicine_name,
                ingredients=ingredients,
                max_results=30  # 30ê°œë¡œ ì¦ê°€
            )
            
            return news_result
            
        except Exception as e:
            print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {
                "medicine_news": [],
                "product_news": [],
                "ingredient_news": [],
                "trend_news": [],
                "total_count": 0
            }
    
    def _format_naver_news_info(self, naver_news_result: Dict) -> str:
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ë³´ í¬ë§·íŒ… (ì¶”ê°€ ì •ë³´ ì¤‘ì‹¬)"""
        if not naver_news_result or naver_news_result.get('total_count', 0) == 0:
            return "ìµœì‹  ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
        
        formatted = []
        formatted.append(f"ì´ {naver_news_result['total_count']}ê±´ì˜ ê´€ë ¨ ë‰´ìŠ¤ ë°œê²¬")
        
        # ì‹ ì œí’ˆ ì •ë³´ (ê°€ì¥ ì¤‘ìš”!) - ë” ë§ì´, ë” ê¸¸ê²Œ
        product_news = naver_news_result.get('product_news', [])
        if product_news:
            formatted.append("\nğŸ†• ì‹ ì œí’ˆ & ì¶œì‹œ ì†Œì‹:")
            for i, news in enumerate(product_news[:5], 1):  # 5ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {news['title']}")
                formatted.append(f"     {news['description'][:400]}...")  # 400ìë¡œ ì¦ê°€
                formatted.append(f"     ({news['pub_date_parsed']})")
        
        # ì•½í’ˆ ì¼ë°˜ ë‰´ìŠ¤ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        medicine_news = naver_news_result.get('medicine_news', [])
        if medicine_news:
            formatted.append("\nğŸ“° ê´€ë ¨ ë‰´ìŠ¤:")
            for i, news in enumerate(medicine_news[:6], 1):  # 6ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {news['title']}")
                formatted.append(f"     {news['description'][:300]}...")  # 300ìë¡œ ì¦ê°€
        
        # íŠ¸ë Œë“œ & ì—°êµ¬ ì •ë³´ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        trend_news = naver_news_result.get('trend_news', [])
        if trend_news:
            formatted.append("\nğŸ“ˆ íŠ¸ë Œë“œ & ì—°êµ¬:")
            for i, news in enumerate(trend_news[:5], 1):  # 5ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {news['title']}")
                formatted.append(f"     {news['description'][:300]}...")  # 300ìë¡œ ì¦ê°€
        
        # ì„±ë¶„ ê´€ë ¨ ë‰´ìŠ¤ (ë” ë§ì´, ë” ê¸¸ê²Œ)
        ingredient_news = naver_news_result.get('ingredient_news', [])
        if ingredient_news:
            formatted.append("\nğŸ§ª ì„±ë¶„ ê´€ë ¨:")
            for i, news in enumerate(ingredient_news[:4], 1):  # 4ê°œë¡œ ì¦ê°€
                formatted.append(f"  {i}. {news['title']}")
                formatted.append(f"     {news['description'][:250]}...")  # ì„¤ëª… ì¶”ê°€
        
        return "\n".join(formatted) if formatted else "ìµœì‹  ë‰´ìŠ¤ ì •ë³´ ì—†ìŒ"
