from qa_state import QAState
from answer_utils import generate_response_llm_from_prompt
from langchain_core.documents import Document
import re
import json
from typing import List

def contains_exact_product_name(doc: Document, product_name: str) -> bool:
    return re.search(rf"\[ì œí’ˆëª…\]:\s*{re.escape(product_name)}\b", doc.page_content) is not None

def extract_medicine_from_context(conversation_context: str) -> list:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê¸°ë°˜)"""
    if not conversation_context:
        return []
    
    # LLMì—ê²Œ ì•½í’ˆëª… ì¶”ì¶œ ìš”ì²­
    extraction_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª…ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½:**
{conversation_context}

**ì‘ë‹µ í˜•ì‹:**
ì•½í’ˆëª…ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
ì˜ˆ: ì•„ìŠ¤í”¼ë¦°, ì´ë¶€í”„ë¡œíœ, íŒŒë¼ì„¸íƒ€ëª°
"""
    
    try:
        response = generate_response_llm_from_prompt(
            prompt=extraction_prompt,
            temperature=0.1,
            max_tokens=200
        )
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì•½í’ˆëª…ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        medicines = [name.strip() for name in response.split(',') if name.strip()]
        return medicines
        
    except Exception as e:
        print(f"âŒ ì•½í’ˆëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def extract_medicine_details_from_context(conversation_context: str) -> dict:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê¸°ë°˜)"""
    if not conversation_context:
        return {}
    
    # LLMì—ê²Œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ìš”ì²­
    extraction_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½:**
{conversation_context}

**ì¶”ì¶œí•  ì •ë³´:**
- ì•½í’ˆëª…
- íš¨ëŠ¥/íš¨ê³¼
- ë¶€ì‘ìš©
- ì‚¬ìš©ë²•
- ì£¼ì˜ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "medicines": [
        {{
            "name": "ì•½í’ˆëª…",
            "effects": ["íš¨ëŠ¥1", "íš¨ëŠ¥2"],
            "side_effects": ["ë¶€ì‘ìš©1", "ë¶€ì‘ìš©2"],
            "usage": "ì‚¬ìš©ë²•",
            "precautions": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"]
        }}
    ]
}}
"""
    
    try:
        response = generate_response_llm_from_prompt(
            prompt=extraction_prompt,
            temperature=0.1,
            max_tokens=800
        )
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            result = json.loads(response)
            return result.get("medicines", {})
        except json.JSONDecodeError:
            print("âš ï¸ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
            return {}
            
    except Exception as e:
        print(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def extract_medicine_context(conversation_context: str, medicine_name: str) -> str:
    """ëŒ€í™” ë§¥ë½ì—ì„œ íŠ¹ì • ì•½í’ˆ ì£¼ë³€ì˜ ë¬¸ë§¥ì„ ì¶”ì¶œ"""
    # configì—ì„œ ì„¤ì •ëœ ìµœëŒ€ ë¬¸ë§¥ ê¸¸ì´ ì‚¬ìš©
    context_length = 100 # ì˜ˆì‹œ ê°’, ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´
    
    pattern = rf".{{0,{context_length}}}{re.escape(medicine_name)}.{{0,{context_length}}}"
    matches = re.findall(pattern, conversation_context, re.IGNORECASE)
    
    if matches:
        return matches[0]
    return ""

def extract_effect_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ íš¨ëŠ¥ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    effect_keywords = ["íš¨ëŠ¥", "íš¨ê³¼", "ë„ì›€", "ê°œì„ ", "ì™„í™”", "ì¹˜ë£Œ", "ì˜ˆë°©"]
    
    for keyword in effect_keywords:
        if keyword in context:
            # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "íš¨ëŠ¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def extract_side_effects_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ ë¶€ì‘ìš© ì •ë³´ë¥¼ ì¶”ì¶œ"""
    side_effect_keywords = ["ë¶€ì‘ìš©", "ì£¼ì˜ì‚¬í•­", "ê²½ê³ ", "ì¦ìƒ", "ë¶ˆí¸"]
    
    for keyword in side_effect_keywords:
        if keyword in context:
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "ë¶€ì‘ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def extract_usage_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ ì‚¬ìš©ë²• ì •ë³´ë¥¼ ì¶”ì¶œ"""
    usage_keywords = ["ì‚¬ìš©ë²•", "ë³µìš©ë²•", "ìš©ë²•", "ë³µìš©", "ì„­ì·¨", "íˆ¬ì—¬"]
    
    for keyword in usage_keywords:
        if keyword in context:
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "ì‚¬ìš©ë²• ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def generate_final_answer_node(state: QAState) -> QAState:
    print("ğŸ¯ ìµœì¢… ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘")
    print(f"ğŸ“Š ìƒíƒœ ì •ë³´:")
    print(f"  - final_answer: {state.get('final_answer', 'ì—†ìŒ')}")
    print(f"  - recommendation_answer: {state.get('recommendation_answer', 'ì—†ìŒ')}")
    print(f"  - relevant_docs: {len(state.get('relevant_docs', []))}ê°œ")
    print(f"  - external_parsed: {state.get('external_parsed', 'ì—†ìŒ')}")
    print(f"  - sns_results: {len(state.get('sns_results', []))}ê°œ")
    print(f"  - sns_analysis: {state.get('sns_analysis', 'ì—†ìŒ')}")
    print(f"  - conversation_context: {state.get('conversation_context', 'ì—†ìŒ')[:100] if state.get('conversation_context') else 'ì—†ìŒ'}...")
    print(f"  - user_context: {state.get('user_context', 'ì—†ìŒ')}")
    
    # âœ… ì´ë¯¸ final_answerê°€ ì„¤ì •ëœ ê²½ìš° (ìµœì‹  ì •ë³´ ìš”ì²­ ë“±)
    if state.get("final_answer"):
        print("âœ… ì´ë¯¸ final_answerê°€ ì„¤ì •ë˜ì–´ ìˆìŒ")
        return state

    # âœ… ë³‘ë ¥ ê¸°ë°˜ ì¶”ì²œì´ ìˆëŠ” ê²½ìš° ë¨¼ì € ë°˜í™˜í•˜ê³  ì¢…ë£Œ (ìš°ì„ ìˆœìœ„ 1ìˆœìœ„)
    if state.get("recommendation_answer"):
        print("âœ… recommendation_answer ì‚¬ìš©")
        state["final_answer"] = state["recommendation_answer"]
        return state

    # ğŸ” LLM ê¸°ë°˜ ë§¥ë½ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
    conversation_context = state.get("conversation_context", "")
    user_context = state.get("user_context", "")
    current_query = state.get("query", "")
    relevant_docs = state.get("relevant_docs", [])
    
    if conversation_context and current_query:
        print("ğŸ”„ LLMì´ ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ ìƒì„±")
        
        # LLMì—ê²Œ ë§¥ë½ ê¸°ë°˜ ë‹µë³€ ìƒì„± ìš”ì²­
        context_aware_prompt = f"""
ë‹¹ì‹ ì€ ì˜ì•½í’ˆ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì§ˆë¬¸:**
{current_query}

**ëŒ€í™” ë§¥ë½:**
{conversation_context[:800] if conversation_context else "ì—†ìŒ"}

**ì‚¬ìš©ì ì§ˆë¬¸ ë§¥ë½:**
{user_context[:400] if user_context else "ì—†ìŒ"}

**ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´:**
{len(relevant_docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤.

**ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
2. ì´ì „ ëŒ€í™” ë§¥ë½ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
3. "ê·¸ ì•½", "ì´ê±°" ê°™ì€ ëŒ€ëª…ì‚¬ê°€ ìˆë‹¤ë©´ ë§¥ë½ì— ë§ê²Œ í•´ì„
4. ìì—°ìŠ¤ëŸ½ê³  ëŒ€í™”ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µ
5. í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬

**ì£¼ì˜ì‚¬í•­:**
- í•˜ë“œì½”ë”©ëœ í…œí”Œë¦¿ì´ë‚˜ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
- ë§¥ë½ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´í•´í•˜ê³  ì‘ë‹µí•  ê²ƒ
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì •í™•íˆ íŒŒì•…í•  ê²ƒ
"""
        
        try:
            # LLMì´ ë§¥ë½ì„ ì´í•´í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
            final_answer = generate_response_llm_from_prompt(
                prompt=context_aware_prompt,
                temperature=0.7,  # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•´ ì ë‹¹í•œ temperature
                max_tokens=1000
            )
            
            state["final_answer"] = final_answer
            print("âœ… LLM ê¸°ë°˜ ë§¥ë½ ì¸ì‹ ë‹µë³€ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ LLM ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë‹µë³€
            state["final_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    else:
        print("âŒ ëŒ€í™” ë§¥ë½ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŒ")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ëŒ€í™” ë§¥ë½ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return state
