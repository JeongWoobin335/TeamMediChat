from qa_state import QAState
from answer_utils import generate_response_llm_from_prompt
from langchain_core.documents import Document
import re
import json
from typing import List

def contains_exact_product_name(doc: Document, product_name: str) -> bool:
    return re.search(rf"\[ì œí’ˆëª…\]:\s*{re.escape(product_name)}\b", doc.page_content) is not None

def extract_medicine_from_context(conversation_context: str) -> list:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê¸°ë°˜)"""
    if not conversation_context:
        return []
    
    # LLMì—ê²Œ ì•½í’ˆëª… ì¶”ì¶œ ìš”ì²­
    extraction_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆëª…ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½:**
{conversation_context}

**ì‘ë‹µ í˜•ì‹:**
ì•½í’ˆëª…ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•´ì£¼ì„¸ìš”.
ì˜ˆ: ì•„ìŠ¤í”¼ë¦°, ì´ë¶€í”„ë¡œíœ, íŒŒë¼ì„¸íƒ€ëª°
"""
    
    try:
        response = generate_response_llm_from_prompt(
            prompt=extraction_prompt,
            temperature=0.1,
            max_tokens=200
        )
        
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì•½í’ˆëª…ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        medicines = [name.strip() for name in response.split(',') if name.strip()]
        return medicines
        
    except Exception as e:
        print(f"âŒ ì•½í’ˆëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def extract_medicine_details_from_context(conversation_context: str) -> dict:
    """ëŒ€í™” ë§¥ë½ì—ì„œ ì•½í’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (LLM ê¸°ë°˜)"""
    if not conversation_context:
        return {}
    
    # LLMì—ê²Œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ìš”ì²­
    extraction_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ëŒ€í™” ë§¥ë½:**
{conversation_context}

**ì¶”ì¶œí•  ì •ë³´:**
- ì•½í’ˆëª…
- íš¨ëŠ¥/íš¨ê³¼
- ë¶€ì‘ìš©
- ì‚¬ìš©ë²•
- ì£¼ì˜ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "medicines": [
        {{
            "name": "ì•½í’ˆëª…",
            "effects": ["íš¨ëŠ¥1", "íš¨ëŠ¥2"],
            "side_effects": ["ë¶€ì‘ìš©1", "ë¶€ì‘ìš©2"],
            "usage": "ì‚¬ìš©ë²•",
            "precautions": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"]
        }}
    ]
}}
"""
    
    try:
        response = generate_response_llm_from_prompt(
            prompt=extraction_prompt,
            temperature=0.1,
            max_tokens=800
        )
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            result = json.loads(response)
            return result.get("medicines", {})
        except json.JSONDecodeError:
            print("âš ï¸ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
            return {}
            
    except Exception as e:
        print(f"âŒ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def extract_medicine_context(conversation_context: str, medicine_name: str) -> str:
    """ëŒ€í™” ë§¥ë½ì—ì„œ íŠ¹ì • ì•½í’ˆ ì£¼ë³€ì˜ ë¬¸ë§¥ì„ ì¶”ì¶œ"""
    # configì—ì„œ ì„¤ì •ëœ ìµœëŒ€ ë¬¸ë§¥ ê¸¸ì´ ì‚¬ìš©
    context_length = 100 # ì˜ˆì‹œ ê°’, ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´
    
    pattern = rf".{{0,{context_length}}}{re.escape(medicine_name)}.{{0,{context_length}}}"
    matches = re.findall(pattern, conversation_context, re.IGNORECASE)
    
    if matches:
        return matches[0]
    return ""

def extract_effect_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ íš¨ëŠ¥ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    effect_keywords = ["íš¨ëŠ¥", "íš¨ê³¼", "ë„ì›€", "ê°œì„ ", "ì™„í™”", "ì¹˜ë£Œ", "ì˜ˆë°©"]
    
    for keyword in effect_keywords:
        if keyword in context:
            # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "íš¨ëŠ¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def extract_side_effects_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ ë¶€ì‘ìš© ì •ë³´ë¥¼ ì¶”ì¶œ"""
    side_effect_keywords = ["ë¶€ì‘ìš©", "ì£¼ì˜ì‚¬í•­", "ê²½ê³ ", "ì¦ìƒ", "ë¶ˆí¸"]
    
    for keyword in side_effect_keywords:
        if keyword in context:
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "ë¶€ì‘ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def extract_usage_from_context(context: str) -> str:
    """ë¬¸ë§¥ì—ì„œ ì‚¬ìš©ë²• ì •ë³´ë¥¼ ì¶”ì¶œ"""
    usage_keywords = ["ì‚¬ìš©ë²•", "ë³µìš©ë²•", "ìš©ë²•", "ë³µìš©", "ì„­ì·¨", "íˆ¬ì—¬"]
    
    for keyword in usage_keywords:
        if keyword in context:
            start = max(0, context.find(keyword) - 50)
            end = min(len(context), context.find(keyword) + 100)
            return context[start:end].strip()
    
    return "ì‚¬ìš©ë²• ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

def generate_final_answer_node(state: QAState) -> QAState:
    print("ğŸ¯ ìµœì¢… ë‹µë³€ ìƒì„± ë…¸ë“œ ì‹œì‘")
    print(f"ğŸ“Š ìƒíƒœ ì •ë³´:")
    print(f"  - final_answer: {state.get('final_answer', 'ì—†ìŒ')}")
    print(f"  - recommendation_answer: {state.get('recommendation_answer', 'ì—†ìŒ')}")
    print(f"  - relevant_docs: {len(state.get('relevant_docs', []))}ê°œ")
    print(f"  - external_parsed: {state.get('external_parsed', 'ì—†ìŒ')}")
    print(f"  - sns_results: {len(state.get('sns_results', []))}ê°œ")
    print(f"  - sns_analysis: {state.get('sns_analysis', 'ì—†ìŒ')}")
    print(f"  - conversation_context: {state.get('conversation_context', 'ì—†ìŒ')[:100] if state.get('conversation_context') else 'ì—†ìŒ'}...")
    print(f"  - user_context: {state.get('user_context', 'ì—†ìŒ')}")
    
    # âœ… ì´ë¯¸ final_answerê°€ ì„¤ì •ëœ ê²½ìš° (ìµœì‹  ì •ë³´ ìš”ì²­ ë“±)
    if state.get("final_answer"):
        print("âœ… ì´ë¯¸ final_answerê°€ ì„¤ì •ë˜ì–´ ìˆìŒ")
        return state

    # âœ… í–¥ìƒëœ RAG ë‹µë³€ì´ ìˆëŠ” ê²½ìš° ë¨¼ì € ë°˜í™˜í•˜ê³  ì¢…ë£Œ (ìµœê³  ìš°ì„ ìˆœìœ„)
    enhanced_answer = state.get("enhanced_rag_answer")
    print(f"ğŸ” enhanced_rag_answer í™•ì¸: {enhanced_answer is not None}, ê¸¸ì´: {len(enhanced_answer) if enhanced_answer else 0}")
    if enhanced_answer:
        print("âœ… enhanced_rag_answer ì‚¬ìš©")
        state["final_answer"] = enhanced_answer
        return state
    
    # âœ… ì•½í’ˆ ì‚¬ìš© ê°€ëŠ¥ì„± íŒë‹¨ì´ ìˆëŠ” ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
    if state.get("usage_check_answer"):
        print("âœ… usage_check_answer ì‚¬ìš©")
        state["final_answer"] = state["usage_check_answer"]
        return state

    # âœ… ë³‘ë ¥ ê¸°ë°˜ ì¶”ì²œì´ ìˆëŠ” ê²½ìš° ë°˜í™˜ (ìš°ì„ ìˆœìœ„ 2ìˆœìœ„)
    if state.get("recommendation_answer"):
        print("âœ… recommendation_answer ì‚¬ìš©")
        state["final_answer"] = state["recommendation_answer"]
        return state

    # ğŸ” LLM ê¸°ë°˜ ë§¥ë½ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
    conversation_context = state.get("conversation_context", "")
    user_context = state.get("user_context", "")
    current_query = state.get("query", "")
    relevant_docs = state.get("relevant_docs", [])
    
    if conversation_context and current_query:
        print("ğŸ”„ LLMì´ ë§¥ë½ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ ìƒì„±")
        
        # LLMì—ê²Œ ë§¥ë½ ê¸°ë°˜ ë‹µë³€ ìƒì„± ìš”ì²­
        context_aware_prompt = f"""
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì•½ì‚¬ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©° ì˜ì•½í’ˆì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸:**
{current_query}

**ì´ì „ ëŒ€í™” ë§¥ë½:**
{conversation_context[:1000] if conversation_context else "ì—†ìŒ"}

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ë§ˆì¹˜ ì¹œêµ¬ë‚˜ ê°€ì¡±ê³¼ ëŒ€í™”í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ
- "ì•„, ê·¸ê±° ê¶ê¸ˆí•˜ì‹œêµ°ìš”!", "ì¢‹ì€ ì§ˆë¬¸ì´ì—ìš”!" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘
- ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
- í•„ìš”ì‹œ "ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!" ê°™ì€ ë§ˆë¬´ë¦¬

**ë‹µë³€ ìš”êµ¬ì‚¬í•­:**
1. ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì •í™•íˆ íŒŒì•…í•˜ê³  ì—°ê²°
2. ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
3. ëŒ€ëª…ì‚¬ë‚˜ ëª¨í˜¸í•œ í‘œí˜„ì´ ìˆë‹¤ë©´ ë§¥ë½ì—ì„œ ì¶”ë¡ í•˜ì—¬ ëª…í™•íˆ í•´ì„
4. í‹°í‚¤íƒ€ì¹´ê°€ ê°€ëŠ¥í•œ ëŒ€í™”í˜• ë‹µë³€
5. 200-400ì ì •ë„ì˜ ì ì ˆí•œ ê¸¸ì´

**ì¤‘ìš”:**
- ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì•½í’ˆì´ë‚˜ ì„±ë¶„ì´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
- ì‚¬ìš©ìê°€ íŠ¹ì • ì„±ë¶„ì— ëŒ€í•´ ë¬¼ì–´ë´¤ë‹¤ë©´ ê·¸ ì„±ë¶„ì—ë§Œ ì§‘ì¤‘í•´ì„œ ë‹µë³€
- ë¶ˆí•„ìš”í•˜ê²Œ ëª¨ë“  ì •ë³´ë¥¼ ë‹¤ ë‚˜ì—´í•˜ì§€ ë§ê³  ì§ˆë¬¸ì— ë§ëŠ” ì •ë³´ë§Œ ì œê³µ
"""
        
        try:
            # LLMì´ ë§¥ë½ì„ ì´í•´í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
            final_answer = generate_response_llm_from_prompt(
                prompt=context_aware_prompt,
                temperature=0.7,  # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•´ ì ë‹¹í•œ temperature
                max_tokens=1000
            )
            
            state["final_answer"] = final_answer
            print("âœ… LLM ê¸°ë°˜ ë§¥ë½ ì¸ì‹ ë‹µë³€ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ LLM ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë‹µë³€
            state["final_answer"] = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    else:
        print("âŒ ëŒ€í™” ë§¥ë½ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŒ")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ëŒ€í™” ë§¥ë½ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return state
